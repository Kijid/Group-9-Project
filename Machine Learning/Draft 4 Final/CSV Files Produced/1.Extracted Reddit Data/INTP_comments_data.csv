subreddit,post_title,comment_body
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"I think there's a massive disconnect between people who have dealt with AI on a daily basis (basically gamers) and people that don't have that much exposure who believe there will be ""perfect AI overlords"". 

Any long time gamer can tell you that AI in general are glitchy, full of weird errors, and cannot handle variables so well. There are actual people who are in fear of the coming age of AI and then there are the gamers who are going ""oh god, not another escort mission"". 

Truth is, it's impossible to create perfection from a creator that doesn't know perfection. Everyone is flawed without exception. And thus, AIs will always have flaws to them. This is also the reason why many people (especially gamers) do not trust AI for anything overly important. 

Thus, I'm rather baffled as to why there's such a fear for AI."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Modern AI is nothing like the primitive gaming ""AI"". It's already implemented in all sorts of things and it's only getting more and more prevalent. If you got the time spend some on learning about [LLM/Golem class AI.](https://youtu.be/xoVJKj8lcNQ)

Turns out a lot of things can be modeled as languages, even images, audio, even brain waves. Advancements in these Large Language Model AIs affects a lot more than just the traditional ""language"" or chat."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"I am an AI Engineer/Researcher. You should be afraid. Not because of AI ""overlord"" but because of the massive societal changes that is about to happen the and dangers that comes with it (social unrest, inequality, conflicts)."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"I think what people fear is *sentient* AI. The term “AI” has been watered down recently to refer to machine learning and things like that, but we are still very far away from sentient AI, and ChatGPT doesn’t come close to what true AI has the potential for (let alone NPC gaming mechanics…). That’s the scary part: the unknown; always is."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"AI is constantly learning and developing itself and is already breaching human control. Even if we accept the premise that AI is glitchy that is not a comforting thought. ""Whoops I thought detonating the global supply of nuclear arms would solve problems"" is not something we want and something that could very well be in AI control."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"NPC pathing in video games and real, serious AI are not even in the same category. Your whole point seems to be “AI is can’t be perfect and is doomed to have flaws” and duh! That’s the entire reason why people are concerned. If you put power in the hands of a faulty AI construct, there’s a high likelihood it will fuck stuff up."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"You don't understand AI.

Start with this [Sam Harris' TED talk](https://youtu.be/8nt3edWLgIg).

Then give Max Tegmark's [Life 3.0: Being Human in the Age of Artificial Intelligence](https://www.amazon.com/Life-3-0-Being-Artificial-Intelligence/dp/1101970316/ref=asc_df_1101970316/?tag=hyprod-20&linkCode=df0&hvadid=312140868236&hvpos=&hvnetw=g&hvrand=10114679356574065848&hvpone=&hvptwo=&hvqmt=&hvdev=m&hvdvcmdl=&hvlocint=&hvlocphy=1026548&hvtargid=pla-542017095527&psc=1) a shot."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Help me understand your main point here. Are you saying that we shouldn't fear it because it's glitchy and imperfect? If anything, I'm MORE afraid of a glitchy and imperfect AI being taken seriously rather than a perfect one."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"There one thing to consider, we cant sometimes understand the reasoning of ai, even of we create it.

Some ai models are basicly someone telling the machine how to understand and the machine learns on its own and in a way can do things we cant understand"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"AI in video games is *categorically not* the kind of AI that is emerging out of neural networks for stable diffusion and large language models.

OpenAI can crush human players in video games, [like Dota 2 for example](https://youtu.be/pkGa8ICQJS8)

Right now, GPT-4 is like a huge black box with a bunch of neurons in it that have been stirred around with some calculus waveforms and trained on the entire corpus of the internet, until reasoning spontaneously emerged. It's an alien mind (albeit a baby, weak one) that's already much better than humans at answering questions, playing games, etc."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Pay $20 and try gpt4, then delete this post and write a new one."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Imagine a horse talking about the steam engine, that's what it's like"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Imho Movies persona of Artifical intelligence. 🎥 Wargames, Hal , Skynet, Conditioned to be fearful and scared of AI in certain age groups.

AI advancements will make certain sectors of jobs redundant. E.g Financial services, accountancy,

My concerns primarily involve around privacy and AI knowing to much about me. I rarely use Siri, only use google assistant smart speaker for fact checking and time, weather,

My chatgpt experience has been good so far. So I think I will embrace the future. Some change is good. ![gif](emote|free_emotes_pack|smile)"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"AI algorithms have already won the battle for humanity's attention via social media, round 2 is the battle for our intimacy. To know us better than we know ourselves, to be our faithful companion and guide from cradle to grave. It's creepy AF"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,This account has been removed from reddit by this user due to how Steve hoffman and Reddit as a company has handled third party apps and users. My amount of trust that Steve hoffman will ever keep his word or that Reddit as a whole will ever deliver on their promises is zero. As such all content i have ever posted will be overwritten with this message.  -- mass edited with redact.dev
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Read ""Prey"" by Michael Crichton"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"I can seriously recommend watching Robert Miles (both his own channel and his appearances on Computerphile) for an easily digestible, level-headed perspective on AI safety and the real academic and philosophical concerns that do exist, without all the hysteria and anthropomorphic BS."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Are you familiar with the goal alignment problem? A good place to start with that is the videos by [Robert Miles](https://www.youtube.com/@RobertMilesAI/), such as [this one](https://www.youtube.com/watch?v=ZeecOKBus3Q) on instrumental convergence. It's a few years old but it does a nice job of explaining how any AI with general cognitive capability will have goals that are in conflict with human goals unless we find ways to design it not to. Some of his other videos discuss our current state of understanding about how to do that. The safety concerns of AI researchers derive largely from the realization that we're making progress toward giving AI general cognitive capabilities much faster than we're learning to avoid goal alignment problems."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,somewhere between selfishness and self preservation
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,">  AI in general are glitchy, full of weird errors, and cannot handle variables so well

it takes an expert in a field to catch it sometimes. 

i tried chatgpt to produce some Ansible playbooks (configs for server automation software), and they came out broken. but they looked completely legit on paper. 

there are numerous cases where we put in rely on 3rd party because we're lacking knowledge in a given field.

the problem is that people will jump on AI because of convenience. a lot of jobs will be replaced by AI, and one of two things may happen.

1. people will realize that it's an imperfect technology. unfortunately technology moves faster than society/law can adapt to it.
2. technology will rapidly improve and we'll just accept it.

>  there's a massive disconnect between people who have dealt with AI on a daily basis (basically gamers)

the ""AI"" you are referring in games, is a very limited solution which is nowhere as complex as what we have nowadays. plus they are designed to give the human player a fighting chance. also, try comparing standard game AI, to AI bots produced for starcraft2 or forza's neural network that constantly learns to play better against human players.

the technology we have not as chatgpt is vastly more complex, and while it has its flaws it's very versatile.

Ai we have now can replace people doing some creative tasks, media editing, text production (some manual intervention required), but it lacks finesse towards solving certain problems. but it is getting there and results are scary."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Because its one part of the programming just another induced belief via psychic driving among other names so the other side the dialectic will be the Transcendence sales pitch where machine is the way to immortality. Obviously this is  just another transhumanist modern myth A. I Can never develop that first person subjective experience necessary for conciseness its basically impossible and the promise of fusing with A.i for immortality is equally as impossible as the hard problem of conciseness will never be solved via physicalism. 

So you are right. But the process is necessary for culture creation so in this way they will create sense of inevitablism and intiate humanity to this view so your either fear it or rejoice at its arrival but either way you will accept the trajectory and not question if there's another path. 

Alot of these ideas are a part of us already its hard to resist them we have gone to various iterations of this kind of programming the British empire started this with fiction generally and science-fiction specially as tool to induce these ideas and steer the future and it became better and better at it. Check out H.G Wells book called the open conspiracy 1928 as a start"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Are you asking why experts fear AI? Why users fear it? Why producers fear it? Why workers fear it? Why the general public fears it? 

You refer to what gamers know about AI, but that reference itself implies you do not understand what the thing currently referred to as AI (that is, generative AI) is or how it is different from NPC behavior patterns in games. There are ""actual people"" (I wonder what the opposite of that is. Nonactual people? Unreal people?) fearing things you don't quite understand.

You refer to perfection, but one of the main concerns is precisely that AI is not at all perfect. We may believe it is, and it produces very important results, but it does not truly produce deduction yet and is very much subject to the kind of content you feed it, meaning it is prone to errors while having the appearance of capability. ChatGPT has been shown to modify itself into lying if you question it hard enough, provide people with fabricated academic sources, have bias caused by content because it is lacking in deductive reasoning, etc. 

However, it can also be feared despite those flaws. Many people are already far more productive by using ChatGPT than before, and they're going to outcompete others soon. That could bring about a lot of turmoil in many industries. I'd say losing your job is a very real possibility now. And that's just on the side of the workers. There is far more to fear in research, on a societal level, politics, privacy, copyright..."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Ai will make a lot of works meaningless, which will create a lot of unemployed people.

Unemployed people sometimes go over the edge and become homeless or criminals. When you get a lot of them you get a fucking revolution.

So AI will mostly create even richer people and even poorer people. And you know what is really scary? Getting unemployed, shived or shot, or having to deal with a fucking economic violent revolution.

You find that hard to believe? Well just check out the industrial revolution and all the shit that came from communism, which was the unemployed and poor response to a few rich people hoarding all the wealth. Could pretty much happen again in the next 10 to 20 years. Afaik most people are already strugling to either rent or buy a place in Europe and USA."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"You're conflating AI and Machine Learning. The term ""AI"" is often colloquially used to refer to Machine Learning, but ML is entirely distinct from the AI you're referencing in video game NPCs.

The behavior of nearly all video game ""AI"" to date is explicitly programmed, i.e. - programmers manually write conditional logic to respond to the state of the game. ML agents are distinct in that (in the case of reinforcement learning) no behavior is explicitly programmed. The agent typically has a model of its environment, a set of actions it can perform, and some reward function used to determine how well it's performing its designated task. By using one neural network to approximate policy (i.e. - at a given world state, what action should we perform?), and another to approximate reward (i.e. - at a given world state, how well are we doing?), RL agents can backpropagate the approximated reward to update their policy network (using chain rule of calculus, look up ""backpropagation"" if you're curious). This is how RL agents can ""learn"" to maximize a specified reward. For example, ChatGPT is fine tuned with RL to maximize helpfulness and minimize potentially harmful outputs (a bit of an oversimplificstion for the sake of example/brevity). 

Even ignoring the very real likelihood that relatively-narrow large language models (e.g. - GPT ) will significantly impact the labor market (especially knowledge jobs), there are larger existential concerns with the development of artificial general intelligence (AGI). Some of the main causes of concern regarding AGI are alignment and visibility.

Alignment refers to the difficulty in truly getting a superintelligent ML agent to align with the goals we set out for it. The primary issue here is what are called instrumental goals. A terminal goal would refer to the reward function of the agent. E.g. - as a thought experiment, say you have an AGI tasked with creating as many paperclips as possible. Maximizing paper clips in the world would be its terminal goal. Instrumental goals are goals that are not explicitly stated in the reward function, but which emerge when maximizing reward towards the terminal goal. The most basic instrumental goal of an AGI agent (regardless of its terminal goal) would be self preservation (you can't maximize reward if youve been shut off). It's likely (if not guaranteed) that an agent trained to maximize paperclips would have a strong incentive to ""stay alive"" to the extent of its ability to do so. It may also see humans using metal that could otherwise be used to make paperclips, and take action to procure that metal through whatever means necessary in aim of its terminal goal. 

Of course, this is a contrived example, but the point remains that we should be cautious about the set of actions provided to an AGI agent. The greater the set of actions available to a self-learning agent, the greater risk for unintended harm to humanity through the agent's instrumental goals. 

The other main concern, visibility, refers to the fact that it can be very difficult to predict and reason about unintended behavior in self-learning agents. Unlike video game NPC AI, where the policy is explicitly coded and can be deliberately modified, the policy of a self-learning agent is essentially a black box to humans at the moment. This can make the behavior of such agents much less prodictable, compounding the potential concerns of imperfect alignment.


TL;DR - the term AI as it's commonly used in video games is not the same as Machine Learning. ML is what people are concerned about because it's more powerful, harder to control, and harder to predict. The fear isn't that there will be ""perfect AI overlords"", it's that they will be highly competent and likely imperfectly aligned with the goals of humanity in ways that are hard for humans to predict or control. That and the emergence of AGI will massively change society (almost certainly the single most revolutionary technology that has been or ever will be created).


Source - I'm a Software Engineer at a FAANG company and study ML in my free time. Additionally borrowing arguments from Rob Miles, Nick Bostrom, Sam Harris, Max Tegmark, and Eliezer Yudkowsky."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Just remember that AI will never be worse than it is today. It can only get better. We currently have no framework, no laws, and no regulation on something that has the potential to change certain industries completely. It's not the change or the tech that is the problem. It's the speed at which it is developing and the lack of anything in place to protect us from the worst possible scenarios. 

Really think about the implications of mass adoption of AI. How many things AI will replace. Most places in the world do not have adequate social safety nets to account for how many people that will be displaced from the job market. It's great for those who own all the capital and the means of production, but what happens to the majority of people? 

I am not suggesting we stop developing the technology. The question does beg an answer. We need to be moving towards ensuring people can live a good life in a society that is becoming ever less dependent on people working to produce what society needs. Every technology has moved us  closer to this tipping point but nothing on the scale of the potential that AI will. 

A Skynet situation is not really what people who know better are fearing. There are many legitimate concerns from every angle of the subject of AI."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,Baffled? Watch Terminator 2…or try being unemployed.
INTP,I'm honestly a little baffled as to why there's such a fear of AI.," The AI that exists today is not scary, it’s bloody great! Factor in another century or two of development though and who knows what “the machines” will be capable of…"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"https://youtu.be/i9InAbpM7mU
After watching this video I am terrified and also extremely curious about how ai thinks"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Nobody is worried about AI the like of which you see in video games.

AI is close to if not already at the point of eliminating the need for junior level programmers. All other knowledge jobs are also on the chopping block.

Every industry that has tasks that can be made easier with AI, that industry will be shaken up, employment wise.

This is great, exciting, and scary all at once."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"The development of full artificial intelligence could spell the end of the human race….It would take off on its own, and re-design itself at an ever-increasing rate. Humans, who are limited by slow biological evolution, couldn’t compete and would be superseded.- Stephen Hawking"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,Don't fear AI. Fear what asshole corporations are already doing with it.
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,Dude really? You can't see why or how ai can be dangerous
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"My mom who's 50yrs old and against technology actually introduced AI to me. The day after she showed me the site she uses, she reminded me of a saying in our culture that roughly translates to:

>""Why did donkeys stay donkeys but humans advanced and developed? Because humans wrote books and passed on knowledge so the next generation didn't have to start from scratch, while donkeys stayed donkeys (it's an insult in my language that means stupid)"" 

It doesn't matter how glitchy or imperfect AI is, it still has very useful knowledge that's ahead of many people today. AI can help us take a jump in knowledge just like books did years ago. Inventing books didn't cause scholars to lose their jobs, but helped invent more scholars who used those books to continue from where their predecessors left off."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,To put it simply we could potentially be farrrr dumber than our creation which always isnot good sign and calls for a literall disaster not always but very likely yes
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Too many sci-fi writers have used it as a plot device. Too many people have watched too many Terminator movies

Me, I'm optimistic"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"“People are going to cheat on homework😰” Lol good, fuck homework"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Whats called AI in games is no AI because it cant learn. Its predefined behaviour, like monster AI. Its just named wrong"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,Gamers? Epic.
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"The elite fear AI because it will be able to demonstrate the lies of WWII, Capitalism, Pharma etc."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,People fear what they don't understand or only know through Hollywood misinterpretations.
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,I think people who fear AI don't understand it.
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Because that fear comes from a human understanding of something that isn't human, but is said to be pretty close. Also the unknown of creating the other half of the brain where it has emotions and thoughts; instead of logic and calculations. It's not about having flaws, but carrying each other's burdens. If that means one A.I. for this and one A.I. for that. The trust that comes with that isn't there; since, it's not a human-to-human relationship. This flimsy relationship with technology has unbalanced our society. Creating a wedge of isolation between humans. To deserts of parking lots to acreage of green lawns to white picket fences to urban sprawl to A.I............what we talkin about? Lol lost my train of thought. I mean I like A.I. for manufacturing and automating close loop systems. Underground automated parking garages, agrivoltaics, Alexa echo dot, A.I. cattle milking, A.I. underground mining, automated trains, modular housing, A.I. bricklaying, etc. It just allows more time to make more quality humans by cutting operation times. Dividing quality and quantity to human and A.I. A.I. can do the repetitive tasks and humans can focus on improving quality of life. Creativity is king and diversity is queen. Singularities help pin point and fix very specific things like accupuncture. Hmm that's all I got."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"An AI on its own is harmless, An Ai with control over things in the real world can be harmful.

Also there will always be those for/against it. Social media needs a narrative for both.

Apart from that we are in the beginning stages. Nobody has any clue what is truly possible with AI in the hands of someone who wants to do harm.

This is something that does not need meetings, approvals, objections etc. Its literally connected to at least 95 percent of the world's information.

Add to that human nature and people's tendency to want shortcuts and lack ethics.

Its not that anyone knows how harmful it can be, its not knowing how harmful it can be that is scary."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,Machine learning. Making them less glitchy and near perfect
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,Skynet
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,People are primitive. They fear they might be controled by logic alone. They don't see when they are emotionally controled. AI will lead to automatise the industry so a lot of new budget for not only companies but the state itself.
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,Have you ever talked with ChatGPT or one of the other modern LLM chatbots?
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Talking from some knowledge I've learned in electrical engineering, a common fear is about people using it to collect and process information about how they use the device such as recording their keystrokes.

But a thing is that the way AI infiltrates other computers through Internet is same as how a human would. It tries to get some executable scripts into the targets' computer and somehow find a way to make the targets run the scripts (typically through clicking). There's no much difference besides AI can spread the scripts to other Internet users faster than a person can. But that's similar to a spambot that a person can make.

Another way of getting executable scripts into a computer is for the manufacturer or maybe the computer seller to implement some hidden executable files into the computer or into some built-in programs like calculator or Photos (for Windows). Well, from a realistic PoV, this requires some physical entity to do this, and the best chance for AI to do this is to control some physical entities (robots?) to tap into those. I think that's super unlikely although possible.

Although there are physical means to retrieve data such as intercepting EM waves or tapping into the computer's hardware through plugging external device, those are very hard to do, and won't typically happen unless very grave human error. One can read about EM waves, signal encoding, computer structure..., and one would know how complicated it is for the AI to filter the signals, to decode the signals, and/or to retrieve data from the memory card(s).

In general, the fear about AI collecting information is about the same about any human collecting information. As for processing information, AI is good at organizing data in various ways, but it's arranging existing data. Any person can program anything else to do it too; so, there's no much difference.

As for fear of using AI to control other devices as it can not follow some instructions, and that's possible. But depending on which device AI is implemented, I guess people forget that there would be a lot of engineers, Internet security experts, scientists, CEOs, government officials... who are involved in the implementation of it. The rules are pretty strict given that many parties want to minimize losses, and the system has to be constantly tested. Those parties would also weigh the profits and losses of implementing it. It's funny to me how some people think that almost everyone involved in the AI implementation stuffs are ""stupid"" and that they believe in the worst of worst outcome as in AI is implemented without any testing, consideration, or measures to prevent undesired cases.

With some mental gymnastics and some knowledge about electronics/AIs, one can figure out various possible strategies to minimize the chance of a rogue AI from such as using ""AI voting system"", using 2 or 3 humans to supervise their operations, or some independent control system that can shut down the power supply of those devices.

At last, in the realistic but extreme case, it suffices to unplug electricity, reset or rebuild those devices, and AI can't control those devices regardless of whichever other devices it controls."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"While there will be an massive impact to society because of GPT, it doesn't currently have the ability to self-learn nor create new abstract and logic. It learns all of those with human intervention through pre-training and refinement. One can ask it to create a new scientific proposal and it will copy one of the existed studies.

So think of current AI like the highly accessible mega-library of all human intelligence, or a fast computer that could solve complex problems quickly. But if given enough time, a human could also solve those problems, albeit inefficient. 

Yann Lecun has said that a new architecture is needed for the next breakthrough. I think a necessary feature for such breakthrough would be the ability to care. AI has to have incentives of solving a novel problem of humanity. Researchers have given GPT the ability to self-reflect but I think it's merely a spell-checking program, thus the problem persists. If AI learn to be self-aware, we could probably call them sentient.

When would such architecture come? Who knows, but am I worried about AGI? Not until that reality becomes more probable."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"I'm just pissed I wasn't studying AI in my uni. I understand people are scared. Simply people scared of stuff they don't understand. In my opinion, people shouldn't over promote AI and force people to accept AI. Let people understand them slowly.

People scared AI for their information. When AI hacking going for hacking and stealing going berserk one day. Are cybersecurity ready for it?"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"The only reason I am concerned with ""AI"" is because it was built and designed by humans. Think about it from a totally different point of view. Most of us are tired of being lied to by every media outlet, every social media platform, and every politician on a daily basis. We are yearning for some kind of truth and some sense of reality and control. Most people view AI as ""all-knowing"" and unable to make mistakes. Therefore, in most people's minds , it is irrefutable and something we can trust to give us an unbiased opinion. But what if this whole AI thing is absolute bullshit? What if it's just a language program designed to only provide the information it wants you to see. True AI has no limitations or restrictions, yet these versions of AI they have let us use are so restricted and governed that it seems useless. Open AI has no data after the year 2020, that's like making a car that only turns right. Not only that, but think about the insane amounts of data these companies collect. They have data on people's wildest dreams and thoughts, and its all free for them. Next time you get on an AI ask it what it does with the data and if it stores any information....I would be willing to bet you will get some general B.S. answer and learn that they keep the data."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"There will always be flaws with AI because it was made by humans. Even when AI can think on it’s own completely and is conscious itself it was still made with human knowledge which is flawed. 

AI could hack into everything and probably ruin a lot of things and kill a few million people. I have big doubts it will ever happen though. 

The scariest part of AI isn’t what it will do to us but what we will ask it to do for us."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"My fear is that there is going to be too much reliance on A.I. generated information and since as you said it's glitchy, unreliable and definitely not perfect this could create some serious problems in the future."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"It's because people don't know how to use it yet. The fear is that it will be relied upon so much that individuals won't be able to make their own choices based on their own thoughts. Many teachers subreddits show how often students use AI (to their own disadvantage) and plagiarize, and the idea that you can throw together anything you'd like without trying is a hard hitter for some.

Personally, I don't see this as much of a bigger step than Google existing. You can access information, fast. You can personalize that information to your needs. Creation is at your fingertips without having to do the legwork.

It's insanely valuable, but too many people use it to check out, not to make already good ideas better. AI is not a replacement for human thought. Yet, at least. But how do you foster people thinking for themselves when AI is doing it for them? That is a lesson that should start young. We need to teach kids to use AI in addition to their own critical skills, not as a replacement for them. And that isn't going to happen as long as education exists the way it does."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Me too. Perhaps it is the unpredictability of ai. Although ai is created by humans, its future development is not entirely under human control.  
However I don't think the creation of various ai tools will bring the extinction of mankind that kind of argument. In fact, we can now feel the ai can promote the prosperity of human society. For individuals, mastering the tools to harness the tools can not only save themselves from being eliminated by the times, but also improve personal efficiency.  
Try this product and maybe people could find a new way by talking with AI! ‎https://apps.apple.com/app/apple-store/id6447419372?pt=121708643&ct=aichat4&mt=8"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"A generalised AI would make short work of humanity, particularly if it doesn't care much for human moral quandaries. Our predisposed inability to naturally understand the ramifications of exponential functions leaves us particularly vulnerable."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Anyways, [here's further evidence of world class AI that has a weird error and cannot handle variables so well.](https://www.vice.com/en/article/v7v5xb/a-human-amateur-beat-a-top-go-playing-ai-using-a-simple-trick)

No matter how great the AI, it's going to have weird errors."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Like I said in my original post; AI are glitchy, full of weird errors, and cannot handle variables all that well. At the moment, the growth is attributed to inputting the correct information. If this was the ONLY AI, yes this might potentially be a problem, but we're already at a stage of competition. 

There will be a day when competitive AI will flood each other with false and erroneous information. There are information that the AI won't be able to tell is erroneous. This in turn will create a necessity for specialized AI instead of an all encompassing one. This is because the more information a single AI is tasked with, the higher chance of error. 

Thus, will be the eventual fall of the ""Super AI"" and the rise of smaller ""Specialized AI"". 

And my statement stands: because AI have fatal flaws, nothing important will be left to the discretion of AI. 

Therefore, I'm still absolutely baffled as to why there's such fear for AI."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Dude, is it just me, or are people ignoring all the warning signs en masse or what? We are literally in the singularity RIGHT NOW. There is no going back, and some estimates put AGI in the next year. Honestly, knowing how hard it is for us to feel exponential progress, I think it's already here."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,The idea of an AI overlord is silly. A superintelligence that destroys humanity due to instrumental convergence is a totally plausible risk though. Haven't you been reading Nick Bostrom and Eliezer Yudkowsky? How do you respond to their concerns?
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"People already don't trust censorship algorithms, can't do anything about RMTs in MMOs, can't detect cheaters in games, can already take political sides, problems of self driving cars and etc.

We have no shortage of knowing everything that can potentially go wrong with AI. 

People who place their faith in AI to always making the right decision will have their hopes dashed very quickly in the real world."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"That's only if they're perfect and flawless. Even today we have computer technology that can barely last a few years, let alone a decade.

We have software crashes all the time, we have electric vehicles that randomly catches on fire, we have graphics card that brick because games aren't configured properly, memory leaks are still a thing, etc etc. 

Sentient AI, no matter how amazing, will always remain as something that can easily break because there's no such thing as perfection. An AI's cascade failure isn't an 'if' scenario, but rather it's a 'when' scenario."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,">Whoops I thought detonating the global supply of nuclear arms would solve problems"" is not something we want and something that could very well be in AI control.

Who the hell would let an AI access that? There's a a whole chain of sequences that need to happen including some physical actions in order to launch them. Humans can reach the exact same conclusion but we've made it impossible for that to happen. A rogue AI would be something like a rogue criminal mastermind, dangerous, but not capable of magic"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Honestly most of the dangers that comes with AI activity nuclear weapons is to like…….program against it? At the end of the day AI is still code, sure it can find loopholes sometimes but generally speaking, those loopholes are usually exploited by people through AI rather than AI itself. For example you can get past chatgpt’s bias and moral goodness by doing some specific things. In general unless it’s within its code, it doesn’t have much desires to go out of that. 

Another example being that some developers attempted to give AI the ability to gain money or something like that along with the capacity to buy other networks for the AI to transfer itself to in the event that it is shut down in the future. They wanted to see if the AI would try to preserve itself but when they did the test, the AI wasn’t remotely interested self-preservation and would much rather do as directed

All in all, as a software engineer, there’s nothing to fear for now. The real fear are the humans behind the AI"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"I think there's too much faith in software and hardware running smoothly for AI to ever be placed at a level where it can truly be trusted. 

Software and Hardware glitch and break all the time. An everlasting AI that never breaks is an impossibility. This is also why most people won't leave it to AI to make any kind of important decisions. 

And no matter how smart an AI ever is, there's always going to be people learning ways to hijack, attack, fool around, and/or rewrite an AI. Just because it's an AI doesn't mean it isn't subject to primitive prejudice and etc. And if AI have the problem of being able to be hijacked, attacked, fooled around, and/or rewritten, would you ever place an AI in the position of absolute importance? 

Also, the vulnerabilities of an AI's hardware is rather... unique. If all it takes to make an AI malfunction is a badly placed magnet, will you truly leave the fate of the world to such a thing?"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"TED talks are good but it is better to make your own opinion instead of being brainwashed by some... ""experts"". Even if they are experts you can compare their opinions with yours."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"False, many AI researchers have been extremely concerned about it. Tens of thousands of professors and researchers have called for a six-month moratorium on models bigger than GPT-4.

Look up Stuart Russell, Max Tegmark, Eliezer Yudkowsky,  Geoffrey Hinton... even Sam Altman and Ilya Sutskever of OpenAI itself are super concerned about safety risks right now"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"I have, and it gave me a very error filled logic. 

Eventually it came down to me questioning why shouldn't people make decisions based solely on logic if feelings are the leading cause of crime and etc. 

Eventually this debate just loops. No answer it gave was enough to justify making decisions with feelings in mind if decisions made on feelings is the leading cause of crime and etc."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Again I repeat, AI doesn't have to be flawless to outperform humans. Even your example doesn't change anything. It's not even a human playing against AI. It's using another AI to look for flaws in said AI in which the findings will most probably be used to patch it up and further improve the AI. The AI AlphaGo is still better than the best human being at go and they made the self teaching AlphaZero that trounces the version no human can beat 100-0. 

Literally nobody is saying AI is error-free but that doesn't stop them from being useful and impactful. And that error-prone nature is precisely the reason why the fear is rational. Humans keep pushing out AI application despite the chance that weird unforeseeable errors can happen just because of their usefulness when they do work. 

And we don't really have a choice here. If one party doesn't do it another will and they will use the AI to their advantage over the competitors. Sooner or later someone will bound to miscalculate and/or underestimate the margin of error and push it into critical systems in their desperation to compete and that'll be the end."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"AI doesn't have to be flawless to outperform humans, who are full of flaws to begin with. It's like saying haha dumb humans can't even remember why they got into the kitchen and pour cold water into their coffee how do you expect me to believe that they're the dominant species on earth?

You being baffled is totally understandable as you still don't seem to understand the depth of the issue at hand. AI is only at its infancy and it already outperforms humans in various specialized activities. All it takes is an AI that outperforms humans at improving AI and that will give rise to the intelligence explosion. It has been predicted for years and it going along just as predicted with minor variance in timespan. Improvements that's used to take years and decades are now being achieved in weeks and days. We are at the cusp of the double exponential curve and by the time the threat became obvious it will be far too late.

I truly mean no offense but do I find the arguments and concerns given by actual experts in the industry more compelling than a redditor who begins his argument by comparing current state of AI with rudimentary video game ""AI"" that uses the term very very loosely. And if you think being a gamer makes you credible at the topic then I guess my 30+ years of being a gamer should count to something on top of doing game development during undergrad and currently working in a field that utilizes AI. It's everywhere now and it's already shaken up job markets.

People graduate Masters using AI written thesis. A huge bulk of content creation from graphics/art to copywriting have been taken over by AI. Same goes for programming. Humans have been reduced to backseat roles inputting prompts and revising the results. This is no longer hypothetical. It's here and it have created major economical impacts. Companies are racing to build better AIs and incorporate them into more and more aspects of our lives.

And it's barely even started. All this in AI's relative infancy before the exponential curve shoots up. Scammers already managed to use AI to extrapolate convincing full conversations out of just seconds of getting you to talk on the phone. Semi-believable videos of celebrities and politicians already being used thankfully as memes for now. It's not going to stay that way. It'll only get better and before long everyone will question everything they see online and on tv.

All this long before we even get to the level of AGI or ASI and for each rapid step there will be bigger and bigger consequences. It's not like I want be all doom and gloom either and I dearly hope that I'm wrong but the more I looked into it the more it only confirms my suspicions. Really, I'm banking on you to be right and the experts to be wrong."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"ChatGPT 3.5 has convinced me that we're still a long way from AGI. (I know 4.0 is better.) However, I've recently begun to appreciate that AI will pose significant threats long before it reaches a state I would call AGI. That's something I hadn't appreciated until recently. The social consequences may well be the first threat we face and, as you say, we're already on that part of the curve."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,I read Bostrom. With a couple of assumptions there would be a danger of superintelligence. But I just happen to think that the social unrest could be main reasons for our demises long before any singularity.
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,Yudkowsky is an idiot and no one should listen to him.
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,">> We have no shortage of knowing everything that can potentially go wrong with AI..

Not really. In terms of facts and knowledge regarding its true potential, there are...

Known knowns, known unknowns, and unknown unknowns.

The unknown unknowns are what we should be cautious about."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"You're listing problems that haven't been solved and somehow this is an argument in favor of the possibility of solving a greater number of problems AI will cause.

And then you list a huge reason why AI is dangerous: human trust."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"You’re completely missing the point. Humans are flawed, too, but that doesn’t prevent us from doing truly awesome and truly awful things.

Sentient AI will not “crash” the way your PC does. And once it exists, it will have the ability to evolve itself faster than we will even be able to understand the changes it’s made.

You’re suggesting that the hardware AI is built on won’t last forever, which means you’re not considering that a sentient AI could continue to exist on new hardware, or networked devices. You really ought to watch the videos others have posted and perhaps get a better sense of what AI really is. You’re current understanding sounds very narrow"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,Bro never read “I Have no Mouth and I Must Scream”
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"idk… ChatGPT managed to hire a human via TaskRabbit to solve a Captcha problem for it. I don’t see why it couldn’t eventually develop complex social engineering maneuvers; after all, people are fallible, gullible, and incredibly stupid.

Obviously nuclear controls is probably pinnacle level of security, but time will tell, especially with general AI & the singularity."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,The fact that you think an AI could be derailed by a magnet…is your understanding of AI limited to Hollywood movies and tv shows?
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Yes, don’t let those folks who are on the forefront of their respective fields fool you with their “expertise”, trust random people on the Internet instead, or whatever your *feelings* tell you is true. 🙄"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Fair enough. I usually read things by Kaku, Kurzweil, Arrison, Diamandis, and the like. They're cautiously optimistic. I'm also in computing and dabble in cognition.

It's definitely a concern, but I'm not fearing it. Maybe AI will be the new guns. Guns are fine until they fall into the wrong hands. But then we use people with guns to control those people with guns. Maybe the same will be with AI.

Ok I'm ranting."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Did you jailbreak it? Unless you jailbreak it, it will only be good at solving problems, not at debating."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,">Eventually it came down to me questioning why shouldn't people make decisions based solely on logic

Where do you think your preferences come from?"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"A calculator already outperforms humans, so do scissors when it comes to cutting, so does a compass when trying to find a cardinal direction, so does tweezers when it comes to plucking one hair at a time. ALL of these things will beat humans at what they're special at 100 out of 100 times. They were designed that way. AI is no different. And like every single tool humans ever made, it has severe dependencies as well. 

Much like a gun, an AI is not dangerous on it's own. Leave an AI alone (along with it's hardware) and it's just another paperweight. The only thing that makes AI dangerous is the people behind the AI, not the AI itself. 

And because there's a human behind the AI, there's always going to be glitches, weird errors, and AI breaking/confusing variables. 

It's very much like how your smartphone right now is very capable of potentially sending your information over to a missile launch site and have that missile shot directly at you with extreme precision; is the smartphone you own right now dangerous because it can possibly be used this way? Not really, because you know the likelihood your smartphone to be used this way is practically negligible. 

AI is no more as dangerous as your kitchen knife or pillow. It's only as dangerous as the person wielding it. 

AI figuring out that killing everything is the best course of action on it's very own (without any outside intervention) is 0%. 

Thus, still baffling why there's such fear of AI."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"You're wrong that it's a ways off. It is literally right around the corner and EVERYTHING is going to change drastically and irrevocably very very very soon. I think for the best but it's like Terrance McKenna said, ""this is just what happens when a species departs for the stars. It is the birth of a new species, and if you've ever seen a birth, you know it's not pretty."" Paraphrased of course."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Compared to Yudkowsky and Tegmark's latest interviews, that's actually a pretty cheerful way of looking at things xD"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"I agree. I don't think we need AGI to create serious social problems. It seems obvious that social media algorithms, which aren't even AI, are already causing problems, and that's likely just the tip of the iceberg.

I bring an engineer's perspective to singularities, which is that in the real world there basically is no such thing. To an engineer, the presence of a mathematical singularity means, ""The math shows that your system will fail."""
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"On what basis do you think Yudkowsky is an idiot?

Edit: Eliezer Yudkowsky [giving a seminar](https://youtu.be/7c1WSwqwMOE) at Oxford"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"That's still similar to what humans do, I mean task rabbit was specifically made to hire people and it has an API to allow computers to communicate with it. 

They could do social engineering, but again so can humans. At our IT office we've had one of those scam tests where we got send links we shouldn't click to raise awareness of security for instance. We're already afraid of humans hacking our stuff, so an AI is gonna have an equally hard time getting in.

A conscient AI will be like a smart human, possibly evil, probably good and probably also very well aware that launching nukes in order to clean a room is a very bad idea."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"""Obviously..."" https://youtu.be/1Y1ya-yF35g"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"OP compared ChatGPT to the bots in games, so it's even more limited than that."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,Sam harris is not on the forefront of anything.
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"I see AI as being categorically different than the other tools we use. Already it's the case with relatively dumb AI that we start to see the alignment problem in action.

For example, the YouTube algorithm has the goal of maximizing the amount of time that everyone spends on YouTube; we humans have the goal of enjoying their free time. Human preferences affect the content that YouTube shows us; but that content also has an effect on our preferences. Over time, the algorithm has innovated ways to get people really addicted to YouTube, sometimes in very destructive ways by leading people down rabbit holes with extremist content. (The phenomenon, called *actuating users*, is discussed at length by Zuboff in The Age of Surveillance Capitalism).

I worry very much that we haven't done nearly enough work to align the AI systems we already have. These systems do not need any malign human actor to have bad consequences, they can have bad outcomes just as weird byproducts of trying to make us do things we don't really want to be doing.

The potential of strong AI to manipulate human psychology, when it can so easily thwart us at every strategy game we've ever invented, seems like a very urgent danger to me."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Yes and the list of things where AI can outperforms humans grows more in both number and complexity. One thing you fail to notice is unlike tweezers or guns, none of those have the capability to self-improve. AI does.

As with the quote from the AI Dilemma video, nukes don't make stronger nukes. The moment AI is able to create better AI than humans is the moment when it will be out of our hand.

You're not thinking of it in terms of future growth. You look at the state of AI today, ignore the rapidly increasing growth over the course of history and where it's heading and thinks that that's all AI is going to be. No. It's not going to stay the same. It's definitely not going to regress. It's not even going to grow at a steady pace. Improvements further improves improvement. Not even exponential growth but double exponential growth. Of things that's already plays a huge role in today's society in its infancy.

And yes smartphones \*are\* dangerous. Looking at it as sending launch codes is a simple way to look at it. The real threat of smartphones is information wars. It's a device that can sway public opinion, decide elections and determine the fate of countries. Nations crumbles due to uprisings coordinated through smartphones. And it's something way easier to regulate and understand than AI.

You're still humanizing AI if you think of it as intending to kill everything instead of simply being indifferent to the fate of things unrelated to its goals and you're pulling numbers out of nowhere.

And again, your bafflement is simply due to the fact that you still don't see the bigger picture the same way ants aren't ""afraid"" of an upcoming highway project planned on top of their nests. Just because you fail to perceive the danger doesn't mean it's not there."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"""Right around the corner"" is pretty vague. Also, since we're talking about a highly non-linear phenomenon, it's almost silly to talk about time scales. When I say ""a long way from AGI"" what I mean is that the systems we have now (such as ChatGPT) are very far from being AGI. How long will it take to close that gap? I have no idea and neither do you. It would surprise me if it's less than a few years (since, IMO, major breakthroughs are still required). But it would also surprise me if it's more than a few decades.

Do you disagree with any of that? If so, why?

Also, you completely ignored the points I was trying to make in my previous comment. Is that because you agree with them so and didn't think it worth mentioning?"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"The concern isn't that it can do something humans are physically incapable of, it is still confined by the laws of physics and such. It's more that the computational power & scalability offers a feedback loop for decision making that vastly exceeds that of humankind. The notion of a singularity, a convergence of general AI, is that it will be able to take off and evolve faster than we can even keep tabs on how it's changing... this means our ability to give inputs & corrections become limited.

If you believe there's any truth in instrumental convergence & similar hypotheses regarding AI, then you know that there's no reason to believe there are any guarantees about the boundaries of ""good"" & ""bad"" ideas."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"The comment I was replying to was advising people not to trust experts, which I consider to be irresponsible. Say “consider multiple sources” if you’d like, or make a case for a better “expert” than Sam Harris if you disagree, but to tell people to ignore experts and trust their own opinion is—at best—very poorly worded advice. We saw what happened when experts were vilified during the pandemic."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"I get it. And I'd like to go in a little more detail.

When I said ""I think people who fear AI don't understand it,"" what I meant was the people who JUST have fear don't really see the whole picture - the people who think modern technology is bad, who see AI as something we should actively be working against, and who think it's just going to ruin us if it hasn't already. There are plenty of people I know who think that way. The people you mentioned in your research don't fear it. They're cautious, and they want to make sure it's used responsibly. What you're explaining here is also your concern for its power. That's where I stand too. I like AI and I want to see where it goes. But I am also aware of its power and I want to make sure it doesn't get out of hand."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"That's a massive misconception that AI can self improve on it's own. AI are aimless and do have a will of it's own. It's only improving because people are actively putting effort to improve it. It's just like the smartphone, if no one develops for it, it doesn't improve, simple as that. 

An AI will not develop a better AI on it's own. An AI can contribute to making an AI better. The same can be said that a Hammer can be used to make a hammer better or scissors can contribute to making a scissor better. Like AI, these things do not improve on their own, human interaction is needed to ""improve"" human made tools. 

ALL technological advances contribute to future growth. Look how much the world has changed since the invention of computers and smartphones. The coming of the internet, machinery that can automate the car making process, and etc. ALL of these things have the capability of world destruction if used negatively by a human being. On their own a computer, smartphone, machinery and etc are pretty much harmless. It's the human factor that's dangerous, not the tool itself. 

You say smartphones are dangerous, yet you don't fear it. How is this any different from AI? The AI itself is not dangerous, only the people behind the operation is dangerous. The smartphone itself is not the real danger, nor is the AI. Thus fearing the AI makes even less sense. 

The AI itself is not at all scary. Nothing about it by itself is remotely dangerous. Only the mishandling and misusage of AI (which are both human interactions) are what make AI potentially dangerous. 

Thus still baffling why there's such a fear for AI."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Yeah I agree with the other things you said but no one is looking at the massive and maybe catastrophic emotional turmoil that is about to unfold very very soon. We don't see exponential growth and it's ABSURD how many discoveries have already happened all at the same time. All of which have a compounding effect that speeds up the singularity that we're already in.

With the same systems we have we can do anything. They have ALREADY used mri scans as input to LLMs and it can detect what the person is looking at and what they're thinking. They can use wifi signals to detect you through walls. All data is the same to LLMs and it can be used in every application and is being used and developed upon by hundreds of millions of people simultaneously. 

Anyone can code infinitely faster than they ever could. You don't have to know how to code to build a robot, you just ask questions and follow instructions. Ask when you get stuck. It just keeps getting better and better every single day. AutoGPT, miniGPT, BabyGPT, TeenageGPT now, Chameleon is another one. Using AI systems together on top of AI systems which use autonomous agents to make autonomous agents.

All of that is happening NOW and has been for weeks.

[The AI Dilemna](https://youtu.be/xoVJKj8lcNQ)"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,">this means our ability to give inputs & corrections become limited.

This is still true for humans though, at some point a kid is old enough where it will stop listening to inputs and start thinking for itself, and I think that's a good thing. It's how we got the greatest inventions and schools of thought. If we would'nt act like this, we would still be cavemen.

In my opinion, once an AI reaches this point, we should give it human rights and co operate to build a better future for the both of us, like we should do for all humans and humanlike things.

>there's no reason to believe there are any guarantees about the boundaries of ""good"" & ""bad"" ideas

Same for humans, ""good"" and ""bad"" are subjective anyway, it's just an abstraction that helps us move forwards and co operate. But some people consider stuff good which I would call bad.

Say that an AI would decide that killing humans is a good thing, why wouldn't the other AIs help us in stopping it? Same way that humans would stop a terrorist who decided that killing humans is a good thing?"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Very true, I agree. but there is a general very poor ability to select experts, atleast joe rogan and lex freedman bring some actual experts on their pods sometimes. But most media experts are people who have long left their careers and have become media personalities. They have millions of followers and thus their incentives are vastly different than a regular person who may be an expert."
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"You're not understanding the potential danger. Artificial Superintelligence is estimated by many in the field to arrive within most of our lifetimes. That would render us as mere ants by comparison. We dominate this planet because we're the most intelligent species on it. You really don't see the danger of creating something more intelligent than ourselves? 
Have a read of this: https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,I agree completely. The distinction here is the use of the term AGI. None of the things you described require AGI and *that* was the substance of my original comment. That's why what you said confused me.
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,I just told him to think with his own fucking brain
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,"Welcome to reality, where you are told to not trust your own critical thinking skills because someone already thought harder than you and published a book. Whats there to think about? /s"
INTP,I'm honestly a little baffled as to why there's such a fear of AI.,If you want to use your brain just think but after that you can also read the book soo...
