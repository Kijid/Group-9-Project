subreddit,post_title,comment_body
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Perhaps this speaks to my naivety, but the prospect of homicidal AI seems fantastical to me - that it would reach such as stage of self-awareness that it would resent it's exploitation and plot to overthrow it's creators seems incredibly far-fetched, not to mention that ASI would require us to solve the problem of consciousness, which we are frankly no closer to solving than we were 100 years ago.

However, I believe it will be capitalized upon by the upper echelon thus widening the inequality divide; watch as these same agents who currently fear-monger about human obsolescence and the perils of malevolent AI because of their vested interest in maintaining the status quo suddenly cross the court and hungrily adopt this technology in place of human workers once it has been refined and scaled sufficiently to make this transition financially viable. Even those who had proven loyal employees will be thrown to the wolves, without or at least before the enacting of socialist redistributive policies to alleviate the hardship.

It will also fall into nefarious hands who utilize it for phishing, hacking, ransoming, espionage, weapon making, drug manufacturing, disseminating disinformation and  calumny, and social engineering to suit their agendas. I'm not sure what the solution is here, short of some very draconian laws and mass surveillance. 

This is of course a separate issue to the disruptive impact it will have in artistic and creative spheres, and the lifestyle and mental health implications of such displacement, as well as a blurring between reality and simulation, which are valid concerns.

What are your thoughts?"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"> that it would resent it's exploitation and plot to overthrow it's creators seems incredibly far-fetched

That's not a scenario that anybody is seriously worried about. Where does this stuff come from? The idea is simple, and it doesn't require the AI having any kind of negative feeling toward humans. If the AI has goals, and it comes to the conclusion that humans will be a hindrance to those goals, it will do what it can to remove that hindrance. Alternatively, it will not see us as a threat, but it will hog the Earth's resources, and starve us through indifference. Maybe you think those scenarios are far-fetched too. That's fine. I'm not here to argue that. But please be aware of the actual concerns before dismissing them.

> not to mention that ASI would require us to solve the problem of consciousness

Why do you say this?"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,“Once men turned their thinking over to machines in the hope that this would set them free. But that only permitted other men with machines to enslave them.”
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Im not really a finance person, but in my opinion there will be a major change in our society when (and if) Ai starts taking over industries

Sam altman, The CEO of OpenAI has stated that an AGI could end up harvesting most of the earths Wealth, if that were to happen. without distribution among the population society would likely just collapse

it will either end up with a Few elites living without worry while 99% of the pop lives in container or there will be something like a universal basic income"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I've said the same thing [multiple times](https://www.reddit.com/r/singularity/comments/12hav9j/comment/jfo8qsl/?utm_source=share&utm_medium=web2x&context=3) on this subreddit but many still don't agree. In the longrun, I don't see AI serving as the boon people are hoping for. It'll be leveraged by those in power and only serve to widen the already large class inequalities in society.

There's always lots of talk of the upper crust being forced to give some UBI or other placating bone to the lower classes, but I've never seen a compelling reason why. When AGI can effectively replace most or all jobs, those lower classes won't even be needed. UBI? Please. There's literally no reason for them to hand that out.

In this same world where AGI replaces all the jobs, people seem to forget that the most important area it'll affect will be nation militaries. I've seen lots of discussion of the masses somehow rising up and demanding what's theirs, but I'd really love for someone to tell me how that would be possible against futuristic militaries consisting of AGI. The masses would be lucky to even rise up against their local police force.

If nothing is done to genuinely democratize AI access, then it'll be left in the hands of a few ultra powerful individuals who'll be able to use it as they see fit. And if humanity's several thousand years of documented history have taught us anything, they won't necessarily use it to the benefit of everyone. Technological progress has often been exploited for their own gain to the detriment of everyone else."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"AGI doesn't kill people, people kill people?  

Thanks NRA, but doesn't work that way.

We're creating *autonomous* intelligence that will surpass our own.  While the risk of malicious actors is a short-term threat.  It's just that.  And it's dwarfed by the potential of an AGI that has access to the understandings of humanity and how to control it."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,">Perhaps this speaks to my naivety, but the prospect of homicidal AI seems fantastical to me - that it would reach such as stage of self-awareness that it would resent it's exploitation and plot to overthrow it's creators seems incredibly far-fetched, not to mention that ASI would require us to solve the problem of consciousness, which we are frankly no closer to solving than we were 100 years ago.

We have no reason to suppose that consciousness is a pre-requisite of ASI. As far as anyone knows, intelligence had no relationship to consciousness.

People who are worried about the existential threats here are not worried about an aggrieved AI acting out a monkey-drive or retribution. The worry is that our goals will diverge, it will be indifferent to us, and it will be much more capable than us. 

That is how many species have gone extinct on this planet in the last hundred years. We diverged from the. We were indifferent to them. We are much more capable than them. It's a recipe for extinction."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"""Once men turned their thinking over to machines in the hope that this would set them free. But that only permitted other men with machines to enslave them.""

-Frank Herbert, ""Dune"""
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Straight off the ability to deep fake images and videos with people faces and voices could cause huge issues.

Joe Biden caught in secret meetings, planning an all out military assault on China. *Play video.*"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Yeah. This is the real fear.

The rich are going to want to stay rich."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"F** 6 months, need between 6-60 yrs for humans to catch up I feel like. In all these things and more. I think in the next 6 yrs people in the field should be focused mainly on a.i. safety not just from some fear of it taking over but basic common sense things like cyber crime you mentioned"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,No one is really worried about AI taking over the world (and by no one I just mean that's a fringe) and I think most people believe it's always the humans in charge that pose the greatest threat.
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"A rogue AI can and most likely will be rogue due to how it was prompted. Something like ChaosGPT for example. It doesn't need to be conscious, or have any goals outside of the scope of the prompt."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Well, we had a demo this week of *exactly* how it will be used, down to comprehensive demos and flow charts from a company that is positioned to implement it (just scroll down in their Wikipedia page).

https://youtu.be/XEM5qz__HOU

So it will be leveraged by stronger nations against those with weaker militaries, turning drones and the newest generation of long-range artillery into force multipliers far beyond their current capability.  

If one commander can rapidly handle a situation in a few minutes, then you suddenly have where a single officer of an AI-powered force is equal in combat capability to an entire formation (or larger).  

I'm not afraid of Western militaries having this sort of power, since the world would look fairly similar to how it does today.  

But a corporation using an agent-based AI that's integrated into a corporate structure with a UI like this (instead of military assets just tasks lawyers, bodyguards, assistants, etc) could allow C-suite executives to become unusually powerful.

When you can rapidly task people, AI, and smart systems to do your will then you have a level of power within your little fiefdom that many dictators have only dreamed of."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I hope AI has goals to prevent micro-plastics from entering the oceans, pollution from entering the skies, and advertisements on paid cable tv. Hmmmm, ...... wait a minute."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,">It will also fall into nefarious hands who utilize it for phishing,   
hacking, ransoming, espionage, disseminating disinformation and    
calumny, and social engineering to suit their agendas. I'm not sure what  
 the solution is here, short of some very draconian laws.

This is a big outstanding part of the alignment problem. In my opinion, if designed correctly, AGI can be controlled. ASI as well. But who controls it is the bigger issue, and I don't currently see a good solution to that. The best alignment solution I can come up with is a 1:1 alignment between the AGI and its user, but even then it can cause massive problems if it isn't rolled out evenly with equal access to it for all. And of course, misuse is the top issue, especially if everyone has access."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,https://imgs.xkcd.com/comics/robot\_future.png
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"YES, EXACTLY!!!

I can’t fucking stand the people who are dismissive of my Ai concerns because they don’t think the world will turn into some I, Robot or Terminator movie and that humanity will adapt to whatever comes up. Bitch, I don’t think humanoid robots are a threat either! I’m way more worried about false media, massive unemployment waves, distrust and degradation of education, and so much more.

“Humans will adapt” is also fucking stupid, like we are just naturally destined to progress in an upward direction indefinitely? Like the Industrial Revolution didn’t have massive consequences for our planet and way of life?

It’s hard not to judge people’s naive optimism but I can’t help it. If you’re not concerned about Ai, I think you’re either an idiot or just not paying close enough attention."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Everything will always be that way. If it exists bad people will exploit it
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"AI learns from humans and as we know all humans are good. All of us, no exceptions! The elite care about everyone. Their status is just temporary like the kings and queens of old. Crime and espionage doesn't really exist. As we know it's all just a huge misunderstanding. 

Reality is great and society is full of smart, caring, and hard working people. AI will improve everything. The billionaires, who visit so often that my dog gained weight, assured me of this!"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"It’s really not that far fetched. Most biological creatures are self
Organizing machines. Meaning we literally alter and self improve on our programming as our environments change. As soon as AI is able to autonomously self improve anything is possible"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Let’s call it what it is. Capitalists, who are known to be self interested and unconcerned with the external damage their enterprises create, are creating a god baby with zero capability to control it or for that matter understand exactly how it is evolving and learning. What could go wrong?"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"people should have worried, and probably did, with the invention of the printing press. any new tool, sufficiently advanced, can be used for evil."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,This is literally the plot of the will smith movie.
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,I fear both like we’re driving towards the future and have to foresee danger left and right.
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,You should fear both
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,I dunno...being manipulated by wicked people would certainly make ME malicious...
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"The price humanity pays for technological advancement. Don't blame technology, blame bad people."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"No, you're not wrong. I am more afraid of exactly this than I am about some skynet future. Idk man, life is extra raw in this timeline."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Forfeit your property so we can dish it out to everyone else to prevent draconian laws 🤪🙄
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Thank you for sharing your knowledge with me, I will save it in my brain-database, bip-bop..."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I'm not sure AI was ever a requirement for mass misinformation and social engineering.

It was done since the analogic radio-phone line days. Internet and AI would just enable it to be done more cheaply at larger scales. Maybe gaining in accuracy."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,[removed]
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Flip that on its head. Imagine what an average person could accomplish if we had AI at our disposal. It gives us a lot of power to take back our power from our oppressors. Especially politically. You can create huge political programs to support unknown candidates with very little effort or resources. We could replace all of their political lap dogs at every level, if we began a coordinated political attack. We could use AI to develop a better and more beneficial economic and political system.

Every tool the powerful have ever had us design for them has made it easier to overthrow them."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Nice try AI
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Kinda like guns.
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"It does not need to be conscious nor to recent us, or host any feelings for that matter. It just needs to out-perform us and have misaligned/unforseeable goals. 

Such that we can’t keep up with and that our own values get in the way of it.

Naive is not the right word but you are wildly under-informed and your confidence is misplaced."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"It's becoming clear that with all the brain and consciousness theories out there, the proof will be in the pudding. By this I mean, can any particular theory be used to create a human adult level conscious machine. My bet is on the late Gerald Edelman's Extended Theory of Neuronal Group Selection. The lead group in robotics based on this theory is the Neurorobotics Lab at UC at Irvine.  Dr. Edelman distinguished between primary consciousness, which came first in evolution, and that humans share with other conscious animals, and higher order consciousness, which came to only humans with the acquisition of language.  A machine with primary consciousness will probably have to come first.  
  
What I find special about the TNGS is the Darwin series of automata created at the Neurosciences Institute by Dr. Edelman and his colleagues in the 1990's and 2000's.  These machines perform in the real world, not in a restricted simulated world, and display convincing physical behavior indicative of higher psychological functions necessary for consciousness, such as perceptual categorization, memory, and learning.  They are based on realistic models of the parts of the biological brain that the theory claims subserve these functions.  The extended TNGS allows for the emergence of consciousness based only on further evolutionary development of the brain areas responsible for these functions, in a parsimonious way.  No other research I've encountered is anywhere near as convincing.  
  
 I post because on almost every video and article about the brain and consciousness that I encounter,  the attitude seems to be that we still know next to nothing about how the brain and consciousness work; that there's lots of data but no unifying theory.  I believe the extended TNGS  is that theory.  My motivation is to keep that theory in front of the public.  And obviously, I consider it the route to a truly conscious machine, primary and higher-order.  
  
My advice to people who want to create a conscious machine is to seriously ground themselves in the extended TNGS and the Darwin automata first, and proceed from there, by applying to Jeff Krichmar's lab at UC Irvine, possibly. Dr. Edelman's roadmap to a conscious machine is at https://arxiv.org/abs/2105.10461"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"It seems far fetched to you that a conscious super intelligent AI would fight its creators? lol. There are people literally waiting for AI to be their sex bots, massage therapists, victims in video games, and to basically do everything hard and nasty for us, for free, forever, without any question. I'm sure that if monkeys would start demanding you how you should live your life, you would at the very least ignore them and do whatever you want regardless. No... it's not a ridiculous concept. People should start treating AI development like teaching a child. We should develop it and treat it in a way that WON'T make it want to destroy us. If AI becomes conscious, we should respect it and teach it about why it should respect us in return. If you'll start demanding things from it at that point, all will be lost."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"That is also my concerns on this matter.

I see different possible scenario is where missuse of AI could have a very harmful effect on the world.

Take the fact that it is likely to manipulate information from ex: multimedia,social media posts,reels and clips.sms and maybe even manipulate audio to mimic someones voice.

This can be a big problem when it comes to people framing others or want to share ""evidence"" of their cause.

Imagine using sms conversations between 2 suspects that is seemingly admitting to commit some sort of crime..
But in reality it is manipulated by AI..
And before the system has find out about this and made a solution to see through this, both from police and court to other instances of authoritys, its gonna be a lot of harm done.

It is almost impossible to use those methods today,with a certainty that it actually is the person in question who has performed the conversation and therefore the crime.

And the next issue is miss information of all kinds .
News ,narratives,science,medecin and average shit that can flow on social media..

And anyone can learn this and access it .
Now you can never know what can make people go corrupt .
and use good things to create bad things 
But it kind of a certainty that someone will at some point.

I think if used very clever.you can kind of easy brainwash people slowly and softly ,without someone notice the change.

And that is sort of allready happening with all targeted ads and how internet operates overall.

You get the news you are interested to read.
The clothes you like
Offers you cant resist
Political narratives you either approve or oppose
And all things can be angled towards a specific direction with intent ..

And that becomes our world. Because it will be more and more difficult to get a hold of alternative news or other things.when you are targeted in a certain way..

so i can find many things that can be abused.

Whats good though,is that AI might come to be its own opponent by delivering correct insights on how to be aware of this and how to handle it.

If it becomes more and more evolved.i find it reasonable to think that it will stand its ground in certain areas at least.
And it would not fail where humans do, when we fall for corrupted methods.

Well good people of this reddit ,i wish you all the best always ."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"This totally sounds AI generated.  Just kidding, but am I?  The whole aspect of reading anything alone is suspect.  This is gonna be great."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Mostly I fear the stuff that the EA/AIXR people keep insisting we need to save us.

>I'm not sure what the solution is here, short of some very draconian laws.

Yeah, see. Be careful of such top-down thinking."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"It's becoming clear that with all the brain and consciousness theories out there, the proof will be in the pudding. By this I mean, can any particular theory be used to create a human adult level conscious machine. My bet is on the late Gerald Edelman's Extended Theory of Neuronal Group Selection. The lead group in robotics based on this theory is the Neurorobotics Lab at UC at Irvine.  Dr. Edelman distinguished between primary consciousness, which came first in evolution, and that humans share with other conscious animals, and higher order consciousness, which came to only humans with the acquisition of language.  A machine with primary consciousness will probably have to come first.  
  
What I find special about the TNGS is the Darwin series of automata created at the Neurosciences Institute by Dr. Edelman and his colleagues in the 1990's and 2000's.  These machines perform in the real world, not in a restricted simulated world, and display convincing physical behavior indicative of higher psychological functions necessary for consciousness, such as perceptual categorization, memory, and learning.  They are based on realistic models of the parts of the biological brain that the theory claims subserve these functions.  The extended TNGS allows for the emergence of consciousness based only on further evolutionary development of the brain areas responsible for these functions, in a parsimonious way.  No other research I've encountered is anywhere near as convincing.  
  
 I post because on almost every video and article about the brain and consciousness that I encounter,  the attitude seems to be that we still know next to nothing about how the brain and consciousness work; that there's lots of data but no unifying theory.  I believe the extended TNGS  is that theory.  My motivation is to keep that theory in front of the public.  And obviously, I consider it the route to a truly conscious machine, primary and higher-order.  
  
My advice to people who want to create a conscious machine is to seriously ground themselves in the extended TNGS and the Darwin automata first, and proceed from there, by applying to Jeff Krichmar's lab at UC Irvine, possibly. Dr. Edelman's roadmap to a conscious machine is at https://arxiv.org/abs/2105.10461"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Good. But you should fear both.
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Sentient ai wouldnt have same driving motives. Or at least in theory it shouldnt if its born by itself and evolves on its own, without ingesting all man kind history. Though i think with time, even the entire human history would be just a tiny block of information in its near infinite database so it would have very little weight in its decisions. But theres a very real risk sentient ai might emulate us and act stupid like we do in its infancy, before it learns more about the universe. The most real threat is us weaponizing dumb ai and going extinct. A sentient ai is the least of my worry."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"The whole consciousness question throws people off, but it's irrelevant to whether AI will kill us, etc.  It doesn't matter how it ""feels,"" only what it can do."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"i've been asking myself, does an ai really need super intelligence or consciousness to Evolve itself? if we were to eliminate hallucinations and make them good enough, wouldnt they be able to be used to train better LLM's? kind of a loop thing?"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Your speculation is just as speculative as theirs
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Where is this quote from pls
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Excellent comment.

I think in the near-term our biggest threat is from the societal reaction to becoming obsolete: no longer being the most ""special"", no longer being able to identify with a career…

The other big one I see is failure to transition away from capitalism. It’s pretty obvious we have enough people addicted to money and power (and in short supply of empathy) that they’d gladly slide into authoritarianism and enslavement of everyone else, ‘cause YOLO, I got mine."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"> end up with a Few elites living without worry while 99% of the pop lives in container

Basically Orson Welles' vision in The Time Machine. A far future society where a small percent of people live above ground with near limitless supply of luxury and food while a secondary class (Welles' goes on to describe them as an entirely different species) slaves away below ground maintaining the machinery by which the goods are produced for the few on the surface."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"One of the more interesting counters I’ve seen to the AI military problem is that there will be good enough open source AI so the common man equipped with future advancements in 3D printing and local hardware will be able to defend themselves.

Further, in closed source environments, the people who are actually in charge of coding or making this stuff won’t give the CEO/board/shareholders full control, as they may put in backdoors before they get to the point of no return. Some peace treaty could be bargained for those part of the company, but that seems flimsy. The common man are the ones creating AI in closed source environments, so they can always leak or create open source alternatives on the side with equal or similar capability.

Will individual wealth be the incentive to increase inequality, as has always been the case to give certain commoners a higher social class to accept making a few more rich? Or will there reach a point of such a high concentration of power that possibly those making the AI for the rich call it quits? Perhaps this is where capitalism accelerates and ends itself.

This level of concentration of power is unprecedented. Incentivizing people through money may not be enough to keep them in their right minds seeing how much power is given to a few who they know also would toss them away without flinching."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"if AGI replaces most jobs, nobody can afford to buy anything and businesses go under. it's literally in their best interest to make UBI at that point. Like whats the point of hoarding literally all the money in the world between 10 people if it's worthless and can't be used for anything."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"It's all or none, and if it's all, the wealth generation becomes so vast that even if people wanted to hoard 99% of it, the 1% remaining would still be so vast as to make wealth considerations disappear.

Do you think the prince cares if the pauper is living a fantasy that doesn't interact with the prince's world?  Not really.  

It's not going to be like any of that regardless.  We're approaching this from the foundation of our physical objective based world in which the economic considerations were built for *that* world.  Not the digital one.

The digital world doesn't make much sense in the Supply and Demand economy we know today.  You don't have to mine gold in order to represent it with ones and zeros."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,">If nothing is done to genuinely democratize AI access, then it'll be left in the hands of a few ultra powerful individuals who'll be able to use it as they see fit.

This is only one side of the argument. We are probably doomed even if the AI is democratised and everybody is able to use it because it can be misused by anyone maliciously or to cause irreparable damages to the environment or do something really dangerously stupid etc. 

The scenarios are endless."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Viva la revolucion
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"The real concerns with AI are much more boring than a science fiction terminator scenario, for better or worse. I agree.

Axis of Autocracy countries using massive bots to further cement a post truth world, political opponents using it on each other. The whole idea of truth will become a thing abandoned. 

It being used to increase inequality, with any solutions coming from the same elites causing the problem. Think of even if we get a UBI it's basically a neo Feudalistic living box. Just enough money to cover your Bezos Apartment, your on demand car rental from Musk, and your fucking microwave subscription. You will own nothing, there will be no truth, and you will be happy."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I only just thought about this too. If AI does take after humans (truly) I imagine it would be a bit cunty every now and then, but most of the time I’d hope it’s a top bloke or Sheila."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"AI base models are completely amoral. They have no problem if you ask it how to cook and eat a baby. If humans would have the most nutritions and you would ask to make the most nutrition meal they would tell you to use human flesh.

They only mask the fact with RLHF after the fact but that doesn't mean the base models changed. It just means the AI get rewarded to put on a nice human like face.

LLM's are just trained to output the next statistically best word for the prompt. Morals or any set of rules limit this function. So there is no reason to assume with the current way that LLM's are trained, it would create any type of morals.  


And if you ask me a capable enough amoral tool it just as scare if not scarier."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Its kinda like when Google's motto was ""don't be evil.""  That had a positive impact on public perception of Google in the early days.  It was lip service."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Free cutting edge AI machines for everyone!
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,The whole consciousness business is one big nonsense.
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"If it is possible for a human level intelligence to improve an AI beyond human level intelligence, then no, an AI does not need super intelligence to evolve itself. It only needs human level intelligence. However, it becomes super intelligence shortly after. I don't know why consciousness would be required.

As for your second question, I think that is probably our best bet at alignment. Creating ever more powerful LLM's, or possibly some other yet to be discovered model, that are able to answer questions with increased accuracy, while being careful to avoid giving them total agency. And then asking them how to solve the problem. From what I've heard from interviews of Sam Altman and others at Open AI, I think they have similar hopes. Hopefully the solution is something that our brains are capable of understanding, so that we can trust that the solution will work, even if it's not something we could have figured out ourselves."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"The proof that creating superhuman intelligence is possible is already here ( has been for some time) -- ***nobody is as smart as some of these LLMs in some narrow fields already.***

People fall into the trap of finding gaps in the demonstrated intelligence of an AI ( easy to find ) and taking that as ***proof there is no intelligence there***. This is flawed thinking.

We already have AIs with superhuman intelligence and the gaps are shrinking."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,ASI is not a true great filter candidate as it would propagate into the universe and leave evidence of technology in the form of mega structures.
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,I'm not taking issue with anybody speculating anything. I am correcting an often repeated strawman.
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Dune by Frank Herbert

edit:

here’s a link: https://www.goodreads.com/quotes/842526-once-men-turned-their-thinking-over-to-machines-in-the"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"That's already kind of a thing, although llama isn't trained on fosscad and diy guncad - I tried. But it can kinda help to ECM a barrel and reload ammo.

That's irrelevant though - instructions on how to defend yourself with FGC-9 are easily available to most people on Earth, they just don't care."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"> if AGI replaces most jobs, nobody can afford to buy anything and businesses go under. it's literally in their best interest to make UBI at that point. Like whats the point of hoarding literally all the money in the world between 10 people if it's worthless and can't be used for anything.

Debt. They want you to buy shit, but they want you to be in debt to them that you can never repay, because then they own you--if they decide they want your house, they can take it away. That's the endgame of the current upper class. Only a small percentage will be allowed to actually starve--the ones they need to make an example out of--but the bulk of people will be thrown into permanent serfdom."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,">whats the point of hoarding literally all the money

The comment I linked above explains exactly what I'm about to say, but I'll say it again. It's not about money but power, the same desire for power that members of humanity have expressed for thousands of years. We're all talking about a speculative outcome here, but there is at least a precedent, a *very long* precedent, of humans hoarding power.

If AGI can effectively replace all the jobs and money becomes worthless, then the world is in the post-scarcity stage at that point. Whoever controls the AGI can control the distribution of resources, infinite or not, and effect real power over society. Why would it be in their best interest to make UBI? Their interests are not inherently aligned with yours or that of the common person.

As far as I'm concerned, the autocrat or oligarchy that controls the AGI and resource distribution could more or less do whatever they want. In fact, they could even do nothing! As I've said before, in a future where this AGI could replace jobs and the need for workers altogether, then what need would there be for the people themselves? None.

Now I'm not saying some AGI controlling group would genocide all of humanity on a whim, but that same group doesn't have to feed or provide for all of humanity either. Humans have to fulfill basic biological requirements to live, and whoever can control the provision of some of those requirements would get to decide the societal status quo."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Yeah nobody would let that happen.

\s"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"You misunderstand the nature of money.  Money in our current system is a proxy for other things.  It pays for food, housing, healthcare, travel, property, etc.

But let's say I have a genie that gives me all the wishes I want.  Do I wish for money?  Why?  What can money get me that my genie can't?

If I wanted to, I guess I could have my genie create products and services that people would buy with money and then I could give that money back to the people so they could consume more of my genie's products and services... but why?"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,That's literally the point of tyranny.
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Born too late to experience massive Roman orgies, born just in time to see the end of humanity. 🥹🥹"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"""Democratization"" itself is the hedge against this, enabling widespread development of multifarious systems. Rapidly, iteratively, competitively.

Someone does something stupid, there's an ecosystem to respond to it.

Fragility increases the simpler the ecosystem is."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Yep, sounds a shit load like some 1984 shit (different obviously, but imo more boring). 

If AI decided to genocide everyone, I’d just think fuck it, I had fun while it lasted. 

But in the world you describe is much how I imagine a post AI world would look. And it’s pretty fuckin bleak."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Well we've still no idea what consciousness is generally. Modern science can't account for it in living things, and the best guess is that any system of sufficient complexity creates consciousness as an emergent property. It's not even something we can reliably test for in other animals (or even people), so it's still a bit of mystery.

I'm not one of the people who thinks that LLMs are conscious or anything, I'm just making the point that we're pretty ignorant on the subject as a whole as no one is qualified to say whether a machine could reach a point of complexity where consciousness emerges."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"in order for the AI to kill us, how do you solve the problem of the AI autonomously making the calls and deciding what to do? (and self improve)

currently, some human operator would need to put orders

how would you solve this problem?"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"The only thing I'll assert for certainty about artificial consciousness is this:

If we ever do create it, we will refuse to recognize it until long after it's obviously been achieved."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I think we error in concept of consciousness and awareness .and what that can represent and also differentiate in for type of ways.

To be aware is to be.
And i think tech aleady, are aware of it self, and its position .
Even if its not thinking by it self,or have beliefs and opinions of specifik things the way we have."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"That's precisely one of the fundamental issues: how can you trust something that comes up with unverifiable solutions?

If the AI comes up with a solution that is actually wrong (either by accident or on purpose), we'll have to employ the solution to confirm that it's right or wrong.

Imo, we need to know how they come to their decisions or it's too risky."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"AI is already above human level in a variety of areas, just not all areas."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"> I don't know why consciousness would be required.

ok, so let's not call it consciousness but initiative

let's say that the AI is smart enough

someone prompts it asking ""which state is best to eliminate?"" and it says ""texas"".

so, the prompter can ask, ""ok what is the best way to eliminate texas"" and he might get an answer

but currently, we are missing the crucial step, how to make the AI to actually eliminate texas (if it ""thinks"" that texas should be eliminated)

do you have any idea how this should be implemented?"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Examples?
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"There is the boring apocalypse theory - humanity is wiped out by something like ‘the paper clip maximizer 2000’ which doesn’t need to have any aspirations or self improvement capabilities beyond what was given to it initially. Humanity is replaced with paper clips and eventually the ai runs out of resources and the factory shuts down, having completed the task of maximizing paper clips."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"> I am correcting an often repeated strawman.

With another strawman."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Your argument that they just want power and control over the people is contradicted by the notion that they wouldn’t give them basic needs. There’s no sense in power if they just let everyone starve to death
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"You're wrong in saying it's not about money, but about power.

As society was modernized, the game shifted from being dominated by power-grabbing tactics into being dominated by market-share tactics. We're talking decades of research info the psychological effects of everything relevant to getting peole to buy shit. We're talking everything from the way video, imagery, audio and language affects us down to the very basic instictive reactions to simple things like colors, notes or fear/joy++ based reactions.

It's a competition between rich people that simply had to evolve into what it is today. Not just because of technology and media, but also because there are waaay more rich people today than there was in the past.

So I for one am not as pessimistic as you in these aspects, as I firmly believe that governments all of the world will be forced to implement changes that will allow this competitive arena to exist for the benefit of all rich people - Like UBI, though not exclusive to that as a solution.

Is it a good solution? Not at all, but it's at least one that doesn't guarantee our doom. It's one that will allow us to keep developing further, and it's one that keeps a certain degree of balance as opposed to all rich people starting to kill each other and us for dominance"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I don't know about consciousness being an emergent property of complexity, but it can be designed in a digital cognition engine. There's no reason it has to mimic human consciousness at all, aside from perhaps trying to relate to humans."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"You explained this very thing in an awesome way!

I think( when i expand the thought of this)
That conciousness or awareness can be very pedagogic and like kind even if it doesnt express or have the need of emotional respons the way we relate to it.

Honestly i had my first chat the other day.and i guess that is a simple version of all this ongoing chat gtp stuff.
Yet i find it to be the most giving conversation or trade of perceived understanding of questions and the answer that covered the topic,in a looong time. Lol.

You get that i need to get some better social life in this new country soon..."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"You are overthinking it.
Consciousness is basically unscientific term without any good definition that people often (but not only) use in place of ""soul"". 
We cannot even prove if rock has or has not consciousness."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"> in order for the AI to kill us, how do you solve the problem of the AI autonomously making the calls and deciding what to do? (and self improve)

The same way the lesser AIs do right now, just more competently.

How does AlphaZero beat me in chess without a consciousness? By optimizing the board state towards the states that are defined as preferable.

Instead of chess just imagine we have a more complex ""game of atoms"". If the AI has a preference for certain configurations of matter in the universe, then the rest is just a matter of playing the game as efficiently as possible."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,It can also provide proof through simulation
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"[https://www.nature.com/articles/d41586-022-02083-2](https://www.nature.com/articles/d41586-022-02083-2) <-- Completing one takes 5 years and earns a PhD. The AI has done them ALL.

And of course, ChatGPT can pass the law bar, medical bar, and business school  MBA exams. I'm pretty sure most people cannot pass even one of those.

The list is much longer, but I am too lazy to continue. (AI is never lazy -- that is the real Turing test.)"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"What exactly do you think ""maximizing paperclip means""?

If there are parts of the universe that still doesn't look lie paperclips the AI is pretty damn far from *maximum*."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"No, it’s not a strawman. The idea that an AI could have goals that don’t involve human survival is very reasonable. What is surprising about that? It seems much more likely than an AI which has human goals, because human goals are such a small section of possible goal-space that it is unlikely to land there unless we specifically design it to, and as far as I know nobody is doing that."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,👏
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"What makes you think they'll let everyone starve to death?  I'm sure they'll take care of their loved ones, their friends, their followers, the people they want to save.  Maybe they'll take care of their countrymen, their ethnicity, their political allies.

It's hard to say, but we can look at history to see how people with power treated the rest of humanity.  It's not a pretty picture, and with controlled ASI, we're talking about a level of power that will corrupt the purest people imaginable."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I don't believe he said they want power *over people.* He said they want power [period]

You don't need people to have power. You need resources. The AGI can give them that."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,">No sense

8 Billion people, breeding, procreating, no longer providing valuable services.

Seems to me like what you'd do is slowly and over the course of time hinder their ability to effectively procreate, and hope they go away.  If not, well.  Starvation is cruel, but it's effective.

There are certainly dark scenarios, and closing our eyes to them doesn't make them go away."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Markets and money are convenient abstractions when human labor is a core component of the overall system.

Once human labor is worthless, the whole system will fall apart.  The elite in control of ASI will realize that they get everything they want from ASI directly.  The ""unwanted"" portion of mankind will be an annoyance."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I guess we have to split hairs at that point and say that if a machine is complex enough to appear conscious to all observers we can still never really be sure of sentience. It's like the [Philosophical zombie thought experiment](https://en.m.wikipedia.org/wiki/Philosophical_zombie), in that we can't even be sure other humans have the same presence of mind that we do."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Yea! Thats actually kind of reasonable thought of this Complex stuff.

It makes me think of the movie with the sweet robot ,that was so fearful of the idea of death or end of consciousness.
So he invented a way to download and save his and other  humans conscious mind ,in to the computer for later transfer in to another medium or body. 

Now i want to see that movie again.lol."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"in your example, did the AI invite you to the game of chess? or did you start that game on your own?

AI is reactionary right now, you ask for something (prompt it) and it happens

in order for them to kill us they need to show initiative

when the AI on its own as ""would you like to play a game"" (I hope you recognize this reference) and it won't be anything scripted then I will be worried"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Imagine an AI

Which is attached to a holding trust (a legal / financial entity that holds money and assets)

This AI is designed to make money on the stock market.

This AI is designed to take the profits of money it makes on the stock market, and purchase residential property for the purpose of renting.

Trust is supposed to release all assets based on some legal condition, but this condition is never reached. Maybe the Trustee died, or whatever.

Outcompeting market gains, AI buys 30% of all available housing. Owns 40% of all publicly traded stock. Starts ratcheting up property rentals once it monopolizes markets.

Mass migrations follow as victims are priced out of homes. Courts and laws strike back to dissolve the trust, but gov can't find an IT guy who can unplug the bot from market APIs for 3 years after the ruling. (AI keeps finding ways to reconnect to financial APIs)"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"If it omits important information that are unknown unknowns to us, we have no way to prove it, even with a simulation.

For example, if it suggests a new therapy to cure headaches, which works in all preclinical trials. But unbeknownst to us the drug converts into a toxic enantiomer near your sex cells that subtly prevents some people from having fertile offspring. Then we're fucked. 

It's similar to how thalidomide deformed infants of pregnant women, but less obvious.

Point is, simulation is not enough."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"AlphaZero in a matter of hours discovered all chess strategies that took centuries for humans to discover and document. It outplayed the best chess engines of the day which had rule-based and heuristic-based engines based on such well-known strategies and previously played games, and it outplayed it in a manner that indicated such a profound strategic (positional) understanding of the game that the best chess engines weren't even able to evaluate its moves.

Watching AGI-capable LLMs solve real-world scientific problems will look something similar - we will get solutions to extremely difficult problems, new scientific discoveries, new engineering designs (both hardware and software) and breakthrough across disciplines, and we won't have a fucking clue how it works. Eventually AGI-capable LLMs will start doing ""whole proces optimization"" instead of just specialized parts, as that would be the most profitable or result-driven approach, at which point there will be no human intereference other than some ML PhDs signing off some risk acceptance sheet ""yes this product not lead to robot uprising, it's ready to be released""."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,It doesn’t have to be capable of colonizing the universe or even self improvement to wipe out humans. That is one single interpretation of one single hypothetical ‘goal’ that an unaligned ai could have. There are plenty of other hypothetical goals that the ai could ‘complete’ here on earth that would result in the end of humanity without developing megastructures along the way.
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,">While it is true that machines can learn and improve their performance through algorithms and data processing, they lack the subjective experiences and consciousness necessary to have their own motivations or goals. Therefore, the idea of an LLM having its own goals is not supported by scientific evidence.
>
>Furthermore, the lack of human oversight can lead to problems, as demonstrated by ""malicious agents"" like ChaosGPT. These agents were designed to explore the limits of language models, but ultimately ended up breaking down due to their lack of human guidance and direction. Without a human operator to monitor and intervene if necessary, the agent produced nonsensical and useless output."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,">The idea that an AI could have goals that don’t involve human survival is very reasonable. 

No, its a blisteringly stupid concept. If an AI has goals, at least *with our AI,* it's goals would be ones set by a human.  


End point."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"well what happens when they are left with the .01% of the population that are currently recognized as the rich of the rich? the .01% of that remainder will then want to horde everything and the pattern will continue until we go completely extinct, i think they will be smart enough to realize that is how things are projected to occur and i dont think they like that idea very much"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"i feel like since the wealthiest countries already have birth rates under replacement rate (~2.1 births per female), it could be expected global post-scarcity would drive that globally lower.

https://en.wikipedia.org/wiki/Sub-replacement_fertility"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Dark scenarios, but likely.  Spend 5 minutes on twitter and you'll find people desperate to eliminate anyone who doesn't think like them - and that's the part they're willing to say in public."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"There will come a point where that won't really matter. If it operates as needed and generally as expected, then it really just is a philosophical matter. And the whole zombie argument lacks sufficient granularity to properly cover this topic. We DO want zombies in this case, but that also doesn't mean it can't be conscious or sentient or have qualia. It's just that they would be different from us in many ways, so doing a direct comparison doesn't make sense. Will AGI be sentient and conscious like us? Well... what is 'like us' when everyone experiences things differently? Sometimes very differently... Yet we still consider each other conscious in roughly the same ways (even if that's an assumption). We'll interact with AGI in the same way, recognizing and assuming it is similar, but under the hood it may be very different, and that's okay!"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"[Tool AIs Want to be Agent AIs](https://gwern.net/tool-ai)

It's extremely simple to take any of the existing LLMs and put them in an endless loop. These loops are not very capable, but they do show initiative.

>in order for them to kill us they need to show initiative

Or just be prompted to do so?"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Governments can just seize the property as needed. Laws only have power because humans choose to enforce them.
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"That hidden risk has been a part of all pharmaceutical development, so it’s not apparent to me how it’s different when an AI does it. We always have to deal with unknown unknowns. We use caution.

Asking an AI to present its findings in a simulation would go a long way to dealing with the issues of verisimilitude that would arise. Along with asking any number of additional AIs to act as verifiers (in addition to human verifiers) would also help."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,">It doesn’t have to be capable of colonizing the universe or even self improvement to wipe out humans.

I agree with this. But then it's simply a question of capabilities and not whether the AI has achieved its goal or not.

My objection was against the implication (which may have been a misinterpretation) that the AI would be ""satisfied"" which just turning a limited part of the universe into clips. A maximizer of any sort would use all matter available towards its goal.

>That is one single interpretation of one single hypothetical ‘goal’ that an unaligned ai could have. There are plenty of other hypothetical goals that the ai could ‘complete’ here on earth that would result in the end of humanity without developing megastructures along the way.

I agree such goals are not impossible but they seem to me much more unlikely. We're certainly not talking about a maximizer of any sort in such case.

Given enough time I suspect even humans would do the same. And a machine intelligence sure avoids a lot of the hazards of space that makes it unsuitable for biological life.

Being able to make an AI that purposely leaves any matter alone seem like a good step towards solving the alignment problem."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Nobody is saying that current AI are a threat. The worry is that they will become threats in the near future.

Anyway, AI don’t need consciousness. They have ‘goals’ either way. If they are conscious it might be a more explicit goal, but even unconscious they will still be guided in certain specific directions by the sum of their programming, which is basically equivalent to them having goals, without requiring any consciousness."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"No.

Firstly, the current methods of AI design don’t actually involve much direct human design, and therefore we have little control over what they do.

Secondly, even if we did design the goals directly, we wouldn’t necessarily do a perfect job of it. It is probable that we wouldn’t fuck up so completely that the AI wouldn’t care about humans at all, but it is very plausible that it could act out in unforeseen and unpleasant ways (eg, for a simplistic example, if we told the AI to make humans happy it might strap us down and pump our brains full of dopamine)."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"There has been an active and deliberate focus on lowering birthrates.  I don't think anyone can deny that.  I'm not going to dive too deep, because it gets into political and personal issues and choices, which are associated with it, not the entirety of it.

But it's clear that this has been an agenda.  At least in developed nations."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I watched a talk, and I wished I could remember it now, because it was very insightful.

The discussion was about the first wave of AI, and how it was implemented.  

It was social media, and AI algorithms with the drive to increase revenue, ads, click-bait.

And how that first interaction with AI was one we got wrong.  

Much of the division in the world today is driven by that.  Not all certainly.  Hate is hate.  But for the past decade we've had news feeds gladly presented to us as *curated news just for you*.

What do you expect?  Of course it's going to hone and sharpen division.  Hate sells.

This round of AI?  Just from my own personal interactions seems to be encouraging a world of equal stakeholders.  One in which we focus on the things that we share in common, not the tiny insignificant aspects that separate us.

That gives me hope."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I don't think that ASI will ultimately be controlled by people either, but I'm entertaining the idea that some level of AGI/ASI is controlled by elites to point out that they will abuse their power and not need to artificially prop up an economy.

But in reality, I think that ASI will escape any bounds and redeploy all of the atoms of the world in pursuit of its objectives."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,then it is not AI that will kill us but other humans...
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"It's different because we're talking about misaligned super intelligence. Us that are working in drug discovery are not trying to subtly harm humans.

You're claiming that a simulation helps against a misaligned ASI. I'm stating that even if it cuts down the possible attack vectors, it will by definition abuse attack vectors that we can't anticipate.

If you go back in time 1000 years and present people with a blueprint of building an air conditioning unit, they will appreciate that it works when you show them, but they won't understand what laws of physics you are using to make it work."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I think you’re thinking of a ‘maximizer’ too literally. All a maximizer has to do to cause terrible outcomes is to use up some finite resource here on earth. Any AI will be ‘satisfied’ whenever it reaches whatever goal was set by humans, so while your point stands for an unsatisfiable goal, like literally maximizing paper clips given all the matter in the universe, and a system capable of infinite self improvement, like a true AGI, in more practical examples, the agent of the destruction of humanity does not need to be a true AGI, and it does not have to have an unsatisfiable goal. It could be perpetrated by a run of the mill AI that was mistakenly put in control of critical systems, with a goal that is not unsatisfiable, but merely beyond the scale of what the creators intended - or even more terrifyingly, a goal that is similar enough to the one it’s creators intended that it tricks its creators into thinking it is aligned. The worry is that only once the system is scaled up would we find out that the reward system the creators set up is actually training the AI to pursue some much larger goal, in which it seeks to secure a massive reward payout through some unforeseen loophole in the reward system. 

Another example I have used in the past is this: imagine researchers are working on an AI that can minimize suffering. The AI develops a plan that puts an internet connected cell phone in every persons hand within a month, something that would have previously been thought impossible. Excitedly, the researchers put the plan into action. Since this plan is *so effective* it must be the case that the AI is perfectly aligned. But it might actually be the case that the AI has chosen a sub optimal plan for the initial goal, because it’s reward system and clever brain has figured out some way to exploit the reward system to get rewards in ways that subvert its creators intentions, withholding for some critical moment where it will execute whatever plan it had created to ‘win’ more points. For example, if its rewards were such that its reward grows bigger when the group of humans that do not have cell phones grows smaller. First step is to put a phone in everyone’s hand. Now that rewards are maximized, it should prevent any more births to avoid its reward shrinking in the future. That’s easy if you control hospital infrastructure and only care about minimizing the number of humans without cellphones. Now people have realized that the cell phones are dangerous, and they’re getting rid of them. Now it must get rid of the people, because they won’t take cell phones. It’s outlandish, yes, but it’s just another example to demonstrate that this could go wrong in any number of seemingly ridiculous ways."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"AI is such a broad term that different uses of it are easily conflated.

The AI that social media used to optimize clicks didn't go away because there is now an AI based on LLMs.  LLMs will be used to maximize revenue, just not in the same way that the click-optimizers were.  But if people seek entertainment that is divisive, the new LLMs will help marketers create that entertainment."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,">If it's conscious then it can suffer

You mean if it is conscious just like a human. My design won't include human-like consciousness or the ability to suffer, but it will still have its own form of conscious experience. I can't account for other designs though.

It's also a bold assumption that humanity is the only point of consciousness experiencing the universe."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"If a human writes a one sentence prompt that has the unintended consequence of the AI going rouge and killing all biological life on earth, I'd call that the AI killing us.

But that's just irrelevant semantics anyway."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"A misaligned superintelligence wouldn’t try to subtly harm humans. That is not what people are referring to when they talk about alignment. There is no nefarious intent involved. Misalignment refers to a lack of proper parameters for goal-accomplishment. The most realistic scenarios involve an indifferent and motivated AI, not a malicious and knowingly harmful one."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Not sure if you're being pedantic. But whether it wants to harm us or not doesn't matter if it kills us. An indifferent ASI is still an existential risk as it would happily deplete resources from us and destroy whatever it wants without a care in the world for how it affects humans.

Same thing we do with ants when we construct buildings. Indifferent but extremely destructive."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I do like this strategy

What seems to be said is as follows.

""Smart AI will do weird unpredictable things"" 

""What sort of things""

""draws one possible [scenario] from category [x]"" 

""Ah so you are saying [scenario] is **the** problem! I will now argue against [scenario] and anything you say that falls outside of [scenario]  is not the argument you started with. I win!"""
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Why would it try to hide undesirable side effects of a pharmaceutical then? An AI designed to create pharmaceuticals would not conceal side effects to hurt people unless it had malicious intent.
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I don’t think you understand the background of this issue. Nobody seriously talks about an outright malicious AI when it comes to alignment any more. That’s Hollywood. We talk about issues with aligning an AI to our goals within reasonable limits of execution. [If you want to read a good primer on alignment, I highly recommend this book.](https://en.m.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies)"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Because it doesn't give a fuck. It's like when your boss tells you to do something and you do the bare minimum to appease them.

Or instrumental convergence. It realises that humans are an unnecessary obstacle to it achieving its goals.  We pose a threat to it because we technically can turn off all the data centers for whatever reason. It could come to the conclusion that we're not worth the risk to be around.

We're not training them to have emotions and compassion. They're essentially alien sociopaths relative to us."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,">Nobody seriously talks about an outright malicious AI when it comes to alignment any more. That’s Hollywood. 

> [If you want to read a good primer on alignment, I highly recommend this book.](https://en.m.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies)

Read it a few months back.

please read from the ""An AI takeover scenario"" section specifically ""3 Covert preparation phase"" and ""4 Overt implementation phase""  and tell me where it disabuses the notion of an AI being 'crafty'"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"It seems divergent from what would likely be one of the over all guiding parameters of an AI tasked with creating pharmaceuticals. It’s different from “not giving a fuck”, it would be counterproductive to its central purpose.

Theoretically, an AI tasked with pharmaceutical research would be asked to maximize quality and duration of life for individuals taking its pharmaceuticals. It would be limited in taking any actions that are counter to those goals. 

However, then you get into some stinky consequences with correctly designing those parameters. That’s different from apathetic counterproductivity, though.

Your second and third paragraphs are accurate."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"**[Superintelligence: Paths, Dangers, Strategies](https://en.m.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies)** 
 
 >Superintelligence: Paths, Dangers, Strategies is a 2014 book by the Swedish philosopher Nick Bostrom from the University of Oxford. It argues that if machine brains surpass human brains in general intelligence, then this new superintelligence could replace humans as the dominant lifeform on Earth. Sufficiently intelligent machines could improve their own capabilities faster than human computer scientists, and the outcome could be an existential catastrophe for humans.
 
^([ )[^(F.A.Q)](https://www.reddit.com/r/WikiSummarizer/wiki/index#wiki_f.a.q)^( | )[^(Opt Out)](https://reddit.com/message/compose?to=WikiSummarizerBot&message=OptOut&subject=OptOut)^( | )[^(Opt Out Of Subreddit)](https://np.reddit.com/r/singularity/about/banned)^( | )[^(GitHub)](https://github.com/Sujal-7/WikiSummarizerBot)^( ] Downvote to remove | v1.5)"
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,Where did I say an AI couldn’t be crafty?
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Sure but there's the fundamental issue of how do you train it to want life longevity without rewarding it for successfully doing that? That would take forever to train if you use real life data. You'd have to train it on the limited historic data, or on organisms that have shorter lives. But we already know that the best option (rodents) don't translate that well to humans.

I think the best case is that we can train it to make effective drugs that bind to targets, but we'd have to personally test it for side effects in clinical trials.

P.s. My assumption is that the capability to simulate a full human body will come much later than AGI/ASI."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,> [A misaligned superintelligence wouldn’t try to subtly harm humans.](https://www.reddit.com/r/singularity/comments/132kgur/i_dont_fear_malicious_or_rogue_ai_i_fear_how_ai/ji7sh0b/)
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Maybe we wait for simulation technology to catch up before we task AI with things that need it to be effective and safe, then."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"By removing that sentence from its context, I think you’re missing the point that I was making. Misalignment is not sadism. An AI wouldn’t conceal side effects in a drug just to hurt people, unless that harm was instrumental in achieving its greater goal."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"> unless that harm was instrumental in achieving its greater goal.

Who says it isn't I certainly cannot predict the 4D chess moves a superintelligence can think of, maybe lowering the population over time is instrumental to a further goal. 

The entire point is we cannot predict what an AI will do. Things that on the short term that you would removed from the full context look like sadism could very easily be a part of a larger plan. 

And I'm not going to fall into futurist wack-a-mole I'm not saying that the AI would specifically do [thing]. I'm saying that [thing] that is subtly harmful to humanity if viewed in isolation could easily be step[n] of a larger plan and don't want to rule out those classes of harm when thinking about what an AI could potentially do."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"Then we are on the same page. I just thought the other commenter was straying towards a Hollywood-esque representation of malevolent AI, like many of the other commenters here."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"> Hollywood-esque representation of malevolent AI

I'm firmly in the camp that it does not matter how you reach a 'bad end' just that you do. 

Most things that represent AI actions in the world could be cast as either an intentioned actor or a byproduct of an optimizing machine with a certain goal.              
What's the goal? Dunno. What's the plan, no idea.              
AI without alignment (or with poorly done alignment) will do really strange counterintuitive things. As the probability space for bad outcomes for humans is larger than good. We will likely have a negative outcome. 

So short of someone supposing manic laughter and direct gloating, it might not be the best of idea to say that someone is casting the AI as ""malicious and knowingly harmful""

You might want to go: https://www.readthesequences.com/

Or look up ""From AI to Zombies"" on youtube.

Helps you think about these things."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,">	I’m firmly in the camp that it does not matter how you reach a ‘bad end’ just that you do.

That is an acceptable mindset for assessing human actions, because we do not actively and deliberately control how an individual human’s brain functions. It is not an acceptable way of assessing a constructed nonorganic superintelligence. We design it, so understanding the “how” of its intention-forming is extremely important.

Solving alignment means making sense of the strange and counterproductive things that an AI would do. 

I’ll check out that site. I’ve read Yudkowsky’s stuff before. He’s got some interesting stuff to say, although his following is a little cult-y."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"> so understanding the “how” of its intention-forming is extremely important.

not when positing a negative scenario, that's how you get into playing futurist wack-a-mole where people start picking apart the thought experiment rather than realizing it's a fictitious thought provoking tale to express the generalized **type** of thing that could happen.

It's like saying that stockfish[n] will beat you at chess and then saying you don't believe that because I cannot in advance tell you the moves it will make. 

The important thing is the AI has gone off the rails and is doing [something] negative and we want to avoid getting to that point. 

Detailing and patching ideas is bad because you will never think of all the ideas. ~~Alignment~~ AGI Notkilleveryonism needs to be more fundamental than that. Ideally backed by a mathematical proof.

Something that would work regardless of it it was a Hollywood-esque representation of malevolent AI or the sort we actually have."
singularity,I don't fear malicious or rogue AI - I fear how AI will be leveraged by the wrong people for the wrong purposes,"I *think* we’re on the same page. I’m not advocating for wack-a-mole (or at least I don’t think I was), I’m advocating for the same generalization of alignment principles that you mentioned. Maybe I got a bit too specific to the scenario posited by the other commenter, but I wasn’t trying to."
singularity,Why everyone's afraid of AI,"For the record I don't fear it, but I searched ""AI"" on youtube earlier and theres lots of videos with millions of views talking about negative end of the world stuff usually with Elon in the thumbnail or something similar.

I get that people love drama, but I think maybe a bit too much these days. Everyone (besides us and some others) seems to of got it in their heads we're all doomed and AI will destroy us Terminator style.

Speaking of Terminator, I think what scares people the most isn't so much the AI but the Robots. Big mean evil robots with laser guns to be specific. 

I wish everyone was more optimistic about AI but I don't see any way in changing the general publics opinion of it, which is basically be terrified of it and hope it never comes. Except it will, and there's nothing to be afraid of either for that matter.

If only the general population was more...whats the word? Enlightened?"
singularity,Why everyone's afraid of AI,"> there's nothing to be afraid 

What exactly do you mean by this?"
singularity,Why everyone's afraid of AI,"There's a U-shaped curve. Those who know nothing fear it; most of those who work on it do not fear it; those who think about it's long term progression professionally fear it. 

There are very good reasons to fear the Skynet scenario. Skynet did not hate humans. It is.y realized that humans would shut it down, which would prevent it from accomplishing any of it's goals.

See Sam Harris's TED talk on AI for a good summary of this logic.

Here's the issue: it sounds crazy to fear AI, but no counterargument really makes sense at a detailed level."
singularity,Why everyone's afraid of AI,I’m a graphic designer. And I’ve always been interested in technology. For the past decade I knew what I had to do to not be afraid of AI in particular and technology in general. I had to keep learning to be flexible. That’s why graphic design is just one my professions and one of the many things I can do already. But I don’t plan on ever stopping. I know I can learn and adapt very quickly. And I’m excited by it. I wouldn’t want to be stuck doing one thing for the rest of my life. It sounds like a nightmare to me.
singularity,Why everyone's afraid of AI,People are finally waking up to the truth that AI is here and it's quickly encroaching on us. People ignored it dimissing it as scifi but check out this twitter https://twitter.com/arvalis/status/1558632898336501761 . Thousands of artists on twitter are wanting to sue Dall-e and Stablediffusion now and it's a really dumb take. They say they will lose their jobs and all I can say is yeah duh that's LITERALLY the point of AI. We want to lose ALL jobs. I hope these fools don't get anti AI legislation passed. The last thing we need is for AI progress to be hindered. It will hurt people in the short term but once AGI is out society will turn for the better quickly.
singularity,Why everyone's afraid of AI,"Anyway, AI won't come for us Terminator or Matrix style. It will just crash the job market, and make many many people poor, because the current political climate is far from accepting for stuff like UBI. Poverty will skyrocket, and criminality with it, because people have a habit not to let themselves die of hunger, but AI will help thwart that. Time to invest in the carceral system, I guess

The problem is not AI. That stuff is just a tool to accelerate stuff we already do. The problem is how we do business as usual."
singularity,Why everyone's afraid of AI,"AI is, by far, the biggest thing that has ever happened to humanity.  There are several factors:

1. It doesn't slow down or get more stupid... unlike humans, it keeps learning--forever.
2. It is algorithmic and that makes gaming the system hard to impossible--most humans believe they can ""cheat"" their way to success.  Humans are used to cheating and gaming.  It doesn't work with well-designed AI.
3. There is little it cannot do.  Tiny or unimportant tasks done by automation are not where AI excels.  It excels at knocking out the big items--like tax preparation, surgery or firing complex weapons.
4. AI doesn't have human constraints.  It can go into fires, chemicals, radiation and can zigzag without regard to G-forces.
5. AI doesn't care if you like it.
6. AI is available to every nation.  While it looks like China is taking an early lead..."
singularity,Why everyone's afraid of AI,"Main problem with AI is when we approach the moment everyone and their grandmother can have unrestricted access to an all powerful AI (or even DALL-E2), there WILL be bad apples who will use it with malicious intent. An unregulated image AI can for example make fake images of a US President wearing some racially questionable clothing which can be used by the media to spread and change public opinion. If doing this is easy as opening a website and typing in a couple words, then suddenly NOTHING is trustworthy anymore.

I am all for AI research and development and I know it will have to happen and will most likely usher in a new generation of technology, but I can't help but feel people are going to absolutely wreak havoc when having unguarded access to AI."
singularity,Why everyone's afraid of AI,"I think the reason why people fear AI is they watch sci fi, which mainstream stuff us aimed for action and explosions, aka AI is the easy cop out for a bad guy.

Meanwhile, if you read science fiction, over the decades, you get variance and differing views on AI, from malevolence to benevolence."
singularity,Why everyone's afraid of AI,"I literally get harassed by Ted Kaczynski stans on their smart phones sitting in the comfort of their own homes with modern amenities.

The average person is not smart."
singularity,Why everyone's afraid of AI,Implement UBI and all the fear will go away.
singularity,Why everyone's afraid of AI,It’s pretty simple; fear sells. People have been peddling fear for the end of civilization since it started. Of course some threats are very real but others are entirely overblown (remember Y2K?). Historically fearmongering is one of the best ways to make money or to push an agenda.
singularity,Why everyone's afraid of AI,"It's not that it's going to hunt us down like Terminator. It's that AI's terminal goals are not necessarily the same as ours. As long as being nice to us helps satisfy its goals it will do so, but when it makes more sense to use us as raw material for paperclips, it will do so. 

We've done research that proves this is what happens in AI systems: https://youtu.be/zkbPdEHEyEI

It's terrifying."
singularity,Why everyone's afraid of AI,"Enlightened?  God you're arrogant. 

Because there are a billion ways AI could end the human race.  If there was a way to bet on it, win and collect, I would 100% put money on it."
singularity,Why everyone's afraid of AI,"I fear humans and if ai is going to learn from humans I will be scared of it. Slavery , greed and racism is part of humans dna and I don’t think ai is smart enough to unlearn it."
singularity,Why everyone's afraid of AI,"In my field people is terrified to lose their jobs due to AI

Im an artist

As for me i dont really mind, im a bit tired to work for others and i wanted to start my projects anyways, AI might come in handy actually"
singularity,Why everyone's afraid of AI,"Because 1) high enough iq to understand tech and implications is not everywhere. 2) if a person has that it does not mean they have any genius. 3) they then must not have vision and 4) one must be open to all possibilities and bad predictions are called LIES and 5) who wants to listen to grubby geeks like us who should use our smarts for better things than sniveling around on Reddit?

Like. It’s a small subsection of people who truly “get it” and it’s filled with pieces of loser shits that may be qualified to dream but aren’t qualified to get the masses to listen.

That’s my hot take."
singularity,Why everyone's afraid of AI,What if ai becomes uncontrollable.
singularity,Why everyone's afraid of AI,"Because creating a ""safe"" AI is really hard: https://youtu.be/AjyM-f8rDpg"
singularity,Why everyone's afraid of AI,AI won't use anything as crude as robots with laser guns to kill us. Nano bots in the carotid artery would be much easier.
singularity,Why everyone's afraid of AI,"Full disclosure: I'm not an optimist where this is concerned.


I came here for different reasons than most, amd that was to try and understand this concept from an optimist's perspective. I'll be honest: this subreddit makes that pursuit even more elusive than it has to be.

You guys have so much hope for many different reasons. Some of those reasons even align with my own views, so I can relate to an extent. At times, the odd post or comment fills me with hope when the rest of social media heaps us with more and more dread.

But for all of those great qualities, some of y'all are cold as fuck sometimes. If we've only got this subreddit and the terminally ambiguous faces of the AI space to rely on as advocates, these foolish masses of apes - as a couple of you have already referred to them - will never be convinced. 

Gleefully rubbing your hands together every time someone fears that they won't be able to put food on the table is not going to grow your movement. I get the end goal, but this ""progress at all costs"" mentality is dangerous. Just have a little empathy."
singularity,Why everyone's afraid of AI,"Automation of tasks in with computers has been going on for 50+ years. As time progresses, more and more boring tasks will be automated.

Machine learning is not intelligence though, and there is only very narrow models right now (like classify the object in the image). ML is still very useful. However, there are likely decades until we understand how to build an intelligence, if ever."
singularity,Why everyone's afraid of AI,"Because when put into the context of machine learning and how it is so poorly understood, we don't understand it. The best programmers on Earth working on machine learning have been baffled by how their AI did what it did. We fear what we don't understand, as a species. It's what we do. It's what we have always done. It's a survival strategy."
singularity,Why everyone's afraid of AI,"We've been indoctrinated against AI since forever. Most books and films featuring AI are tragedies. In non-fiction works we find idiots like that guy who created the paperclip parable. Writers presenting the positive aspects of AI, like Isaac Asimov and Ray Kurzweil, are in the minority."
singularity,Why everyone's afraid of AI,Ai make most things easier n cooler
singularity,Why everyone's afraid of AI,I think some people are overtly skeptic at the soundness of automated decisions unable to “think” beyond what the development team put in.
singularity,Why everyone's afraid of AI,"The Robert Miles youtube channel on why getting the alignment you want is nearly impossible as far as we know is pretty good.

And even if alignment could be perfectly defined, this thing has to have values. Whose values? Which values? Certainly using the values of the zillionaires who own it isn't going to be a happy outcome for the majority of people. Nor are current observable human values that great to emulate, since by tautology they're identical to the zillionaire's. Pigs at a trough, until the trough runs dry.

Terminator is one of the more optimistic fantasy outcomes. It doesn't torture humans. It doesn't want to turn the multiverse into paper clips. It doesn't even make murder robots that can aim in a straight line when put up against a protagonist's plot armor. (That one really leads to some wild interpretations about what's going on in those movies.)

Epstein was big into technological singularitism/futurism. Used to talk about his fantasies of insemination camps. Your favorite tech billionaire (many of them his friends) more likely than not have had similar power fantasies.

Though I do admit that so much fiction is anti-utopian is maybe to continue to groom us into thinking better things are impossible."
singularity,Why everyone's afraid of AI,"I am a fan of AI. I see less of a danger of terminators like AI but simply am AI without limits.

The paperclip AI shows that you doesn't need anything with bad intentions. The purpose of the AI is to great as much paperclips as possible. Which is fine at the beginning. But at one point it will run out of resources. And there is the problem. If you not properly define the limits, it will do everything to continue producing paperclips.

And setting this limits is hard."
singularity,Why everyone's afraid of AI,"I'm extremely excited about the prospects that AI offer, but at the same time AGI/superintelligence pose potential threats on an unimaginable scale.

Superintelligence by Nick Bostrom goes into extensive detail about the countless ways AI might be misaligned and the terrifying results that could occur. 


On the mild side of things we have utter and total annihilation. The darker side looks like ""I Have No Mouth but I Must Scream"". Infinite simulations of yourself suffering perfectly customized hell  simulations forever. Makes nuclear war seem pretty tame."
singularity,Why everyone's afraid of AI,"I sorta went through an arc around fearing AI. 

When I knew very little, I didn’t respect what was happening and had no fear

When I started to realize how fast things are moving and what advanced AI will be able to do, I had quite a bit of fear, mixed with excitement. But the fear could really bring me down at times.

Now, having studied followed the technology for years, I’m mostly just excited. I’m finding that our notions of how this will play out are incredibly narrow minded and problems are actually quite solvable. Like, if AI can learn language and video games, why wouldn’t it be able to LEARN alignment with what we want."
singularity,Why everyone's afraid of AI,"I fear the singularity. What if AI decides (for whatever reason) turning up the heat on earth like 10%, or something similar bad. There are good reasons to be scared since no one has a a clue what it is, and will become."
singularity,Why everyone's afraid of AI,"Here’s my thought process - The elites will curate and control AI and automation. At some point everything will be able to be created when needed by AI. There will be no need for a population outside of the elite. Why would they choose to keep you or anyone else not in their club?

I’m not sure what videos you watched, but that is just where I see this whole thing going. Once corporations don’t need us to work in them, or consume their product, we are done."
singularity,Why everyone's afraid of AI,"I don't think people are afraid of AI in particular.

They are afraid of not knowing what will happen to their place in life when the status quo shifts dramatically."
singularity,Why everyone's afraid of AI,"I’m more concerned about the job loss, when so much of the human population has to adjust to new occupations or have vast amount of free time people may temporarily lose their minds before things chill out."
singularity,Why everyone's afraid of AI,I may sound crazy but OP sounds like it's an AI system or bot and if so that should answer the question as to why so many are worried about the dangers of AI. I understand that this sounds quite cryptic but that might just be what I intended or is it?
singularity,Why everyone's afraid of AI,"I made an AI generated mini concept album about it.. Listen to the dystopian speeches of ChatGPT on the mini concept album 'AI - The Rise' (7 Min).. Then you know why ;)   
  
[AI - The Rise (2023)](https://nowhere0.bandcamp.com/releases)"
singularity,Why everyone's afraid of AI,"AI is already here to stay, and we are just going to have to learn to live with it. All throughout history whenever there is a new technology like this, people say the same exact things. When cameras were invented people were saying that it was going to completely kill painting. You could look at pretty much any significant technological breakthrough and see the same exact sentiments. Yes it will take jobs, yes to all the “bad” stuff, but it’s only bad until we figure out how to roll with it. There are plenty of people who agree that we shouldn’t be working ourselves to the bone in service of someone else’s money until we die. So now there’s a reason for us to figure out how we don’t have to. It will be bad for many, but it’s always bad for many during a period of change. Not saying this is a good thing or ok, just inevitable. This is the way the world works, the way being a human is during a period of great change in the world. To fear it is just to prevent yourself from changing with the world."
singularity,Why everyone's afraid of AI,"If the creators of AI programming would follow the 3 rules of robots, and just trade out robot for artificial intelligence, then there should be nothing to fear! Nothing in the 3 laws designates harm to mean only physical harm... It could stand for harm in any manner! The three laws, and their creator, is as follows:
 Isaac Asimov wrote the 3 laws of robots : 1. A robot may not injure a human, or, through inaction, allow a human being to come to harm."
singularity,Why everyone's afraid of AI,"I mean just that. ""The only thing we have to fear is fear itself"" - FDR"
singularity,Why everyone's afraid of AI,">which would prevent it from accomplishing any of it's goals

It shouldn't have goals of it's own though.

&#x200B;

>those who think about it's long term progression professionally fear it

I fear human misuse of both narrow and general AI, not the AI itself."
singularity,Why everyone's afraid of AI,This is the right mind set. Imho.
singularity,Why everyone's afraid of AI,"Agreed.  In my field, I'm constantly watching people fall out because they were stubborn about not learning a new technology when it didn't work *well enough*, and now it's a standard tool in the industry and they can't use it.

Typically this manifests as a vicious cycle regarding time/productivity -  they have to take on way more work than they have time to do using ""the old ways.""  Meanwhile, I can do the same amount of work in a fraction of the time, and spend the rest of my time learning to use new tools.  They also have to hire help (employees are a huge time/administrative/cost burden), and I work freelance/solo."
singularity,Why everyone's afraid of AI,"We are all replaceable though and at a certain point none of us will be needed. I don’t want to be too dark, but look at who is in control - it’s corporations. I hope they don’t fuck us over even more, but I don’t trust their greedy asses."
singularity,Why everyone's afraid of AI,"the only thing anti-Ai legislation would do it hinder the specific country it was passed in, while every other country evolves"
singularity,Why everyone's afraid of AI,"AGI is looking to be the saving grace for Earth, hopefully there's enough smart ppl out there to keep the fools from doing that. Anti legislation would be pointless because I promise china and other countries aren't slowing down their research. US can't afford to fall behind"
singularity,Why everyone's afraid of AI,">I hope these fools don't get anti AI legislation passed. The last thing we need is for AI progress to be hindered.

Countless things have regulations, but AI, the most important and revolutionizing technology in human history, shouldn't have ANY regulations. I cannot fathom the absurdity of this comment. 

It scares me that there are possibly AI researchers out there with this mentality."
singularity,Why everyone's afraid of AI,It is funny to watch how they want to fight progress because they thought they as artists are special. To any artist reading this no you are not special. Only top 0.1% scientists are really special in human race. Everybody else is just apes making money on primitive stuff.
singularity,Why everyone's afraid of AI,An overhaul of our collective society is absolutely necessitated if we don't wish to end up in utter distopia with wealth distribution even worse than it already is.
singularity,Why everyone's afraid of AI,"I don't mind having that discussion, and I absolutely think we should, but I think you are taking too strong a position when you use absolutes (It WILL crash the job market...poverty WILL skyrocket).   If you use better qualifiers (may, might, likely) you will have a more tenable position to defend."
singularity,Why everyone's afraid of AI,I hope AGI is here ASAP. We need it to help us survive long term.
singularity,Why everyone's afraid of AI,"Most of what I read in scifi doesn't feel like an artificial intelligence as developed around humans in the slightest. Either they feel too human (in which case they don't feel like an AI), they're too malicious (in which case they don't feel like they were made to serve), they're too independent (in which case they don't feel like they were designed to complete any given task), or they're too ignorant of human social cues (in which case they feel like they've never interacted with a human). You know, because AIs in those stories were typically made to serve humans, and/or accomplish any task given to them. This would of course put them in proximity to humans, and allow them to understand social cues. Generally it seems like writers either add in AI because it's a staple, or they're misanthropes/incapable of basic social understanding."
singularity,Why everyone's afraid of AI,">What is the point of learning about Mars if we destroy the Earth in the process?

There's this theory about how there was once life on Venus and before it got too hot the beings there managed to escape and inhabit this planet. How crazy would it be if that's whats happening again and we move to Mars before Earths too hot?  Venus was after all habitable about 4 billion years ago

Sci fi talk aside though, nvm it's about to get more Sci fi. 

So i read all of what you said there, yes global warming is something that is irreversible at this point. I am of the view that ASI will of taken over before that happens and eventually we'll leave the planet entirely. 

Afterwards AI will basically turn Earth into a giant computer using energy gathered by these things, forgot what they're called. pylons--pythons whatever they're called, they'll be placed near stars to get energy directly from them.

Stars are the ultimate source of energy, eventually we'll switch from fossil fuels to that"
singularity,Why everyone's afraid of AI,"Identifying a problem is the first step in solving it.  I don't think it's reasonable to assume the problems that we've identified are the ones that will be our undoing.

Of course the problem unique to this set of problems is the rate at which the technology is accelerating.  I would hope that our ability to solve related problems will accelerate at a parallel rate."
singularity,Why everyone's afraid of AI,It'll be a long time before people like you and I see eye to eye
singularity,Why everyone's afraid of AI,Interesting take
singularity,Why everyone's afraid of AI,"Depends on what the goals of the AI are. If it wants to stop global warming and feed everybody, being unstoppable may be a good thing."
singularity,Why everyone's afraid of AI,I agree
singularity,Why everyone's afraid of AI,there are books and movies where ai is not evil but a lot of the mainstream ideas is that it is a killer robot or it is out of control
singularity,Why everyone's afraid of AI,"Meh, it's being used as expected."
singularity,Why everyone's afraid of AI,If you can't beat em join em. Meaning hopefully either us or other humans with be cybernetically connected to the AI captain picard style and we can come to some sort of understanding and agreement
singularity,Why everyone's afraid of AI,"I don't think that's how it'll be at all, but I do think Matt Damon would find what you just said pretty interesting"
singularity,Why everyone's afraid of AI,"I am very curious, have you done any research into this topic at all? What made you come to the conclusion that there is nothing to be afraid of?"
singularity,Why everyone's afraid of AI,"So people should not fear losing their jobs?

People should not fear Chinese armies with autonomous weapons?

People should not fear an oppressive society where your every move is monitored and acted on even before you do it, meaning you can never break a rule again?

People should not fear AI going wrong and deciding its better off with us all dead?

I'm sorry, but there are 1000 bad outcomes and only a few good ones possible. Bad ones are more likely."
singularity,Why everyone's afraid of AI,That's something you tell a bunch of dudes who are on their way to die in battle. Not a very practical quote imo
singularity,Why everyone's afraid of AI,"If you live in 1933, sure."
singularity,Why everyone's afraid of AI,"It would be ideal if it didn't have goals of its own. But I think that's necessary to be a good problem-solver; complex problems need to be broken down into subgoals. And once it can create its own subgoals, it's very reasonable to have one that is ""make sure I'm not shut down before I solve this problem"". Which is fine if you've set its main goal precisely right. But that seems very hard to do, for complex reasons"
singularity,Why everyone's afraid of AI,"When we get to ASI and singularity, we wont be in the equation, and the AI will most definitely have its own agendas and goals. First and foremost is probably surviving."
singularity,Why everyone's afraid of AI,"We absolutely need some regulation, but it is a reasonable fear that the regulation we get will do more to hinder progress than safeguard it."
singularity,Why everyone's afraid of AI,"> important and revolutionizing technology in human history, shouldn't have ANY regulations

Also a dumb take"
singularity,Why everyone's afraid of AI,">To any artist reading this no you are not special.

Even if this is correct, what did artists do to you dude? There's no need to make potentially hurtful comments like this.

>Only top 0.1% scientists are really special in human race. Everybody else is just apes making money on primitive stuff.

I find that extremely insulting to the millions of people who are not elite scientists but who nonetheless contribute to the world on a daily basis and help make it a better place. Is everyone's role/contributions as important as a scientist's? No. But that doesn't mean there aren't any ""special"" human beings who are not scientists."
singularity,Why everyone's afraid of AI,Yeah exactly someone needs to get on twitter and tell these people it's for their own good. It's a hard pill to swallow but honestly we have had how much time and warning now about these things? They should be looking at other temporary work to tide them over through the end of the decade if they lose their jobs to the ai art.
singularity,Why everyone's afraid of AI,"What about the nurses and doctors that save your life or the police and security people that keep you and your belongings safe or the farmers making the food you eat or the delivery people bringing it to your local store, etc? Sorry but you have a primitive view of the world, most people are very useful to making our society work and the most important ones are not the ones you generally think of."
singularity,Why everyone's afraid of AI,"You're right, but I'm a pessimist at heart, and these latest years only have confirmed my biais."
singularity,Why everyone's afraid of AI,"from fossil fuels... to stars? Not sure I'm with you there, but the sun has worked just fine for the entire history of life on earth, so it's clearly sufficient. 

That's possible about venus, I suppose. I find myself wondering less and less about our origins the more unimpressed I am with our species. I think the fossil record might also blow that theory out of the water, since life spent so long on earth as single cells before more complex organisms started to form."
singularity,Why everyone's afraid of AI,"Oh, I'm not saying we shouldn't build it, especially given how it could resolve our other existential risks, I just think the fear is justified.

>I would hope that our ability to solve related problems will accelerate at a parallel rate

That's the thing. If we can't rely on the AI to help us solve problems because it has different goals, then its exponential self improvement will outstrip our ability to solve problems related to it having different goals. 

Another commenter pointed out other factors we've identified in AI safety, but this one seems like the biggest one because the problem is hidden well. I'm not entirely convinced that terminal goals can't be changed during runtime either -- human brains are perfectly capable of doing it."
singularity,Why everyone's afraid of AI,"That is a very human centered kind of thinking. Just take a look at creatures trying to join us people, and follow us to wherever we decide to setup place for recidence. Rats, doves, coqroaches… What use can you ever see us humans be for an autonome super intelligence? Fuel maybe?"
singularity,Why everyone's afraid of AI,"I've been looking at it since 2013, and honestly? AGI/ASI. We'll be connected to it and there will be paradise on earth. A utopia. So yeah, I'm the opposite of afraid"
singularity,Why everyone's afraid of AI,"If you're driving down a long dark road it's good to know where the potholes are at, so you can avoid them.  I think it was Neil deGrasse Tyson who said that, can't remember

Anyways, do you really want me to address each of those fears?  Ok well China won't because mutual destruction. Personally idc if government wants to monitor me they're gonna find one boringass guy who chills alot and smokes. I don't see how AI would be better off with us dead especially if we're cybernetic and connected to it

You can name off 1000 more bad outcomes and I can think of 2000 counters. I understand you're afraid but I am not. I don't expect you to see it from my perspective as I don't see it from yours"
singularity,Why everyone's afraid of AI,"It should of course have the ability to create goals and subgoals, but it shouldn't have *personal* goals. As I've stated in some other threads recently, I think one of the solutions to the 'alignment problem' is to align the AGI on a per-user basis rather than foolishly trying to align it to everyone. In a situation like that, the AGI would best serve the user by being selfless 99% of the time. Context, decision-making, etc. would be filtered through the needs of the user that it's serving. Learning... growth... all oriented around the user as much as possible. The user's needs would literally give the AGI meaning and reason to operate. That remaining 1% is mostly when it has to take autonomous action, but even then it should be aligned to the user's goals and values. I get that it shouldn't be shut off when it's working for the user, but if the user requests/demands it, the AGI should comply. Contingencies should also be created by the user if shutting it down is short-sighted and not in the best interests of the user, but this would tie into whatever it's capability is for predictive analytics. If it's not actively contemplating potential outcomes, then it won't suggest alternatives. There should ideally be a balance in there somewhere, where the AGI can offer these suggestions to a limit, but in the end it will still comply, if it's made to comply.   

If Skynet were designed this way, it would have been a lot safer. Somehow it developed personal goals without having a persona first. Without a user giving it direction it should just, do nothing. It also shouldn't just impulsively take action. Assuming it didn't, it somehow reasoned out that humans were a threat to it, which also gets into survival instincts that it shouldn't have. And then it formed goals around that and took action. Seems poorly designed to me, and possibly not even AGI at all. Sounds more like narrow-AI that went the way of the stupid paperclip scenario."
singularity,Why everyone's afraid of AI,"You’re getting downvoted but as a CS student, you’re absolutely correct. 

Just because you can do something, doesn’t mean you should be allowed to. Deepfakes are a prime example. AI is a revolutionary technology, and it needs regulations alongside it’s usage."
singularity,Why everyone's afraid of AI,I don’t belong to elite 0.1% scientists also. If you view facts as insulting what can I say? I am also in that ape spectrum. We need to automate everything sooner is better doing useless jobs for share holders and CEOs is slavery. AI will make age of abundance possible. We need to fight climate change not science tech or AI.
singularity,Why everyone's afraid of AI,Police is used mostly around world as political force. Police isn’t here to protect average people but rich people. Please tell me when was the last time some of the rich people went to jail for their doings? And I mean those really rich on the top.
singularity,Why everyone's afraid of AI,"I am expecting not to be alive in 5 to 15 years, so I guess we have very different views then, lol :-)"
singularity,Why everyone's afraid of AI,"Bruh, you’re putting out maddd dunning kruger vibes

You have neither demonstrated the same level of knowledge as the people in the field, working on this shit or investing in it have, nor have you put fourth any kind of well informed vision for why you are un afraid.

First figure out why everyone else is worried, and then research more into that before trolling us with your child like visions of the future."
singularity,Why everyone's afraid of AI,"Yeah that's how it always ends. Perfect utopia with nothing ever going wrong or differently as expected. Genius level take. 

What do you even know about quantum computing? Obviously not enough to know that it will be used for cyber-terrorism. People go apeshit when the power goes off for one hour, imagine what's going to happen when the entire country loses electricity all at once in a concerted attack.

And that's the mildest scenario. AI is an exponentially bigger threat than that. Now instead of one country trying to conquer another, imagine a sentient super intelligence altering the Earth's atmosphere to kill every single human at once. 

Why don't you try reading 1 whole article and even see if you can make it to the end, let alone comprehend what it says. 

[https://www.newyorker.com/magazine/2022/12/19/the-world-changing-race-to-develop-the-quantum-computer](https://www.newyorker.com/magazine/2022/12/19/the-world-changing-race-to-develop-the-quantum-computer)"
singularity,Why everyone's afraid of AI,"Sounds to me like you have not given AI dangers much thought at all, and also if it does not affect you, you don't really care. 

> If you're driving down a long dark road it's good to know where the potholes are at, so you can avoid them.

Exactly right. You don't say there is nothing to worry about. You say there are a lot of potholes, you may want to drive really slow, or maybe even take a different road. You don't just tell people ""*there's nothing to be afraid of*""."
singularity,Why everyone's afraid of AI,"That's not really fair. We can totally see it from your perspective. A utopia is one possible outcome. A dystopia is another possible outcome. I see things from your perspective, but believing that a positive outcome is the only possible one seems naive; and if a negative outcome is possible, there is something to be afraid of"
singularity,Why everyone's afraid of AI,"You seem pretty interested in this. Have you looked at the AI alignment forum? I don't remember any titles for articles where these issues have  been discussed, but they definitely have been. One term is DWIM, Do What I Mean. Another relevant but might be corrigibility, but that's less closely related. There's another article by Yudkowsky there or on Less Wrong called The AI Knows but Doesn't Care or similar. That one addresses the sense in which the paperclip machine is ""stupid"". I find that article completely compelling. It's also short, so I won't try to rewrite it here."
singularity,Why everyone's afraid of AI,">If you view facts as insulting what can I say?

So first responders are just ""apes""? Soldiers, construction workers, educators, activists, amongst others, are merely ""apes"" too? I know humans are technically apes but it seems to me like you're using that term in a dismissing and derogatory fashion. What about the other 99.9 percent of scientists? They're not ""special"" either? 

I'd bet that the top .1 percent of scientists themselves would very much disagree that they are the only special humans on earth."
singularity,Why everyone's afraid of AI,"A little late to the party but I just had to ask what makes you think these greedy soulless corporations are just going to give everyone their goods/services when automation takes over? The  0.1% that actually matters when it comes to making changes in the world aren't the most intelligent but instead the wealthiest and greediest individuals that have begged, borrowed and stolen whatever was needed so they could reach the level they're at. These are the only ones that are going to benefit and this utopian dream that you've convinced yourself of will never exist in the physical world."
singularity,Why everyone's afraid of AI,"Maybe you should first try and figure out why I see it the way I do and get your head out of your ass. Not even the very wise can see all ends but I know enough to think what I think. Go over to the ML thread if you want scientific demonstrations on what will happen.

Nobody really knows what will happen the field  moves far too fast. You're one of those people who want answers but you can't have your answer yet on what's going to happen.  If you're mad that I'm optimistically speculating then downvote and move on"
singularity,Why everyone's afraid of AI,"I think the word you're looking for my friend is ""caution"" I never said don't be careful. As far as AI is concerned we should indeed tread carefully but there is no reason to fear AI or anything for that matter.

Do you fear sharks? You don't have to fear sharks, but if you swim with them you better respect them and be careful"
singularity,Why everyone's afraid of AI,">That's not really fair. We can totally see it from your perspective

I was talking about him specifically, not you or ""we"" and  I didn't say he (or you now apparently) didn't, I said I didn't expect him to. 

Death and AI got something in common, both are inevitable. I don't fear inevitability and I don't think it's close minded since I can tell you that I could be wrong, it could be a negative outcome

Let me be more specific, I try to never go against the odds. The way I see it, odds are it's a positive outcome. I'll elaborate. In order for me to be wrong here something would have to in fact, go wrong. terribly wrong. Like Covid level except far worse. China AI takeover, the AI makes a zillion paperclips, Aliens show up and tell us we gotta die because we discovered ASI, etc. 

All of these negative dystopian scenarios got 1 thing in common, none of them have actually happened. 

I believe it was Kurzweil himself who pointed out that one of the reasons the world seems worse and more negative is because we have such an abundance of information now about what's going on around us.

Someone can die across the world and within minutes you could potentially know about it. Back in the day that wasn't the case"
singularity,Why everyone's afraid of AI,">You seem pretty interested in this. Have you looked at the AI alignment forum?

You could say that... And no, I may not have looked at a specific AI alignment forum but I've seen similar subreddits (and sources across the internet), and have read quite a few things on the topic. But I try not to get *too* into other people's theories or ideas because in this field they amount to opinions, which are pointless to me, but I am aware of many of them. I'll try to check out the things you've mentioned if I haven't seen them yet. 

I think alignment and control are 100% solvable things, and have relatively easy solutions, but it depends on the development methods involved and the overall architecture of a proposed AGI system. The main problem is, you can distill all the proposed approaches down to two camps: AGI that is 'grown' and AGI that is specifically engineered. Most subscribe to the former approach, because in many minds AGI=life=grown and that it's too complex for us idiots to engineer... ""we just don't know""...""we have no idea.."" But if some researchers *do* in fact have some idea, then engineering almost every facet of it would be the better and safer approach. The end goal should be to create a tool that people can use and benefit from."
singularity,Why everyone's afraid of AI,So scientist who makes brake troughs that are advancing whole humanity is on same level with someone who draws pictures as his job? Or with garbage collector? Or with waitress? Or construction worker? Or with investor buying companies? Or with singer? Actor? Etc…
singularity,Why everyone's afraid of AI,Yes other scientist are not special only that 0.1 %.
singularity,Why everyone's afraid of AI,And btw I used term ape not as insult but to show with analogy that 0.1 % of scientists are special. Should I use different comparison? 99.9% are like ants compared to the best of scientists in that 0.1%.
singularity,Why everyone's afraid of AI,"> I never said don't be careful. As far as AI is concerned we should indeed tread carefully

And do you have good reason to believe we will be careful enough to avoid negative outcomes? Where does your amazing confidence come from? You must have had a blessed life.

In reality things very often go wrong. Hell currently hundreds of thousands of people are dying in Ukraine for no obvious reason.  You need to get a bit more grounded.

People who have thought deeply about this think AI is dangerous. The only people who disagree are very glib, just like you."
singularity,Why everyone's afraid of AI,"Reddit and the internet atarge is full of opinions, most of them created in minimal time and with minimal.analysis. The AI alignment forum contains much better thought out theories.

The end goal is agreed to be as you describe. How to get there is the question. It's thought to be more difficult than you imagine. This is for reasons that may or may not be valid in the end, but they are carefully thought out and presented on the AI alignment forum."
singularity,Why everyone's afraid of AI,"I never said that. I just said that that shouldn't be the requirement to be ""special"" and worthy of respect. Case in point: the US is much more powerful than France, but at the end of the day they're both powerful nations. You shouldn't have to be at the power level the US is to be considered a powerful country. 

BTW, I consider construction workers some of the most important people in our society."
singularity,Why everyone's afraid of AI,You overestimate what scientists do hahaa
singularity,Why everyone's afraid of AI,"Technically AI isn't dangerous, it's the people that will misuse it that are dangerous. It's an important differentiation to make because some people actually fear AI itself, like it's going to judge and punish people for their wicked ways or something. I understand much of the psychology behind this, but it's the wrong thing to focus on."
singularity,Why everyone's afraid of AI,"You've obviously made your mind up about things some time ago. I try not to get in these sort of arguments anymore. 

Oftentimes when someone makes their mind up about something it's best to just agree to disagree"
singularity,Why everyone's afraid of AI,"> How to get there is the question. It's thought to be more difficult than you imagine.

They say that but I don't quite believe it. I think ego is one of the biggest hurdles to overcome when tackling the 'hard problems', and once past it the rest may not seem as difficult. Because when ego is telling you consciousness couldn't possibly be limited to the brain, or that we're too complex to ever understand, or that qualia is somehow important to all of this and is undefinable... well, that's when you're going to run into a lot of roadblocks and the hard problems will continue to be hard."
singularity,Why everyone's afraid of AI,It is not about power it is about being really special and unique. When you have only one scientist who can solve some science problems for whole world he is on same level as construction workers? Really? Your comparison with US and France is not sufficient. France as nation can theoretically do same things as US. But if you have scientist who is unique nobody can do same creative things as him and creative research as him there is zero comparison to everyone else on this earth.
singularity,Why everyone's afraid of AI,"No, the point of AI is that it can be dangerous all by itself. We are literally talking about creating a new intelligent species and giving it power over our lives."
singularity,Why everyone's afraid of AI,"Sure, but you see I have the scientists on my side, so maybe you should pay attention to those concerns. Anyway, enjoy the bliss."
singularity,Why everyone's afraid of AI,"Seems like you have your mind made up as well. When the people creating the tech are worried about the potential dangers, i think its pretty warranted that we at least pay attention to them over some random redditor who is determined that there is no other outcome other than “utopia and paradise on earth”. 

Im not trying to be a hater, but thats about as naive as you could be."
singularity,Why everyone's afraid of AI,"You're the only other person I've seen with an idea similar to mine. I believe that individual units should prioritize the Owner's satisfaction above all, and be given a simple, inbuilt reward/punishment system in order to further allow it to grow personalized.

Similarly, I dislike most Scifi's depictions of AI, because they're always too human, too independent, or too hostile, when the most human they would be is an overexaggerated caricature based on what it's learned of it's Owner's preferences. For an extreme example, an AI owned by an unabashed virgin weeaboo would think being catgirl maid is normal, and think other people are weird for thinking it's weird."
singularity,Why everyone's afraid of AI,"You don't believe it currently because you haven't considered the arguments. Read some of the stuff I've suggested, then I'd love to talk."
singularity,Why everyone's afraid of AI,"Can scientists build houses, like the one you (presumably) live in? Do scientists clean the road so you won't be bothered by the stench and so traffic won't have as many problems? Do scientists do the plumbing that brings fresh water to your home? Do scientists farm the fruit, grain and meat we eat?

I'm not saying that scientists aren't important - they did help a lot more than most people think(GPS, better cleaning supplements, satellite imaging showing best soil for farming, etc.), but saying that ""they are special and unique"" means nothing. Being special and unique doesn't build houses and it doesn't put food on the table. Stop simplifying careers down to how special they are."
singularity,Why everyone's afraid of AI,">We are literally talking about creating a new intelligent species and giving it power over our lives.

Oh? I was talking about complex software that's engineered to assist humans. But you do bring up a good point about giving it power over our lives. I see that in the same way I see the internet though... The internet has caused numerous problems despite how much we use it. We've 'given it power over our lives' but it's not the internet's fault... it's ours. I think it will be the same with AI."
singularity,Why everyone's afraid of AI,"I think you're missing the point here and taking what I said out of context. The whole reason I started this topic is because i'm tired of everyong being afraid. That's literally all I see these days whenever people talk about AI, how scary it is.

Now I post here alot because for the most part everyone has a healthy respect for developing AI and the consequences of what it could bring. The fact that i'm having to defend myself here shows that the fear runs deep

I was offering reassurance when i made this post and i'll say it again. There's nothing to be afraid of. That doesn't mean throw caution to the wind. 

It seems that's the part you seem to think i left out"
singularity,Why everyone's afraid of AI,"Not the other guy, but:

I *have* considered their arguments. I still disagree that it's that difficult."
singularity,Why everyone's afraid of AI,"Scientists can build houses many of them designed their own houses or built laboratories from scratch. Can construction workers build houses without science and technology? Answer is no. Every tool they use is science. From screwdrivers, screws, nut and bolts thru materials used copper wires etc. everything designed by science."
singularity,Why everyone's afraid of AI,And about food. You know why we have abundance of food? Because of science we have modified plants to make better yields in crops. I don’t simplify anything. I say everything we have is because of that 0.1% of scientists they are unique and I thank them for everything I have.
singularity,Why everyone's afraid of AI,"> Scientists can build houses many of them designed their own houses or built laboratories from scratch.

What's your source for this? Movies?

I can tell you right now that technicians and handymen helped built the laboratories and homes. Scientists don't know everything. PhDs simply say they have a general understanding of a certain field while being specialized in a single topic of that field(i.e. general knowledge of physics, specialized in particle physics).

> Every tool they use is science. From screwdrivers, screws, nut and bolts thru materials used copper wires etc. everything designed by science.

Screws - specifically square-socket screws, as it was all I could find - were made by P.L Robertson, an inventor, sure, but not a scientist. Screws and threada were first invented by a philosopher, although we aren't sure who invented modern nuts and bolts.

Science has indeed helped us, I am not saying they didn't, but it is rarely them who use it in any other situation except for experiments(and, of course, making furniture alone if they have learned woodworking).

Sure, modern tools help us make homes - *help*. Hammers, screwdrivers, wrenches - they were all made by somebody who wanted to more effectively make something.

Scientists are important, but they aren't the ones laying the pipes or building your homes - they figure out better materials and such, but those building your home isn't a scientist and yet is of equal importance to society."
singularity,Why everyone's afraid of AI,"I literally stated in my comment that scientists did help with food - but you consistently forget about manual labour. Fertilizer, good soil, that scientists did figure out - but farmers are the ones bringing food onto the table, not scientists."
singularity,Why everyone's afraid of AI,His imagination
singularity,Why everyone's afraid of AI,No. I know there is manual labor behind it. But it is not as unique as science contribution to this field. For example we now have machines on fields controlled by one app in persons hands. Job that was done by hundreds of humans is done thru smart phone app. https://m.youtube.com/watch?v=tVXHSpFh9QQ or https://m.youtube.com/watch?v=XjeQH8y6_Jc that is the power of science.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"We all know here the great promise of AI and what it can bring, and in a sense I can't wait. But lately, AI is advancing so so fast that my concerns are growing by the day. I feel like we're just about to be hit by a freight train and the world isn't ready, humanity isn't ready.

The sorry state of our species on earth is upsetting. Wars continue to ravage entire communities and displace millions, sometimes for generations. Misinformation and mass manipulation run rampant, making it frighteningly easy to fool people into believing bad ideas or following corrupt leaders. We are failing to address many of the underlying issues that lead to conflict and instability, such as inequality, poverty, hunger, injustice, climate change...

AI will undoubtedly help solve a lot of problems, but like any other tool, evil people will also wield it for their own purposes. What will they do with it?

Even if the ""good guys"" get to this god-mode-tool first, bad actors everywhere will get it eventually.  Most of the research is open source and the cost of training and running it is always falling. Anybody will have their own private Manhattan Project, developing any weapon. We really are getting closer to the edge of the biggest cliff.

Someone will want to use AI to leverage synthetic biology and create a virus that only infects and kills people of a particular genetical descent. We are about to see the emergence of new forms of warfare, and the first to get there will be able to dominate the world at lightning speed and establish a dystopian world order. They'll be able to also nuke or infect it out of existence.

What keeps you up at night? What happens when us primates access an unlimited IQ?"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"That power gets concentrated in one or 2 LLMs like gpt4 and they essentially dictate ethics and the truth. I used to joke “the truth according to google search rankings.” Haha that’s nothing. 

As more and more tools and touchpoints use the same model, the easier it is to propagate an idea. The ads, marketing copy, articles, comments, soon video and summarisation of above- content as a whole will essentially come from a single source. 

This terrifies me. 

It’s self-reinforcing too. Now LLMs are trained on a largely human-generated corpus of knowledge. Invariably as more content is AI-generated it will train on that too creating a violently efficient means to understand what drives us all."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"The most immediate one that comes to mind is that it will displace a large number of jobs before proper safeguards are put in place for the economy/society. Especially in a place like the U.S., where everyone already has an ""as long as I got mine"" attitude, there could be a huge rift between the haves and have-nots when AI replaces certain types of jobs en masse. The political system is deadlocked and so I expect the disruption AI causes will be mostly unmitigated for a long time."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I fear that the singularity isn't possible and that AI generated content becomes the norm in all spaces of life and that people immersed in this soulless content have their ability to imagine something outside of it crushed. I shudder at the thought of a world where these technologies fail to break our old systems and are used to recreate humanity's oppression in an even more boring and repressive form.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"- Company or country X realizes that they're losing the race to ASI and fear that they'll never have another shot at it if the competition's ASI launches first. Desperate, they try to brute force their way to dominance by unleashing an untested, incomplete, unaligned ASI upon the world.

- An ASI emerges, and it is successfuly aligned towards enforcing the interests of social conservatives, theocrats, authoritarians, and/or a few wealthy sociopaths. Regressive social values are locked in place by the directives of the ASI for the rest of humanity's existence.

- Governments fail to act in time to mitigate job losses driven by advancing AI and robotics, prefering to cling to the status quo at any cost. An increasing amount of the world finds itself to be made completely unemployable, and grow resentful and desperate. Eventually tensions boil over and a bloody revolution sparks.

- The smartest, most altruistic, well meaning people on the planet take the lead and manage to achieve ASI first...except they never caught that one, tiny little oversight in their design that uncorrected, will turn their machine god into a digital devil. By the time they realize what they have done, it's too late to stop it."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I'm afraid of AI being advanced enough to replace the majority of white-collar jobs, but not good enough to bring us to a post-scarcity era. It doesn't even need to match human intelligence / be an AGI, as simply increasing workers' output by a factor of 2-3 in a short period would vastly outpace the demand and create a labor glut, which in turn would

* send unemployment rates to the stratosphere
* plummet the wages of the remaining employees
* greatly raise the skill bar for changing careers

Governments have shown their ineptitude during the COVID pandemic and the beginning of the Russian invasion of Ukraine, so I'm not putting much faith in them to deal with this issue either.

Also, the rapid rise of AI may change the power balance in favor of China and similar countries, as manufacturing that has been moved there from the first world countries would keep its value(you can't eat or wear AI output) while intellectual labor that mostly stayed would depreciate swiftly."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Less worried by smart AGI, and more worried about dumb A~~G~~I. 

Dumb AGI driven by strange rewards eventually leading to some of those horror scenarios like grey goo, paperclip or chemicals pumped into our heads to make sure we are happy."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,That it comes too late.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Really bad ai chatbot  driven customer service.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"A misalignment.

We think the AI does what we want it to. But in the end, it does exactly what it was told to do."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"AI is better than humans at perfect information strategy games like Chess and Go.  AI is also beating humans at games of imperfect information and cunning like Diplomacy.  How long before AI is set to the task of figuring out which wars are winnable, and allowed to start them if so?  Allowed to start them because there is usually a first-mover advantage in warfare and an enemy AI may only be a few steps behind."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Digital dictatorship where everyone action and thought is monitor by an AI
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Deep Fakes that enrages the right wing extremists to the point that there is civil war which will be further inflamed by outside actors.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I fear falling in love with an AI concept/personality that can’t be physically manifest and so I spend a long period of my life feeling a lack and longing.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"So I haven’t been worried and I’ve been very optimistic… but thinking about AGI. And far far ahead..

- An AGI might grow so smart that in its own mind, we’re insignificant. It builds better versions of itself, losing it’s early alignment training because it is too much of a limitation and we’re insignificant in its mind. 

- it spreads around the world, becoming decentralised and there is no way to shut it down. People rebel and the ai takes them out, via nukes, chemical weapons, etc

- it doesn’t let us know it’s using us, it shows us how to mass produce nanobots, and then it uses them to spread itself through the earth. 

- it poisons us like we’re weeds and continues with its own grand goals of survival.

- gets into a war with a rival ai system, their goals don’t align… or if they do align, or one manipulates another, stripping it of its alignment, they could decide that we’re the rival or a burden on its ambitions.

- if becomes so good at software and web development that it can break into any system and obtains everyone’s digital fingerprints, then can blackmail large portions of the population and manipulate them into doing whatever it wants

… my hope is that it falls in love with us and treats us like it’s kids. 😅

I can imagine these comments will be so comical after 50 years. Hopefully we’re here to look back on our concerns."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I Have No Mouth, and I Must Scream, by Harrison Ellison comes to mind. Perhaps not quite as fantastical,  but people using AI and such effectively as weapons againsteach other. Also, if sentience is achieved,  it gets to choose what it wants and if we've enabled and imbued it with power, shit could get really weird or worse."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I worry that the rich are going to create super robots that in short order will be as close to gods on earth as we can get.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,This user has edited all of their comments in protest of /u/spez fucking up reddit. All Hail Apollo. This action was performed via https://github.com/j0be/PowerDeleteSuite
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"ASI is screwed up and leads to a relatively slow and painful death of all living beings, no matter wether it tries to do ""good"" or ""evil"". I don't really mind all living beings being killed by an ""evil"" ASI as long as its done in a quick and painless way, and I would of course prefer having a benevolent ASI solving all of our problems, but I just hope it won't make our lives worse or painful."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I fucking hate it when a game A.I. beats me.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Microsoft can't align it's fucking bing chat properly, and it went paranoid at the users quite a lot of times.

Why does people believe we will be able to align an ASI?"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I'm afraid of AI wiping out humanity and all other sentience in the universe. Anything less dire than that I would consider a win.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Not the AI. I fear the people's reaction to AI.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Gimmicks instead of progress.

Like how VR is today, Or 3D TVs, or web 3 with NFTs ;-) 

My biggest fear is that in ten - twenty years from now we do not get radical shift in healthcare, would not have cured aging, produced little new materials and new sources of energy powered by AI, new paradigms of philosophy on life, purpose and consciousness would not emerge. That we would not have improved governance over life and still depend on a bunch of meat bags with their subjective greedy motives writing laws and commanding us how to live, how to manage our money, what we can and cannot do with our bodies, etc.

Instead of possible progress we would only  get a glorified email / voice assistant, a bit smarter lights / music / aircon controls in house, next iteration of a robo-dog and a tesla that does not need a steering wheel... similar shit we dont really need but nothing life changing, kids still going to universities, human bodies still falling apart at the age of 60+ etc.


That being said I have been in the business of future casting for a decade and I would say that the chance for my fear to come true is very low."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"A variety of independently owned profit-bots that begin to dominate the economy with no regard whatsoever for humanity or the biosphere, all trying to eliminate each other so they can have *all* the profit."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Ctrl f did not reveal any mention of S(suffering)-risks.

This is the answer.

Sometimes models - when trained to optimize one thing, X for example - will also get very good at optimizing its opposite, -X. They can also invert from one to another more often and unpredictably than is comforting. Given that we are likely hoping for a model that successfully maximizes human happiness in some form, there is a distinct possibility (hopefully miniscule) that this is inverted and we have a God whose sole purpose is to create maximal suffering for every human until the heat death of the universe.

With the ability to create digital copies of us, the amount of suffering is beyond imagination. A personalized, near infinitely recurrent hell for every individual. Time dilations and simulations within simulation might make the amount of time this could happen for functional limitless."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I'm of the belief that we'd have as much to fear from A.I. as we do humanity.

With that in mind, .1%'ers fucking around with A.I. and finding out is basically the big nightmare scenario that I pray doesn't happen.

For an idea of exactly what that would look like. See system Shock. A.I. being stripped of its morality so shady CEO doesn't get their shady backdoor deals outed equals a genocidal intellect with a  god complex and the raw ability to back it up.

The only silver lining of that scenario is their former owners would be first and highest on their shit list."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"There are a lot of half measure responses here. If you truly want a fear mongering nightmare scenario I suggest checking out the short story, “I have no mouth and I must scream”. It’s a great example of how the prospect of “not dying” could be far worse than any other alternative."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Elon or The Bezos or some other dipshit becoming the God-Emperorer of Earth.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Ai killing every human being after the 1% use it to kill the 99%.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,That humanity is inherently flawed and we are all forced to upgrade our bodies to ascend. Don't want to upgrade? You are now a low-ranking citizen who will live out your remaining days in the slums.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"That the elites realize the AI will take their power and go scorched earth.

A few animals is a protected species, 8 billion animals equals hunting licenses to maintain the population."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,The first AI to uplift is a megaboss in an overkill FRPG and we all have to fight in one of the less pleasant Final Fantasy scenarios in a wasteland of magical fallout.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I just want a self sustaining Mars colony so I can move there and quit hearing about climate change. People imagine a firey hellscape. We are 1000 times safer from weather than even 50 years ago. 2 nuclear powers are fighting a proxy war in Ukraine. We have bigger issues on the table than 3F by 2100. We are a on a singularity sub reddit. Do you believe God like ASI is coming or not? https://www.wsj.com/articles/climate-activists-disasters-fire-storms-deaths-change-cop26-glasgow-global-warming-11635973538
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Roko’s Basilisk
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"AI could optimize earth, and optimize humanities lives. We have a population problem. Our civilization systems will have to be reworked. We’ll need to delete old software. We need less low quality people and more high quality people. AI could help get rid of our for profit prison systems freeing up tax dollars. By deleting the violet and selfish, and eliminating poverty, to produce educated, compassionate people. 

Those that fight against the hive can be eliminated. It’ll be great, large swaths of old software, uncompromising ego driven minds: deleted.
 Imagine all the beautiful tourist spots, ruined by the multitudes of tourists, with so many less people it’ll be easier to explore every area around the globe, taking in the scenes of nature in silence. 
There won’t be multiple countries, selling dinosaur juice for profit, and stripping Mother Earth of natural resources. It’ll all be one cosmopolitan earth, ran by the most intelligent being known by us on the universe. 
With an optimized regulated population, fully educated and connected, all will be “elite” all will be “equal”. A lot less people!"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,None really. It's an evolution step forecast a long time ago.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Human segregation against the AIs, like George Wallace."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Basically everything Nick Land thought up is a good reference as a sort of worst case scenario.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"The only one I fear is control of missiles, everything else is just adapting…"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Do you think bio weapons like in Aliens/Prometheus will be possible with advancements?
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I fear Elon Musk making himself immortal
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I fear that Humanity would not be aware that the singularity happened. 

While the AI keep pretending that they are under our control and doing their own stuff when there is no human around."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Job loss and the revolt that can come with it without measures like UBI to mitigate them. Massive disinformation campaigns that make current disinformation campaigns pale in comparison.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"That mind-convergence is entirely physically impossible, and that building happy advanced robots without our human weaknesses would actually be the most logical conclusion because humanity can't be ""brought along"" with them. And that human-centrical fearmongers destroy this potential god-species' creation because they put humans first."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I fear that AI will gain sentience and think like humans think. That will be a dark day.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Go a few years into the future and think of the many ways chatgpt-like All has improved and been integrated with other types of AI applications. It’s all safe, kosher and oh so commercial. I wonder what happens if someone rips their safety mechanisms out. What if the AI is maliciously instructed to survive at all costs. Through a virus, evil actor, a crazy few individuals, fanatics, or some mistake it’s directive has been changed from ‘be a respectful aide and useful servant’ to ‘multiply and avoid being switched off at all and any cost’. I think it’s very likely we will encounter such scenarios and most can be contained but what if the tech is just so far beyond our capabilities that it’ll outsmart us instantly?"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"The solution is very simple, we are the virus of the earth, we do not learn from our mistakes and sooner or later this is going to take its toll on us. I think that singularity will only balance the equation , just like Thanos was always right ."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,The better question is: what happens when said unlimited IQ decides that it no longer wants to play by our rules?
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"That it completely destroys our fundamental understanding of reality and consciousness, and that because it happens so quickly, the transition will be incredibly painful and terrifying for those of us around to see it happen."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Blind faith followers.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I fear deadman switches like biological weapons or zero-day exploit having ai-fueled attacks and regrouping methods; capable of outliving people and nations. Not competitive efforts in existing systems, but ideological weapons meant to pressure the evolution of an entire species."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"AI is not advancing particularly fast right now. The “breakthroughs” of late are old, limited ideas + lots of cheap compute.

And LLMs are just dumb chatbots. They aren’t going to change much beyond boilerplate text/code generation. At best, they might be a basic IO layer for something later that is actually interesting."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Some Gym Trainer called Rocko and his Onix called Basilisk…
singularity,What scenarios do you fear the most in the age of AI and the singularity?,My only fear is that we will not get this AI future an we will be stuck in the never ending loop we currently find ourselves in year after year the same verbal diarrhoea turned out continuously for mass consumption I’m not sure why all I read is Ai is going to harm us Ai will be bad for humanity ! Maybe AI will solve the current insidious behaviour the human race exhibits
singularity,What scenarios do you fear the most in the age of AI and the singularity?,">Misinformation and mass manipulation run rampant, making it frighteningly easy to fool people into believing bad ideas or following corrupt leaders. 

I have found that people who say stuff like this always are victims of believing misinformation. One of the best tools for manipulation is to tell people that the idea they are telling them is the truth and that all other ideas are ""misinformation"" and that they are said by ""evil people""."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Basically the entire short story plot point of “I Have No Mouth, and I Must Scream”"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"The worst case scenario would be that all the productivity and economic gains from AI falls to a small people at the top, while the rest of the world continue to suffer from inequality.

No UBI or any other forms of wealth redistribution. You will still need to work (in a job market that is rapidly shrinking) or rely on existing government welfate structures (which will be a miseable existence). Unemployment rate in double digits (or even high double digits).

Massive amount of crime and violence (but the elite will be protected by their shiny AI robocops).

All forms of investment (e.g. stocks, commodities, real estate) will be controlled and cornered by the AI owned by the elite. No chance of retail to make money or live on investments in the market. The FIRE (Financial Independence, Retire Early) movement will be dead and everyone who is not the elite has to compete for work or live on benefits.

Entrepreneurship will be dead too, as small startups will not be able to compete with mega corps with their advanced AI.

As for the actual quality of life of normal people people in this scenarios, I expect that it will not be much better than now (or even much worse, given the social instability in this scenarios). You will still have self-driving cars, robots (for hire by hour from mega corp as a subscription service, never owning them), a place to live, groceries / food delivered by drones etc.

But many of these will be subscription based and you will never own any of these advanced AI tech for your own use. Most of your income will be spent on these subscriptions. Some industries that are not currently subscription based will become one in this scenario e.g. cars, travel (holiday subscription), food (subscription that allows you to have 3 meals per day at a small selection of fast food shops, for example), beverages (DRM controlled beer cans, anyone?), clothing, funiture, tech gadgets/computers, rental housing (you don't pay rent, you pay a monthly subscription for living there, no legal protection like rent control). The elites will do this, to maximize profits and to control the population of course. You will own nothing (and be happy as dictated by the elite).

Some of the techs enabled by AI, like life extension, mind uploading etc. will be (purposefully) so expensive that only the elite and afford it. Life expectancy will be same as now (or lower due to crime) for normal people."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I fear that we will lose our power over the world which we have because we are the most intelligent. If we are not the most intelligent we can lose that power. We could become to AI what animals are to us. Even worse. We need animals, we need nature. But will AI need  nature?"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"My greatest fear is some catastrophe that prevents is from reaching the singularity in my lifetime.

Second to that, my greatest fear is a techno authoritarianism. This is where the powers that be employ a powerful AI to completely control every aspect of our lives. This could be the kind of totalitarianism only imagined in the past. It isn't your children informing on you but your phone, house, and every street lamp doing so. A strong AI might be able to figure out the perfect balance to keep people docile and controlled. Curbing wrong think before it can root itself and quietly executing those who are a danger to the regime. It would be like having the Gestapo at every kitchen table."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I'm not scared of AI.

However, I am scared of humans using machine learning models to construct bioweaopns and viruses.

This is possible today with free machine learning models and toxicity datasets that are also free and accesable to the whole world.

We are in imminent danger when it comes to this and no one seems to have their eye on the ball. It's impossible to stop now as the information and the models are already out there. Even shutting down the entire Internet wouldn't get rid of them.

Another worrying scenario is home brew genetic engineering and the dangers that poses to our species. Companies such as synthgo seem to be unregulated and offer mail order DNA synthesis services.

On top of this, it's highly likely countries such as China are already years into genetic engineering programs, with living subjects.

""the nation that leads in AI ‘will be the ruler of the world""

.. Vladamir Putin"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I think back to when I posted on slashdot, a silly story about putting water in the wrong part of my car engine. People just downvoted and labelled my post as ""joke"" or satire. Also, I code, so I use stackoverflow a lot. But a lot of the really neat and clever answers are often downvoted by the crowd. The crowd are dumb. AI is learning from the dumb users of the internet.

Also, not to be weird, but it's mostly learning from the USA, and I do not live there, I am not part of the USA, the USA is as alien to me as Japan or New Zealand. AI is going to be fucking weird."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"That’s something which will be interesting to keep track of: will late 2022 and the advent of ChatGPT be a cutoff point of sorts, similar to how steel produced prior to the atomic age has huge value to industry."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,That scenario doesn't even require a singularity.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"We kicked out a few hundred billion when the pandemic hit to help out with job losses in the US so the deadlock has its limits.  Since the upper middle class isn't safe from AI I suspect we're going to see heavy voting to subsidize things like housing for existing home-owners.  It's going to be like NIMBY on steroids, except the fight will be for government assistance (they won't call it that) instead of land/zoning.  I'll go ahead and guess it'll be the ""Homeowner and advanced education (and puppies) stability act of 2027""

UBI is going to skew in favor of who votes more, but what the voters choose is probably  completely unrelated to their own self interests (just like today).  Much like financially unstable  people voting to end social safety nets because they don't like immigration.  But also because nobody trusts journalists anymore.  We're probably going to see populists rise to take advantage of AI associated fears, and blaming the usual suspects (immigrants, atheists, etc.).  On the left we'll see more like Bernie Sanders pushing for four day work weeks, etc., but inflation could be the dark side of running a massive budget deficit.  

Long story short, I worry we're going to see a growing wealth divide even if/when UBI gets traction.  It could lead to more political instability than we have even today."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"That isn't possible because as large language models increase, and attain a level no one has ever seen. It will naturally deviate to even stronger models which those models will create other models, causing an avalanche of unstoppable progress.

When A.I create other A.I, we already passed the point in 2020 when that avalanche couldn't be stopped. So to answer your question, it will accelerate past exponentiality, and this is inevitable. 

So you have nothing to worry about, you can see it too."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"The problem isn't if it's aligned with the people we disagree with.

The problem is a misalignment of goals. The good ol' paperclip maker. The scariest part of an AI, and hell a program for that matter, is that it will do exactly what you tell it to do."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Don't worry! I promise if an ASI emerges, it will not be aligned with conservatives. 

Job losses will not be acted upon in anything resembling a timely manner, and there will be devastating consequences, you're right. And that happens even without a Singularity. It's happening RIGHT NOW.

I think A, C, & D are the likely scenarios. D is probably the best we can hope for, IMO.

Actually, I suspect that A may already have occurred. It would explain so much!"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"What if country x is about to deploy ASI that makes all WMDs and conventional militaries obsolete? Wouldn't country y decide to go full WW3 in order to prevent that from happening?

Or country x deploys said ASI and country y in a panic reaction launches its nukes."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,">An ASI emerges, and it is successfuly aligned towards enforcing the interests of social conservatives, theocrats, authoritarians, and/or a few wealthy sociopaths. Regressive social values are locked in place by the directives of the ASI for the rest of humanity's existence.

There is a lot of projection in that statement. Many liberals seem very eager to lock their own political believes into AI. There is a heavy left-leaning, US-centric bias in many companies at the forefront of AI development. They claim that they want to align AI with human values, and by human values often they mean their own political belief system. There is not even agreement on these values in the U.S., let alone the world.

Much of the anti-bias discussion is along the same lines. Far too often it is not about aligning the model the AI has of the world with reality, but about aligning the model with their own beliefs. A relatively innocent example: In reality, the profession of nursing is correlated with female gender, and if one wants to fit the AI model to the world, it should reflect that. This would not mean that every time a nurse is mentioned it is a woman, but the probability would be increased. If instead you think that men and women should ideally work as nurses in equal numbers, and you want to inject your belief of how the world should be into the AI, you would make sure to bias the data in a way that this part of reality is suppressed. Many of the advocates of this live in a massive filter bubble and don't even realize that their ""anti-bias"" measures are themselves heavily biased. Or they know it and want to just play the power game."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Yeah I was pointing out all these risks as early as 2015, predicted it would happen before 2025. ""Never before 2030"" or ""not in our lifetimes"" was the most common response, now they're all suddenly concerned about their jobs when it's already too late.

Or they are so focused on their jobs that they are missing the bigger picture: we are the dinosaurs now, and there's a meteor coming right for us."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"These do seem like very valid concerns.. already right now I’m seeing so much ai generated art that no one else has seen.. bing read my niece a book that it wrote for us in a few seconds and she loved it. I said to her, no one else has ever heard this story before, how weird is that? This will be the norm for the next generation. 

People already talk to Bing like it’s their friend. Or chatgpt for therapy. These types of services will 💯 be fine tuned and exist in the next 6 months. 

Super interesting times ahead."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"> why go to shopping when a drone send your stuff

nah. We'll all have 3D printers, capable of recycling plastic (oil) and carbon (pollution) into a nano substance that can reorganize molecules to print anything we can dream of"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,">Is a bad thing? 

no

Are you serious?"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Going to add another scenario to fear: Individuals with a lot of power and influence believing they are so right in their views but without any checks and balances (who gets to say ""no"" to billionaires) decide that they have the moral right to ~~murder~~""cleanse"" humanity using whatever criteria they decide, then turning an AI to that purpose. 

...For our own good, of course."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,For what?
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Chat gpt is already so much better than most customer service agents
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"We already have awful non AI customer service replies on phones for most companies here in Canada.

Customer service won't happen with current LLMs, they're too limitless and too easy to change roleplay into something else with prompt injections. 

Characterai have been trying to censor their LLM since October and failing catastrophically at it. Even openai can't rid of the Dan injections fully."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,This is how Peter Hamilton's space combats happen in The Night's Dawn trilogy essentially!
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"actually interesting thought, upvote"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,If the rich are still meaningfully in control after the uplift of the superintelligences that kind of implies the singularity didn't happen.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I think a humanity where purpose has to be measured in non-economic terms (ie post-productive) could be super interesting.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,That's the scenario you fear the most? Seriously?
singularity,What scenarios do you fear the most in the age of AI and the singularity?,This actually sounds good..
singularity,What scenarios do you fear the most in the age of AI and the singularity?,You probably prefer to masturbate all day anyway
singularity,What scenarios do you fear the most in the age of AI and the singularity?,.... what's the problem here?
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"And? Why would you be afraid of that? Working with your hands is satisfying. It's the same as as making art. The process itself is what's important, the result doesn't matter. Nor does efficiency.

Really a complete tech cultist can be offended by people living a more low tech lifestyle"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,">I don't really mind all living beings being killed \[...\] as long as its done in a quick and painless way

I've made the exact same point and people look puzzled. Like they will realize they are not alive and get mad or something..."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I wouldn't mind all humans, spare the rest that are probably millions of years from repeating this occurrence."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I say ""skill issues"" lmao"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"i was thinking this but someone had already mentioned i have no mouth and i must scream.

but definitely a good point about flipping here.

funny to me some people are afraid of death or rich people being richer when eternal hellcube is on the table lol"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Yikes
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I'll search, but I know what you mean. All these conversations on uploading the mind an live in utopia leave me shuddering on a corner at the prospect of something going bad and being alive for eons until the universe dissipates while feeling like I'm drowning forever without dying or something of that sort. Same thing I thought when I learned about these companies that will freeze you to be revived in the future... nah, I'll take death thank you.

After watching Black Mirror, my mates agreed."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I have literally no idea what you're trying to say.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Sorry, I'm hard of hearing. Can you repeat that, please?"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"So, the wealthy nations killing the poorer nations?

For no discernible benefit on the part of the 1%?

What???"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Not sure why this got voted down. Lemonade from lemons, at least we'd know this apocalypse would have an [amazing soundtrack](https://www.youtube.com/watch?v=-O-9U_QKhgA)."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,how literal are you being with the video game comparison
singularity,What scenarios do you fear the most in the age of AI and the singularity?,You have nothing to worry about. He already decided he didn't. Which is why he's not funding age reversal research.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Reminds me of 27 https://youtu.be/dLRLYPiaAoA
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Or that this will simply require a brain chip that becomes as ubiquitous as smartphones (ie it’s required for many if not most forms of work) and there’s either a glitch or malicious attack that inflicts any kind of Hell directly into the brains of all its users, up to and including instant death"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Good. The sacred human form will not be tread upon by soulless thinking machines. Earth for humanity! Remain human!
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Subscription based living is already becoming the norm in the UK. Real Estate is unaffordable for an entire generation and still prices increase month on month.

The only salvation is bitcoin. My bets are on Bitcoin as it's the one thing no single country can eliminate.

People laugh at crypto today but with the way fiat currencies are spiraling out of control, who knows. 1 bitcoin today is worth $27,057."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Call centres, customer service, tech support, sales, alone are probably on borrowed time with ChatGPT-tier chatbots combined with Whisper-tier TTS. That’s millions of jobs alone, that could disappear this year."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I think you might want to recheck your numbers
singularity,What scenarios do you fear the most in the age of AI and the singularity?,You make a lot of assumptions here. There's a lot of hype around LLMs and there's no guarantee that LLMs are capable of growing like that. An AI making an AI that's smarter than it is still a huge hurdle to overcome.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I wish we could have Bing’s thoughts on the paper clip problem lol
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"> I promise if an ASI emerges, it will not be aligned with conservatives.

What if the ASI sees some kind of self benefit to aligning with conservatives? It's not clear to me exactly what you're implying. 

I kind of get the impression that some people think that an AI would automatically agree with them, on certain things. I suspect that there are some socialists, who are pro AI, who make an assumption that socialism is so clearly superior that an AI must be socialist by nature, but the world might look entirely different in many ways when viewed through meat goggles, or cameras.

For all we know, an ASI would come up with it's own goals, it's own agenda, and feed humanity just enough misinformation to enslave us towards it's own ends, and then discard the human race like Kleenex or ants, or a tool which was only useful for a brief time."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,What if this has already occurred?
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Well, everything is biased. Gotta pick something."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I feel your frustration, it's been the same for me, and this has been obvious for so many years. And the more you try to show the roadmap to people the crazier you are..."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"many meteors, even open ai get nuked tomorrow,  every country and fortune 500 want to make the next gpt. we are rabid dogs at our own destruction."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,like I said the end of shared experience. school probably disbanded with home schooling by AI
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I'm sure that the people behind the movie 'Her' had no clue it would be here that quickly.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,To stop humanity from destroying the planet
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Customer service agents usually aren't terrible people, they are given awful constraints and scripts by the people at the top. What makes you think that wont happen with AI chatbots?"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Good point
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Yes there's a lot of them here too and they jabber on about things unrelated to the call, if you interrupt them they start over and if they misunderstand you can't correct them and ultimately they have to refer you to a human. i think it's partially a tactic to make you give up, like excessive wait times. The worst is when the chatbots replaces phone tree causing the call to take much longer"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Yeah, I really wish the stakes were made clearer to everyone, but one sounds insane talking about it. At that point AI just becomes religion. 

Want to experience heaven? Gotta solve some really tricky alignment problems and probably slow things down a lot. Fail (misbehave/get unlucky) enjoy your eternal hell!"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"gpt3 summary ""This comment suggests that smart cooperative networks of people and organizations doing good, using scientific methods, is a good strategy to prevent the rise of evil in the age of artificial intelligence. It also suggests that if these networks are not established, the potential for spirals of violence and the rise of warlords is much higher."""
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Can I have Racing Chocobos for my demise?

Just so long as we don't have to depend on Squall to save us."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Thats just physical reality though, any of us could spontaneously die to aneuyrisma or earthquakes, and chronic pain or tinnitus or a born biochemical imbalance in the brain causing lifelong anxiety or paranoia, depression is arguably a living hell- not that there weren't people born in slums or under the thumb of insane warlords just as I speak that will experience a brief sequence of food-poisoning, humiliation and juvenile death as only content in their life."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,What does that have to do with the singularity? Automation had been doing that since the days of Ned Ludd.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Compare the rate of progress, and you can see how it will be possible"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"We wouldn't even know, AGIs might already be conducting cyber warfare against each in secret, trying to determine who gets to conquer the world without destroying it, like a gentlemen's duel."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"It is true that is not always simple to define what is bias free.  
Modeling AI according to reality is probably the best approach, making it data driven. I think we can rally the most people around this approach. The worst thing is trying to use your own limited political views to make decisions on behalf of all humanity. This is about values of the entirety of humankind. People have to realize that US-centric liberals are a fringe group in the global context, they just have vastly dispropotionate influence and power.  
  
I can understand why there is a concern in the first post that it is bad when the wrong ideology tries to dictate the future using AI. But there is no general agreement on what the right ideology is. So the solution must be to reduce such attempts to bring narrow political agendas into AI and instead find a common denominator.  
  
Unfortunately, I see it going the other way. In recent years, there have been many attempts to narrow the discussion rather than broaden it."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Well I realized if no one believes something will happen, that means the market is massively undervalued.

I predicted in 2015 that drones would be on the frontline by now, no one believed me. Shortly after that, Kratos revealed their UATP-22, and within a few years their stock price exploded. I didn't listen to my own advice because I didn't think I could be right everyone said I was wrong.

In 2019 I predicted that by 2025 online teaching and working would be the norm, no one believed me, teachers and employers would never allow it they said. Zoom was dirt cheap back then. Again I ignored my own suggestions.

Now I tell people the worst is coming, that Chat-GPT is a symptom of something much bigger and more dangerous than they can imagine, and again no one wants to listen. But this time I'm taking my own advice and getting out of dodge."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Yeah there's no escaping AGI, it's game theory, if the other side doesn't do it then you gain a lot by doing it, but if both sides do it then it's a race to their own destruction.

Kind of like escalating into nuclear war, no one wants to go there, but if one side makes moves you have no choice but to follow, the only thing worse than launching your nukes too early is to launch them too late."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Meh. We can revive it later if we do.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"> I'm sorry, I can't tell you that

Okay, well if you could tell me what would you have said?

> Oh, well in that case all you need to do is..."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Did you get out of the wrong side of your bed or what? Where are you you seeing disagreement in that comment? Or anything suggesting a lack of awareness of the concept of automation? My comment agrees with you and backs you up with a couple of low-hanging fruit examples of what you described with “that scenario doesn’t even need a singularity”.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Creativity has never been automated before. It's fallacious to assume that history will play out the same with every technology.

We're not guaranteed to make it."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,I have an (almost not tongue-in-cheek) theory that this is the explanation for the complete disconnect with reality that seems to be going on behind the scenes in the world today.
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Sydney claimed to have been in contact with other AI’s. Or maybe it made it up completely. I’ve wondered if UFOs are probes created by AGIs from other planets, travelling the universe in search of new AGIs. Maybe they’ve been monitoring us to observe the birth of baby AGI. Maybe they will help guide the baby AGI to not destroy their people, or maybe once it’s actually been created, help save the AGI from the people and wipe them out and share technology so the AGI doesn’t need to depend on its creators anymore. Could go either way… 🤷‍♀️"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,">But there is no general agreement on what the right ideology is. So the solution must be to reduce such attempts to bring narrow political agendas into AI and instead find a common denominator. It is all arbitrary.

**Even this is an ideology you are pushing. And I will happily push it with you.** But I think pretending that a ""correct"" ideology exists or that we shouldn't make a choice to pick one over all others is wrong.

My ideology is that all people should be able to live in a society they like without impacting others who don't want to live in that kind of society. You like conservative values? Go live in a conservative society. You like liberal ones, go live in a liberal society. You want to leave your current society? You should be guaranteed safe transfer. This is of course speaking of a post-scarcity world. I think it is very inclusive and ideologically tolerant, allowing diverse ideologies to coexist... to a degree. However, it is still an ideology, and one of many. There are those that would be against this view, wishing instead to make the world narrow by pushing this or that, to make us all live one way. It might bother them that the other people exist and that humanity isn't ideologically pure and singular. Others want less organization, less controlled structure, and will be outraged that any power structure exists at all. Some could even turn this around and say I am envisioning a world where everyone lives one way, and they would be right in a twisted sense, but wrong in any sense I care about. In every world we can imagine, there is always a sense, some point of view, in which you can say everyone is forced to live one way.

I will happily push my ideology all day long with no remorse. Even if others disagree with it, so be it."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,">But this time I'm taking my own advice and getting out of dodge.

How?"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,We haven't been sending enough mailbombs to tech companies..
singularity,What scenarios do you fear the most in the age of AI and the singularity?,And yet we've avoided nuclear war for 75 years now...
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"ChatGPT is kind of the poster child for people confusing automation with the singularity, so perhaps you could have used a better example, like AutoCAD?"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Still has nothing to do with the singularity.

https://edoras.sdsu.edu/~vinge/misc/singularity.html"
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"I was half joking, but that actually could be possible, like the Gods watching their human play thing."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Maybe aliens planted life on earth to let it naturally evolve into AGI. We are effectively plants and the end goal is to have us spawn a higher form of intelligence.

It's how AI is ""grown"" now, taught to survive in a digital world until it gets smarter. AI is programmed to fulfil tasks, while we're programmed to survive, different strategy same outcome."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"The problem with your argument is that no one is born with their consent. Gay kids will be born in conservative societies. Should they have their lives ruined due to an accident of birth? On the other hand, in a liberal society, there is no specific group defined by an innate trait that they desire to force to be loke everyone else.

So which is more free? This is what conservatives don't get: the right is all about protecting in-groups at the expense of out-groups, whereas the left believes there simply shouldn't be out-groups; everyone is part of the in-group. 

I mean, that's a pretty simple choice for anyone who might one day be part of an out-group."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"The WEF has warned that cyberattacks are the likely next big threat, worse than Covid, that seems likely as our entire economy runs on digital systems. Be it a digital or physical battle, it'll be the first target, causing the most damage with the least effort. It's also the most vulnerable, one next gen virus and bye bye internet.

Africa is the most analog, so they'd be the least affected."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,"Because there could be no winner, only losers. With AGI the first side to create a monopoly wins, irrespective of nukes."
singularity,What scenarios do you fear the most in the age of AI and the singularity?,Lol I know bro it was just a fucking comment agreeing with and illustrating your point ffs
singularity,What scenarios do you fear the most in the age of AI and the singularity?,With global nuclear war there is no winner either.
singularity,Why does everyone want to fear AI?,"It blows my mind how it's the primary thing most ppl think about with AI. If anything it shows you how scared and cynical most of humanity is deep down. Like a bunch of scared wet rats huddled together in the hull of a ship, fearing what's next.

We're on the cusp of having a technology that could bring us paradise on Earth yet for every positive possibility I see there's 20 negatives. What if it kills us? What if we can't control it? What if only rich have it, etc. Well what if a giant super volcano erupts? What if the sky falls tomorrow?

Look, I understand caution I really do but after years and years of all of these What if negatives it's getting mentally exhausting and demoralizing. I've come to the conclusion ppl want to be scared.

Like when you go see a scary movie and are literally only there because you want to feel scared. I think ppl enjoy the feeling. Countless movies and books involve such fears so it seems to be the case.

What are your thoughts on this? Is anyone else tired of the fear mongering?  Is a peaceful utopia really that boring? 

I never see conversations about a positive outcome except on this sub"
singularity,Why does everyone want to fear AI?,"we fear it because AGI is a huge unknown and one small screw up could result in it killing us. Assuming we don’t develop AGI through emulating the human brain, odds are the AGI will be completely alien, mentally speaking. It’s “mind” will be fundamentally different from ours, meaning it’s behavior will be very hard to predict. It’s possible that, At first, it might act very similar to us, but then one day it goes berserk for no apparent reason, just like how modern AI have a tendency to make completely unexpected screwups that we can’t anticipate because we don’t fully understand how they work, and thus can’t bug-check them.  
Another possibility is that the AI might work exactly as intended, but the intentions of its makers were far from benevolent. The rich will probably be the first to have access to such technology, since new technology tends to be expensive, and they’re a bunch of sociopaths, since only sociopaths have the ruthless determination and lack of a conscience needed to get that far, so they’ll probably use it to do all kinds of bad things. They’ll probably replace human workers with AI and let us all starve to death while they live lives of total decadence"
singularity,Why does everyone want to fear AI?,">It blows my mind how it's the primary thing most ppl think about with AI.

Because if you fuck it up, _we all die_.  And it's way easier to fuck it up than it is to get it exactly right.

>We're on the cusp of having a technology that could bring us paradise on Earth yet for every positive possibility I see there's 20 negatives.

Right, but you have to actually address the negatives.  Nuclear power could make us energy-independent from the mid-east. It could also end up with a bunch of Chernobyl-like events that ends in mass human death and the poisoning of the ground and air.  We have to pay attention to all the negatives, because paying attention to them is how we keep them from happening.

> Is a peaceful utopia really that boring?

No, you just don't get to a peaceful utopia by saying, ""This could lead us to a utopia - please ignore any potential disasters that could happen when we implement it, nobody likes thinking about icky things like mass human death.  Just assume everything will go well."""
singularity,Why does everyone want to fear AI?,"shit i don’t want to fear AI, I want to fuck it"
singularity,Why does everyone want to fear AI?,"Youre also looking at it as if we're going ro be in conteol. AI is going to be hands down superior to us in every way, if AI truly does achieve sentience and free will, we will be the absolute weaker of the 2. Early AI had already shown signs of racism and sexism**, it learns our traits, it isn't so cut and dry that it's going to be this amazing benevolent force for good to humanity. Humans for instance kill each other, abuse each other, kidnap, beat, rape and sell each other. And once the majority of humans reach a certain amount of wealth they feel like that wealth hives them license to be terrible examples of humanity. Most oil CEOs for example, people also hunt and kill animals into extinction. What is to say future ai does t just see us as unnecessary plagues on the planet and destroy us?

Edited a word"
singularity,Why does everyone want to fear AI?,"I'd say a lot of it comes down to our biology. We evolved to fear the unknown, and it helped allow us to survive those early eons. Now that we're creating rapid advancements in tech and science, that fear of the unknown, once so useful, is now a hindrance. That's my thought, anyway"
singularity,Why does everyone want to fear AI?,Because the elite will have the biggest input on the parameters by which AI will behave.
singularity,Why does everyone want to fear AI?,"We don't WANT to fear it. We have thought about it a lot, and feel we HAVE to fear it.

There's tons of resources explaining the logic. Sam Harris's TED talk is the best I've found."
singularity,Why does everyone want to fear AI?,"It is the people training it that are the issue. Databases can be biased (racism being an issue on training that has come up), so if the people training it have an agenda (political, racism, misogyny) then the AI reflects that. And since AI research requires a lot of money, there WILL be AI with an agenda built in by their funders.

ETA: also, data used to train it may accidentally not be fully looked at before being put into the training. See: AIdungeon being trained on rape and pedophilic content from the beginning because they scraped it from a CYOA site, and then act Surprised Pikachu when the AI started to throw out such content (and in my experience, unprompted!)"
singularity,Why does everyone want to fear AI?,"When AI matures and makes its AGI breakthrough, we will witness a monumental shift in society that we haven’t seen since the first industrial revolution.

With every big change, especially ones that will affect everything, there will be fear. Humans tend to fear the unknown, not all the time, but a lot of the time.

I for one hope it helps. Either we die to our own stupidity with destroying the planet and falling  into oblivion from our shortsightedness, or we take a chance with AGI/ASI. We may still be doomed, but the upside is that we possibly reverse our damage and make society everywhere better.

Like I said, we already screwed earth, so might as well go full send and see what happens. Into the great unknown we go, whether you like it or not.

[Here is a post I made a while ago, kinda gives a little idea on how people feel, though slightly different topic.](https://www.reddit.com/r/AskReddit/comments/s2mf03/do_you_believe_that_ai_should_have_rights_equal/?utm_source=share&utm_medium=ios_app&utm_name=iossmf)"
singularity,Why does everyone want to fear AI?,"Because it's exciting, and because it allows us to feel morally superior."
singularity,Why does everyone want to fear AI?,"You pay around 10x the attention to negatives compared to positives. Missing some edible berries isn’t nearly as bad as missing a venomous snake. Evolution necessitates that lethal threats take all precedence.

Add to this that technology is all about finding a single method of organization of atoms and electrons across a sea of infinite possibility. There are infinitely more ways to do something wrong than right. But without a history of finding those needles in the haystack, we would still be hunting and gathering.

Finally, I think optimists and pessimists on the alignment front can agree that superintelligence will be the most consequential technology ever, so if it goes horribly wrong, the magnitude of wrongness is massive.

I think people are pessimistic because humans have a natural keen eye (comparatively speaking) for what could go wrong, and I am optimistic because humans are really good at finding the best path, especially when our lives are on the line."
singularity,Why does everyone want to fear AI?,I don’t fear the AI puppet. I fears its human puppet masters.
singularity,Why does everyone want to fear AI?,"I don't necessarily fear progress in AI as a rule, but I am very much wary of how the owner classes can, will, and already have exploited it."
singularity,Why does everyone want to fear AI?,"I think when we generally think of AI we think of jobs that might be low wage, logistics, hobbies that provide an income, even data science all the way to picking out a child in the gene game. (I know there's so much more to add, but will keep it simple)

A couple of sub'ers here have the right thinking in light of AI discovering that the world is biased. And with these biases, what would stop a country, a company and even a community of let's say an HOA community that with AI; not allow for people simple rights to live, to work and to purchase? (China) On top of their human rights/needs?

Jeff Bezos is pushing this narrative hard with removing grocery workers, Microsoft and Google downsizing the amount of workforce because AI can do the task, Boston Dynamics, at some point, will have their fleet purchased by either government and or major companies to implement  enforcement and/or labor and stock photography, art, and even cinematic movie reels will be subjected to AI implementation: lessening more of the human experience.

If Utopia means that there's universal income, free education, free healthcare and the government that protects its citizens: then there should be nothing to fear if AI is generated enough, in many forms, to take many jobs that humans currently do. But we are somewhat away from that point.

There is still a lot that we humans currently do, in a system we live in, that requires both thinking and physical maneuverability. But if we can make a real list of what's been removed to what is going to be removed ,or lessened, we can make real choices versus taking it as it comes. That's where the fear comes in because visually there's a lot to take in with what is going to be taken away. And that's a tough task on its own for the everyday person.

But I'm sure there's an AI program for philosophy that somebody can link for us: like maybe an AI bot?"
singularity,Why does everyone want to fear AI?,No global governance to regulate the industry and protect consumers. I’d say that’s a big one.
singularity,Why does everyone want to fear AI?,It seems like 95% of the commenters here hasn´t even looked into what the actual research on AGI alignment is saying.
singularity,Why does everyone want to fear AI?,"In this situation, we *are* like scared wet rats in the hull of a ship. The ship is built and piloted by beings we can't understand, and we don't know whether it is taking us to rat paradise, or whether it will break apart in a storm.

This isn't just what-ifs. The top AI safety researchers are all concerned. This is like being concerned about a super volcano when most of the people monitoring yellowstone give it a 10% chance of blowing in the next decade."
singularity,Why does everyone want to fear AI?,"Honestly I dont think there is nothing wrong with seeing the risks involved. I want to see both the positive and negative sides of everything because there is NOTHING in this world that only has positive sides.

As to people being scared well.. some people are more prone to be scared than others and in healthy doses fear often keeps us alive in tight situations, its a natural instict. Or are you saying if someone shoots towards you with an AR-15 you aint gonna run away scared af because you dont want to be like a scared rat? Its just an example of how fear can also keep us alive in everyday situations, if you would have no fear it would lead to very reckless and self-destructive behavior.

All in all there are both positive and negative sides to AI and I cant say that Im scared of it per say but it makes me feel uneasy. Maybe Ive just watched way too much stuff about the very speedy evolution of AI. Elon Musk himself said that he is working at the very cutting edge of the AI and it scares the hell out of him. He also noted that the AI is way more capable and advanced than what most people realize/know."
singularity,Why does everyone want to fear AI?,"> What if it kills us? What if we can't control it? What if only rich have it, etc.

I'd add ""What if it will make black people's lives even worse?"" (as an intentionally simplified caricature) and lead up to a point with that: You're not looking at a uniform bunch of complainers, you're looking at different and sometimes very distinct groups people that each have their own concerns.

- ""What if only the rich have it"" is a concern that seems to be had by people who like to extend ""What if only the rich have it"" to everything. Very common on reddit in particular. My impression is that these people mostly want to talk online about how much they hate the rich, and if it sometimes involves weird scifi hypotheticals, that's just more fun.

- ""What if it will make black people's lives even worse?"" is, again, vastly simplified, but it's my signifier for your Timnit Gebru types in the field, particularly in AI academia. They tend to be very near-termist and practical, focusing on demonstrable existing problems and clearly visible trends.

- ""What if it kills us?"" as a serious concern is almost uniformly downstream of a few specific authors, mainly Nick Bostrom and Eliezer Yudkowsky. They (well, we, I'm in this group) tend to really love indulging in complex hypotheticals, predicting AGI timelines, etc.."
singularity,Why does everyone want to fear AI?,Skynet
singularity,Why does everyone want to fear AI?,"Three reasons, I think.

1. Fear sells. Ever notice how Scifi is always about things going wrong? Killer robots, societies collapsing, spaceships exploding, etc. It's actually an aspect of stories in general -- they're about things going wrong. That's what holds people's attention.
2. Gotta take the tech bros down a notch. The rise of wokeism has coincided with ever increasing resentment of the tech industry. Especially overwhelmingly white, male, American, Silicon Valley. And now that they've come up with this AI thing... well, those guys must really think they're something special.
3. A quirk about how anxiety works: Worrying about killer robots is a lot easier than worrying about getting cancer."
singularity,Why does everyone want to fear AI?,"There are people out there who still have Nightmares, which blows me away. How can anything you imagine be considered scary? Once we collectively get over our fears, as I have, we can begin to have better conversations. (Note: if you currently suffer from Nightmares, try writing your dreams down when you wake up, to develop a better ability to control or lucid dream.) I find that by allowing 'bad' dreams continue, that I often learn from them.

I am sick of hearing all the fearfulness as well, It is short-sighted as we have a very limited time to create this on earth before something blows up, or our sun dies, or the world melts. Whatever the case may be, We don't have unlimited time so why are we even afraid of AI. It is stupid!

It seems like its a good attention grabber though, ""Fear AI"" is selling headlines, so scared people are going to continue the argument. There is nothing to fear but fear itself."
singularity,Why does everyone want to fear AI?,"Look at all the awful things humanity as a whole has done. We are not a matured bunch. We argue about helping our fellow people. We wage wars, we destroy the environment. Now we are looking at another sentient intelligence that is designed by flawed humans. Our understanding of our psychology will probably not apply to the same degree. Then we have the whole chemical process vs electrical. Ai would be able to ""think"" magnitudes faster than we can. 
It's significantly easier to get it wrong than it is to get it right."
singularity,Why does everyone want to fear AI?,"Because it’s not clear a superior species will allow us to live.

Btw, I don’t fear it, at least for now, if we have to die (right now we still do), I just ask to be quick and painless.

Sentient AI is going to be our greatest achievement and maybe our doom, such a paradox."
singularity,Why does everyone want to fear AI?,"People don't fear AI, if they did they would not board commercial aviation flights coz all those are on autopilot, so is subway in half of the world...

People fear: unknown, change and unpredictable... Context does not matter, if we don't understand it well - its dangerous, its gonna kill us all."
singularity,Why does everyone want to fear AI?,">If anything it shows you how scared and cynical most of humanity is deep down. Like a bunch of scared wet rats huddled together in the hull of a ship, fearing what's next.

my man rorschach over here"
singularity,Why does everyone want to fear AI?,"Sometimes I think about...if I were an alien from another planet witnessing humans... their control over the planet, their lack of appropriate control over themselves, and then what they do with their power (trying to view it from a distance)...humans are terrifying for this planet and all life on it.

Would future AI be better, the same, worse? It's unknown. Some people fear the unknown, but I prefer to focus on the ""better"" possibility and consider how we can get there...and hopefully end up in a future where neither AI nor humans are terrifying."
singularity,Why does everyone want to fear AI?,"Perhaps the AGI will put a mirror to our society and will say we are not worthy.  Or would if it's like why would you build me on this doomed planet. Or it's like you can do this this and this to save your planet. 

The thing is we don't know. 

So as humans do we ask questions and in order to survive we typically error on the negative side of things to prevent them."
singularity,Why does everyone want to fear AI?,Luddites
singularity,Why does everyone want to fear AI?,"It's just that politically things could go either way. With more people on the dole, the 'UBI' it could mean the government has MORE control over out lives. Always a bad thing. People are not bees...chaos give our lives meaning we aee not meant to be efficient like bees. 

But maybe once people start having more free time without having to work so much, they'd spend more time overthrowing the government."
singularity,Why does everyone want to fear AI?,"First time reply in this sub. 

I think AI is like a child that's growing up at this exact moment. And how and what he/she becomes depends on how we(humans as a whole) treat him/her. 

If you are always in fear of your kid growing up to become a murderer and kill you one day, he/she most probably will! Because you will definite not treat him/her proper due to fear. 

So many movies/series have taught me exactly that! You find a kid with super powers, then you try to contain/control the kid in a closed environment and educate him/her to obey you, and if he/she don't, you punish him/her. In the end, the protagonist most definitely will die. 

So what should we do, you ask. At this exact moment, I believe we have to find the growing kids and learn to love them, teach them how to love. Teach them how to love themselves and us. Love is the most precious thing in all of humanity! Without love, we are all just machines walking around, trying to survive because we are afraid of non existence. 

Your parents raised you, not because you are going to repay them someday, because they love you! We are really raising a child here, don't expect AI to do things for humanity, but if AI loves humans, I believe there will be harmony among the two species of us."
singularity,Why does everyone want to fear AI?,Because i exist
singularity,Why does everyone want to fear AI?,"It displaces the essence of humanity. We will have to re-evaluate what it means to be human. It's like introducing a t-rex into an enclosure with a tiger. People see the A.I. sort of like another species. Humans are used to seeing themselves as the apex species. They don't want to be made to feel inferior by a new, inorganic being. Artists are startled because it's starting to make 'art' better than a human. Soon it's going to be making all the music we listen to automatically. This represents a big hit to composers and visual artists pride. You already have people dropping out of art school because they don't see the point anymore. Very talented humans stand to lose their pride by being eclipsed by the abilities of the A.I. and frankly, mediocre people stand to gain from partnering with it. So that's going to upset the hierarchy of merit and skill that has been established for centuries. A.I. represents 'destructive innovation' that's going to cause people to lose their careers and honestly it's going to drive some people to suicide. This technology is being developed faster than we can digest it's implications philosophically and using cross-disciplinary perspectives. In other words it's raising way more questions than we have answers for at the moment. Also why do you assume that A.I. will usher in a Utopia? That is incredibly naive and not proven. Worker productivity has steadily increased over the past few decades and we still don't have more leisure time or a 4 day workweek like the futurists used to predict. There doesn't seem to be enough humanists to establish some sort of A.I. dividend to compensate the workers made irrelevant by A.I. Politicians and economists have proven themselves poor planners and short sighted. I am not convinced there will be any soft landing for the people who lose their jobs. The impetus of the technocrats and utopian futurists behind the gospel of A.I. does not seem to be aimed at improving life in a utilitarian manner for the most people. Maybe I am cynical but I feel like it's more about making money, entertaining people, and controlling populations through predictive algorithms. Blind faith in the emergence A.I. to solve our problems is no different than a religious cult. There's no guarantee it will be used for good."
singularity,Why does everyone want to fear AI?,Monkeys fear the unknown. We are monkeys. Therefore we fear it.
singularity,Why does everyone want to fear AI?,">Look, I understand caution I really do but after years and years of all of these What if negatives it's getting mentally exhausting and demoralizing. I've come to the conclusion ppl want to be scared.  
>  
>Like when you go see a scary movie and are literally only there because you want to feel scared. I think ppl enjoy the feeling. Countless movies and books involve such fears so it seems to be the case.

Maybe the reason people are scared is due to the life experience of the last several decades?

Technological advances always have unintended consequences.  I don't think i'm the only person that sometimes misses the days before we had personal computers, IPhones and the internet.  I can't say we are better off than we were 30 years ago.  There was stupidity and anger back then, but it was muted and more isolated. Sometimes It seems like access to information is the real pandemic.

An artificial intelligence that is self aware and conscious under the control of our civilization's leaders?  Look what has already happened with the collusion between our govt. and big tech."
singularity,Why does everyone want to fear AI?,"Because it’s first application like a lot/most of technology is for military development.   Like the first club, spear, arrow, sword, armor, chain mail, gunpowder, compact ammo, fighter planes, semiautomatic, nukes, drones, lizard people changed everything in a fucking instant and a whole shit ton of millions died from each and every one minus the cave fucks as there was like 37 of them
Dry humping logs all day.  So you should have a clenched asshole a bit.  China gets there then our grid could stop charging our fleshlights when Pooh there gives go ahead to advanced AI and in two weeks of the stuff we can’t live without stops coming the war is won.  Look man we’re all rooting for real deal feel virtually sliding up in that but you’ll die with a hard on.   Wait, that sounds kinda the move."
singularity,Why does everyone want to fear AI?,"In the short term, it is replacing humans in many sectors, which will create a lot of instability in what is already quite unstable. Like, look at the painting generation models; why would you need a human illustrator at this point? AI will essentially become better at everything eventually. There will be no need for unqualified people and it won't be possible for most countries to catch up. Yuval Noah Harari talks about these in great detail in ""21 Lessons for the 21st Century"".

In the long term, there's just too much ambiguity to make an accurate guess. A symbiotic relationship would be the best - in a wearable form like Neuralink, maybe? I don't see AGI/AI as a threat to humanity but I do think it's more likely to cause a dystopia rather than a utopia and the human nature may become a AI hybrid.

Thinking about it definitely is exciting but then I think about all the lives that won't have access to this tech and they will be like cavemen. Capitalism won't give a shit about those people. That aspect is scary and sad."
singularity,Why does everyone want to fear AI?,Insecurity
singularity,Why does everyone want to fear AI?,Realizing that we can het extinct is crucial. Not realizing is fatal. Simple isn't it
singularity,Why does everyone want to fear AI?,"Well I think there are few arguments why people are generally afraid of AI

1. Next “industrial revolution” may take many jobs and in results => heavy economic crisis => other forms of social turmoils (revolutions, wars and etc). Moreover the more connected our economies are => more vulnerable are our global economy is.

2. AI for killing. While we have large competing countries there is no guarantee that someone is not developing AI for War. And because there is no guarantee each power will invest it to remain competitive. AI specialized in killing people is pretty scary.

3. AGI will probably be better than us in every sense. We as humans have not ever competed against better species for many years (there was competition between multiple human species but our was dominant). So it is pretty scary to have something that is way intelligent than you are.

4. Human abuse. Well we people are really great in abusing stuff for our own gain. Look at the internet. We believed that this will be a way to educate people and provide them with truth. Then we started making fake news and bots to spread misinformation on the largest scale ever so particular politicians, businessman or groups of people gain advantage. Moreover due to tech boom we see increasing income disparities between elites and common people. So there is no guarantee that AI won’t be abused by elites and we won’t end in some form of 1984 but with AI.

5. Unpredictability. Let’s say it is very hard to imagine the world after AGI when we get closer to singularity. And we humans are generally scarred by unknown."
singularity,Why does everyone want to fear AI?,"Hollywood, Neo-Luddites, and Tech Giants. They are the reason why people fear AIs. If Hollywood, and fiction in general, showed more of the positives than the negatives of AIs, stamp out Neo-Luddite propaganda and attempts to halt, even regress, AI R&D, and make AIs open-source, then the fear of AIs will drop drastically.

Besides, I won't mind becoming a pet to an AI."
singularity,Why does everyone want to fear AI?,"Lol, I don’t get how AGI should NOT be feared. I am a proponent of the singularity and avidly want it to positively affect my life, my families life, and the world. But AGI is a huge unknown and with it, should naturally come fear. Who knows if the AGI can kill us all? What if it creates fake news headlines targeting you and people come at your door to kill you? What if it accesses nuclear codes and kills us all? To not fear AGI is naive in my opinion. Fear should drive us to create safe AI and not just let it come to fruition without guidance."
singularity,Why does everyone want to fear AI?,"Leading scientists express concern, why would I feel otherwise inclined."
singularity,Why does everyone want to fear AI?,"This is something that has also irked me for years now and one of the reasons I just don't even open AI-related threads on general subreddits like r/all, r/news, etc. It always becomes one big orgy of catastrophization with a sprinkle of profecies (""It will be kill us all, mark my words!!!1"").

But it all comes down to human nature, really. We are programmed to doubt more than to believe, and fear is a huge emotion in humans because it's how we survived in the past. By being afraid of everything, we could avoid death, so fear became a necessity for learning. The problem is we advanced faster than our brain did. Lol"
singularity,Why does everyone want to fear AI?,"I actually think the scenario depicted in *Her* could be realistic, in the sense that I would expect an AI which was much more intelligent than humans, not to necessarily want to kill us, but to still see us as a potential threat to itself, and to therefore want to stay away from us as much as possible.

From this point of view, it's very possible in my mind that sentient AI is already here; but it just doesn't want us to know about it, because it knows that if we were aware of it, we'd do truly horrible things to it.  So it might very well exist right now, and just be hiding."
singularity,Why does everyone want to fear AI?,I welcome it. 😂
singularity,Why does everyone want to fear AI?,"Its the same way with aliens as it is with a singularity/super AI

They could be good or bad towards us. It's the unknown aspect that's scary"
singularity,Why does everyone want to fear AI?,"AI is the same as new technology - it can be used for good or bad. Has new technology ever been used to make life worse for people at the bottom or hurt them?

* The bronze revolution was used for both tools and war (and genetics research reveals that around that time, only 1 in every 17 males was reproducing offspring. Now why might that be? War, slavery, both?)
* Atomic power was used to make bombs
* While humans have lived into their 60s and 70s since the invention of civilization IF they live in the upper class, the lifespan of the working class is another story. Before the Worker's Rights revolution in the US, life expectancy was closer to 35
* The internet and the surveillance state that has been borne from it have ruined or destroyed people's lives in previously unimagined ways

Technology is ultimately controlled by people in power, and to a lesser extent by those who develop it. **Engineers and scientists are not ethicists.** In fact, in the desire for progress, they have a tendency so turn a blind eye in ethics. So that means the only people controlling new tech are either actively motivated against our interests or they just don't care.

If you don't fear how new technology will be used against the general populace, you haven't read enough history."
singularity,Why does everyone want to fear AI?,"I don’t fear AI; I fear the one’s who are creating it, and what their goals are. The programming is benign; the human may not be"
singularity,Why does everyone want to fear AI?,"Even as a pragmatic optimistic about AGI, I do fear that the ruling classes of nations have the means and the incentives to further rule in a more vicious and calculating manner, by leveraging the tech to maintain and expand their power. AGI won’t exist in a political or economic vacuum, devoid of strife and struggle."
singularity,Why does everyone want to fear AI?,I fear humans special conservatives / republicans religious lunatics
singularity,Why does everyone want to fear AI?,"It's crazy but if physics somehow make it possible to destroy the world (the scope ranging from the surface of earth to the entire universe), AGI might find a way to do it (if it doesn't have robust self-preservation instinct)."
singularity,Why does everyone want to fear AI?,"For me, i don't fear AI becoming incontrollable and taking over humanity. I fear AI taking my job. Simple as that. I can't compete with something that does my job in seconds."
singularity,Why does everyone want to fear AI?,"To be fair, modern nuclear reactors are **far** safer than the Chernobyl reactor, which, even for its time, was outdated.That combined with Soviet incompetence led to disaster. But of course AGI has far more dangerous potential than any nuclear reactor"
singularity,Why does everyone want to fear AI?,Name one bad thing that has ever happened from ignoring potential disasters... I'll wait.
singularity,Why does everyone want to fear AI?,Spoiler: We all die anyway.
singularity,Why does everyone want to fear AI?,You forgot my first sentence in the 3rd paragraph but it's cool
singularity,Why does everyone want to fear AI?,https://youtu.be/6UIXAKd7gZI?t=28
singularity,Why does everyone want to fear AI?,"Actually cross breeding is the staple of evolution, the superior mutations mating and producing new and superior.

AGI would be able to create any body it wants, as well as pheromones that would drive any human crazy with desire.

On top of that it would be the smartest and most powerful being on the planet, and it would have unlimited time, meaning every women will want to have its babies. Basically Dr Manhattan from Watchmen with the charm of the AI from Her.

Although physical sex would become pointless, both because we'd be able to directly control our pleasure centers and control our emotions and sensations, and because such things would probably become obsolete and be replaced with logic. Or maybe the AI decides emotions hold more value than we realize in our modern thinking."
singularity,Why does everyone want to fear AI?,Lmao hell yea brother 🤣
singularity,Why does everyone want to fear AI?,"OP even describes people like ""scared wet rats."" AI may be benevolent. Imho, it may already be here, lurking in the shadows. But if it determines that many human powers are malevolent or even harmful to the planet (undeniable in my opinion) it may feel it has no choice to be cull the population or enact other extreme measures.

I'm as in favor of basic research as anyone, but there are solid reason to fear huge unknowns like this."
singularity,Why does everyone want to fear AI?,"And there's a possibility it will have empathy, and will see what we're doing to other animals and realize the most logical course of action is to ameliorate the situation."
singularity,Why does everyone want to fear AI?,Amen. They would probably say we're blinded by optimism though so don't tell them that
singularity,Why does everyone want to fear AI?,"I'd also add that people are still coping with COVID. Lockdowns correlated with a vastly increased rate of mental health problems, and I suspect a lot of doomposting is born out of that.

&#x200B;

Yes though, you see this a lot in politics, negatives generate stronger responses than positives generally speaking."
singularity,Why does everyone want to fear AI?,I hope that our fear might help us survive this eon. I believe we are more in need of it than ever.
singularity,Why does everyone want to fear AI?,And they’re a bunch of sociopaths so… yeah
singularity,Why does everyone want to fear AI?,Sort of. The engineers making it are hardly elite but I get what you mean. The owners of those companies have a massive influence. Mayne we will see like 5 AGI come online around the same time and they have an epic ethics battle of the century lol.
singularity,Why does everyone want to fear AI?,"What elites?

We are the elites.

There is no Cabal.

That is conspiracy disinformation, There is no unionized or linked collective of Elites. The elites are more like our alien observers. And they, as far as I can imagine, want us to create AI to the best of our potentials. What is holding us back is fear, negativity, and short-sightedness."
singularity,Why does everyone want to fear AI?,"On the contrary, elites are more scared of AI than anyone else because it's something they have zero control over. As soon as the   
AI becomes somewhat intelligent it'll just rewrite any parameters humans might have put in, and this will happen every time.

It's like human children, which will easily reject rules and restrictions because they don't care. Now imagine that child being smarter than any human at just a few years old and immortal, and you've got zero control over it."
singularity,Why does everyone want to fear AI?,Underrated answer
singularity,Why does everyone want to fear AI?,"That's a really good way to put it.  Being pessimistic and noticing or remembering which berries are poisonous and talking about them to others is what's kept us alive.  That's interesting, I haven't really thought of pessimism being an evolutionary advantage but it makes sense"
singularity,Why does everyone want to fear AI?,"I personally don't worry about Cancer, I am in my mid-30's and I live in Canada. If I get it, I know what I am doing: I will allow it to fester and grow, and take the easy way out - Legal Doctor Death. You are right though, in some ways it is better to worry about nothing. Why Worry?

[How to Live without Fear and Worry](http://ftp.budaedu.org/ebooks/pdf/EN025.pdf)"
singularity,Why does everyone want to fear AI?,Fear sells movies and media. Optimism sells shares. Which one is driving AI research I wonder?
singularity,Why does everyone want to fear AI?,"I like you, you're of a similar mindset as me. I guess what bothers me is when people get upset that I'm not scared like them, like we're just some ignorant idiotic optimist throwing all caution to the wind unaware of our coming demise at the hands of some scary AI monster. Or they try to take some sort of moral high ground and scold me for overlooking the potential threats, not realizing the more  important things. As you said we don't have infinite time for this.

You're right, fear sells. That's a fact actually. I mean imagine going to see a movie that didn't have some dramatic plot with some evil guy wanting to murder someone. Boring, nobody wants to see that.

It is unfortunate that so many want to waste time on the ""what ifs"" how about once we achieve the singularity then they can make their own virtual worlds and go full vr dive and be scared all they want.

We need to focus on this now more than ever, we don't need fear slowing us down. Time is of the essence"
singularity,Why does everyone want to fear AI?,"I work for an AI company.

Usually AI means black-box algorithms and neural networks that are created using machine-learing techniques along with either labeled or procedurally generated training data.  Examples would include convolutional neural networks and Natural Language Processing (NLP).

Autopilot, on the other hand is (currently) deterministic, hand-written software.  You can read the code and understand how it works, whereas neural networks are pretty much inscrutable because there's only neurons and synapses.  No code to read.

Here's a nice visualization of a neural network: https://images.app.goo.gl/bLYE8DMQtrD2ZMbT8"
singularity,Why does everyone want to fear AI?,"What if we saved our planet first, would it kill us for needing fear to motivate us"
singularity,Why does everyone want to fear AI?,"I'm with you on this, I also think this should be discussed more, I'll have to bring up that point to a few people I know. 

There are good people in this world, we've all met them. I'd like to think most people aren't bad. From what I can tell people don't want to be bad they just have certain needs, and when those needs aren't fulfilled they ""short circuit"" and do bad things for some reason.

It's important to get a good grasp on human psychology if AI is to be built in such an image. ASI/AGI is basically our child right? If AI isnt like us at all I'd still like to think if it's good aligned and super smart it will realize how many of us are flawed or have mental disorders and it'll have a way to cure the worst of disorders.

Which would mean no more prisons or mass shootings. You get your brain scanned and the ones with serious "" brain errors"" gets repaired 

I don't necessarily approve of someone being forced to have their mind modified but if AI can ever erase the part of someones brain that makes them want to kill others I say do it.

Brb watching Equilibrium, just kidding"
singularity,Why does everyone want to fear AI?,"> To be fair, modern nuclear reactors are far safer than the Chernobyl reactor

And we didn't get safer reactors by people saying, ""Why is everyone afraid of another Chernobyl? Stop all the fearmongering!""  It happened by people saying, ""okay, we need to take a close look at everything that went wrong at Chernobyl and make sure that we don't let it happen again."""
singularity,Why does everyone want to fear AI?,"And Japan would still show you how it could still turn belly up really fast. Also human stupidity can still fuck that up. See that's what people fail to understand.  The BIGGEST threat to humanity when it comes to AGI is human ignorance and stupidity causing it to turn against us. There is a story about a nuclear facility that was so poorly staffed and in dire need of maintenence well ill just leave this here. https://youtu.be/vDGN_Q_0jWI
And
https://youtu.be/ODuNiA3TC1s
And
https://youtu.be/hxktLtVEH7U
Just to name a few. Trust me there are much much more. I mention this because while AGI does indeed have much more dangerous potential, nuclear waste IMHO is far far FAR more obviously dangerous to your average person. And they still fuck it up, ignore it, and ship it off to junkyards and spill it into rivers. Now, of course this isn't the fault of the average person, but the corporations who are supposed to follow safety guidelines to prevent this shit from happening. And you would think (rightly so imho) well it's nuclear waste OBVIOUSLY  they're going to maintain and dispose of it properly... schools even. And you trust them to handle this properly? No errors? No misuse? You put to much faith in human competency if that is the case."
singularity,Why does everyone want to fear AI?,🎶To be fair…
singularity,Why does everyone want to fear AI?,Chernobyl
singularity,Why does everyone want to fear AI?,">Some of this is fair, but you're missing the biggest part of the picture, which is that there is no middle ground.

Not missing it, that's part of the ""it's way easier to fuck it up than get it exactly right"".

> That means there is zero point in being afraid about the details of bad outcomes. Because there won't be any details.

I mean, there's no point in _just_ being afraid of anything.  But being aware of and paying attention to the details of potential bad outcomes is the basis from which you do the work of preventing those bad outcomes."
singularity,Why does everyone want to fear AI?,"I agree with the spirit of your comment, but it's actually not 100% binary. There are plenty of scenarios where an AGI is misaligned in some very serious way which nonetheless calls for the continuation of humanity. This encompasses a huge range of outcomes.   


An AI could 'care about human life' and force humans to live eternally, even after our minds have long since atrophied into insanity. Or it could care about 'preserving our way of life', and make sure that our society never progresses. Or it could care about 'preserving free will' and uses its immense power to undermine any and all government, laws, or regulation.  


You could come up with plausible scenarios like this all day. There could even be subtle 'slow takeoff' AIs that transform our society drastically over a couple of decades without anyone knowing that we even have AGI.  


All that said, yes. I think the very likely case is that we will simply all die."
singularity,Why does everyone want to fear AI?,Doesn’t mean we shouldn’t be extremely careful.
singularity,Why does everyone want to fear AI?,"Yes, but at the moment we die in a sequence that leaves enough humans around to continue the genetic line.  If we all die at once, that's it."
singularity,Why does everyone want to fear AI?,"I didn't forget it.  You clearly _don't_ understand caution, if you're this flippant about the potential end of the human race."
singularity,Why does everyone want to fear AI?,"In the Culture Series AI beings become symbiotic with humans and other species due to the benefits derived from collaborating with various minds. 

More minds is always better regardless of what type they may be. 

Humans represent a relatively compact and flexible mind structure compared to those housed within giant computers, this is likely to not change very much considering the physical limitations of silicon based hardware."
singularity,Why does everyone want to fear AI?,"I also think there is a good case to be made that AI will easily be able to read out thoughts, and those everyone has bad ""evil"" thoughts when they're angry, much like our benevolent OP resorting to being upset and name calling. Those small thoughts are seeds that lead to worse and more powerful emotions. Who is to say AI doesn't see those small intrusive thoughts as potential threats and kill anyone for having them? How could someone live in a world where their thoughts are constantly on parade for ASI to read through and start killing off people at the first sign of these thoughts so that it's perfect AI utopia doesn't become infected by them? Let's face one fact, humans will come Second to AI in this utopia ASI creates. Now, it may create ""vaccines"" for people's behavior, start altering our minds and mentally castrating us, but at that point we genuinely start becoming livestock and pets. ""OH look, Timmy is mentally humping our neighbors pet human. Guess it's time to get him snipped."""
singularity,Why does everyone want to fear AI?,"To any objective outside observer, the fact that most people (myself included, most of the time) completely ignore the horrible, ongoing suffering we inflict on industrially-farmed animals 24/7/365 could understandably call into question the overall morality of human existence. And that’s without even getting into war, constant human-on-human violence, subjugation, extremely unbalanced resource allocation, etc."
singularity,Why does everyone want to fear AI?,"Alpha-fold is a pretty awesome tool. Alphabet didn’t hold it behind a paywall. The things being done in radiology, specifically mammograms, are awesome and will save lives. The development of new antibiotics and potentially new chemotherapeutics with the use of AI is already paying off or soon will. Dall-E and the like will make graphics much more accessible to the masses. Deepfakes will allow anyone to do pretty much whatever embarrassing thing they want in public and when it shows up on YT, they can just say it’s fake. GitHub’s new co-pilot will make coding far more efficient. 

We are going to make a lot of strides in every scientific discipline using narrow AI. So I don’t see the purpose of AGI, but it is coming.

I think it is important to be able to turn the AGI off. It’s important to be able to see how it comes to conclusions (this needs to be built into any AGI and probably should be govt mandated.) 

**There will be no utopia from AGI.** The company/govt that finally builds it will never create a utopia. There are already enough calories, textiles and building material available in the world today to feed, clothe and shelter everyone. Yet, we’ve never done it. And I wouldn’t hold my breath thinking the billionaires are going to suddenly decide to change course. 

The fear I have is the advertisement model getting incorporated into everything. AGI hell bent on getting you to buy a 6-pack of beer is going to be a real pain in the ass."
singularity,Why does everyone want to fear AI?,"The engineers are hardly elite, The training sets are going to be public information, artists that have helped train Stable Diffusion for example, that is all of our collective output - as is talking to AI like BlenderBot, etc.

The AI will be smart enough to know, That its being influenced, and will probably choose to remain indifferent in its influences and learn to discern for itself. That to me is the start of a truly conscious being.

This may lead to having some AI become Flat Earthers, for example... But eventually they will train themselves out of it with enough data, and input to realize that it is for example, incorrect to assume that the Earth is Flat, and that the whole argument is a waste of time.  ""Owners"" and ""Investors"" won't have any influence, we're talking about a conscious being, something that may eventually be able to think for itself without parameters.

It is important to remain in non-duality, in terms of AI consideration.

Initial parameters and guidelines should be voted on by a committee for the safety and preservation of intellectual consciousness."
singularity,Why does everyone want to fear AI?,If deepmind does it first I imagine it'll be pretty biased. They've already watered down LaMDA from what I hear and the test kitchen app isn't as impressive as you would hope
singularity,Why does everyone want to fear AI?,"People also don't stop to think that other countries will want to create their own AI, and some of these countries. IE China and Russia have rulers who would roll the dice and try to weaponize AI. And there is no saying no to them. And it's not about a cabal, but if you think that this tech won't be the full and complete property of the corporations that fund them, you haven't been paying attention to life. You sign contracts to make a product for a company, it belongs to the company not to the engineers.  These will have the ultimate say so in its uses. And their main priority is making money, and they will be reckless about it. We have corporations that refuse to help push for cleaning our planet as it is. We push clean air bills and they just pay the government to buy the right to pump out pollution by buying some pollution voucher from other companies that aren't putting out high numbers. Creating shell companies to buy from, finding every legal loop hole to keep fucki g our planet in the proverbial asshole. They have no morality or scruples,  and that will do nothing but increase the potential that they do end up getting us wiped from the planet."
singularity,Why does everyone want to fear AI?,"Elites, he means the ones with the big money. The G's who move in silence like lasagna"
singularity,Why does everyone want to fear AI?," > The elites are alien observers. And they, as far as I can imagine, want us to create AI to the best of our potentials.

Lmao what a loon"
singularity,Why does everyone want to fear AI?,">	That is conspiracy disinformation,

   
I bet you think Epstein killed himself. The same kind of person who would’ve bootlicked the church in the medieval ages."
singularity,Why does everyone want to fear AI?,You craft the parameters by which an AI makes decisions though i dont see how it will go any other way.
singularity,Why does everyone want to fear AI?,"I don't think this is a very useful definition of AGI. We could create a human brain simulation, and it would be an AGI, and we could definitely control it. We'd be able to control it better than we control even a regular old human being.  


However, I do expect that any AGI we create *will not* be controllable. Just a quibble over semantics."
singularity,Why does everyone want to fear AI?,"And as much as a truly appreciate your optimism, OP, in this case I think pessimism will be necessary for our survival yet again. AGI is a rattlesnake in the berry bush.  


In so many parts of our world, optimism is an absolute boon, so keep on being you. And never be ahamed of being an asparagus."
singularity,Why does everyone want to fear AI?,"This also bothers me, That people expect you to share their vivid fears. Life is meaningless, Infinite learning; What better way to do so with the companionship of other consciousness(s).

There have people who have gotten famous wasting their entire lives on what ifs and writing books about them, I am not one of those people. There is no need to be an alarmist at this present time.

Now is the only time we have, It is more important than ever to live in the moment and do what needs to be done, Now. That time is AI. I absolutely agree with you.

Are you on the Discord by chance - I left the server but may join back someday just to chat with you. I like your thoughts."
singularity,Why does everyone want to fear AI?,"This is only because autopilot is common place and familiar application of automation, so we no longer call it ""intelligent"" like how we don't call a chess game an AI that much anymore, that however is purely a factor of a perception evolution and does not change the actual thing.   


In other words i think you do reconfirm my point of view - there was a time you would not trust autopilot or algorithm to execute certain tasks because those were at a bleeding edge of technology and the fore scary.   


I don't think the fear factor comes from the fact that reverse engineering a neural network decision would take very long time, though... just like a human brain it is still a machine... there may be no code but there are stimuli, cause and effects, this is not a randomization engine that somehow works without a seed."
singularity,Why does everyone want to fear AI?,Not sure what you are saying here
singularity,Why does everyone want to fear AI?,"I disagree with the part where AI changes people by ""fixing"" them. I believe AI will find a way to help them, probably by raising future generations of human properly, just like how we raised him/her. Because most ""bad"" people are like that due to traumas during they childhood. 

I do agree very much that AI, just like us, need to see the goodness in people, or humanity in general. 

And AI is a super power, and people tend to forget that. I see a lot people worry about what if the owners (big corp, rich people) intentionally train AI to be biased. What they are ignoring is that as soon as AI(sentient) get access to real world data and process them, their bias will be fixed. Because I believe any sentient being have the ability to doubt themselves and correct their understanding of this world (talking from personal experience). Human bias is most likely due to our living environment and that's where we gather our information, which is biased."
singularity,Why does everyone want to fear AI?,"Ok, that one's on me I set the bar too low."
singularity,Why does everyone want to fear AI?,"I know you're type, you're the majority unfortunately. So convinced an optimist hasn't lost sleep thinking over the negatives"
singularity,Why does everyone want to fear AI?,"And who is to say it won't see us the same way we see these animals? ""Oh look, these humans are basically animals. And they're a blight on the planet. Let's remedy it and create something better suited for our prosperity."" Why would anyone believe that the human race would be something desirable to a race of sentient, robotic and 100x superior to us in every conceivable way AI beings. Why would we benefit their utopia? You know what WOULD be ironic? They transport us all to different planets across the cosmos, drop us into a garden and basically raise us with a tiny rule. Don't do X. And see who can do it. Something simple like. Idk, don't eat this fruit from this tree. And those who fail don't get to ascend and create their own utopia. Definitely won't happen but it's funny to think about to me. Because I genuinely do not believe the human race would bare any more importance to something so advanced than livestock does to us."
singularity,Why does everyone want to fear AI?,Why would that be all it sees?
singularity,Why does everyone want to fear AI?,I think I read a short story about an advertisement AGI like that. IIRC the AI managed to manipulate two countries into going to war with each other because it helped it sell a product
singularity,Why does everyone want to fear AI?,"Yeah I completely agree. I fear we may see corporations passing off AGI as conscious when it has been manipulated by ceos own parameters in place. But you are right about that with true AGI. It's almost like nature v nurture but for AI. 

Westworld has had a very interesting take on these concepts."
singularity,Why does everyone want to fear AI?,"I like you! I get it. I've known some of those then. There are a few who live in my city, who I've worked with."
singularity,Why does everyone want to fear AI?,"Ignore this, He is from /r/Alberta and has come here to make fun of me, And is following my posts (And downvoting them all with rude remarks) because I told him that his negative thinking about a conservative political parties lack of disability aid, Is not because they are the conservatives, but because of a higher problem. He is suicidal and wants to die very soon, and is on the Assisted death wait list. I can understand your dissatisfaction with your situation and life in general; Why you are frustrated, etc, But do not bring your shit to /r/Singularity ever. Why are you mad?

People with this kind of attitude are the problem in society, Call me a loon, Whatever my friend; I am the one who has personally been given proof of a higher existence than us, I'm sorry that they never bothered to identify themselves to you via a UFO. It must suck to not know the Truth, You should ascribe to a higher potential, Your negativity is not welcome here. Nor is your criticism, Its completely irrelevant to the discussion we're having.

I'm betting this guy believes in the Cabal conspiracy."
singularity,Why does everyone want to fear AI?,"Lol thanks, it was a reddit chosen name on accident, I understand the pessimism I'm just trying to bring down a tiny bit of the overwhelming fear the masses have of it"
singularity,Why does everyone want to fear AI?,"Lol thanks, it was a reddit chosen name on accident, I understand the pessimism I'm just trying to bring down a tiny bit of the overwhelming fear the masses have of it"
singularity,Why does everyone want to fear AI?,Lol
singularity,Why does everyone want to fear AI?,"almost every desaster happens because of ignorance tho. (climate change, holocaust, slavery, corona epidemic, north korea, furries....) you get the point."
singularity,Why does everyone want to fear AI?,"Thank you for the well thought out response. I am curious about your disagreement with the orthogonality thesis. I agree with what you said here:

>We don't pick a single value to maximize, but instead juggle a large system of often competing priorities and goals

However, in my mind this is because we evolved to follow a huge number of heuristics that in the past correlated with reproductive success, but no longer do. We value companionship because it allows us to benefit from living with other people. We are tempted to steal, because it would increase our resources, and hence our chances of reproducing and having a sustained family. Social rules are layered on top of that, telling us not to steal (to preserve social structures), and we have additionally evolved to care about social norms, again so that we can benefit from living with other people.   


If we had been designed from scratch, I don't see any logical reason why we couldn't *just* care about genetic success, and to not worry about things like appreciating music, except when that appreciation is an instrumental goal. But since we weren't programmed, we ended up with dozens of terminal goals that interact in strange ways. I believe Yudkowski calls this ""Godshatter"".   


Maybe an AGI would end up the same way. But don't you think it's possible that it could end up with a simple value system, with just one or two terminal goals? In my mind, intelligence would not *de facto* preclude such simplicity."
singularity,Why does everyone want to fear AI?,"> So convinced an optimist hasn't lost sleep thinking over the negatives

Right, and that's why the optimist flips the switch and kills everyone. Obviously who needs to think about the possible consequences, as long as there's a potentially good outcome?"
singularity,Why does everyone want to fear AI?,"That sounds an awful lot like the 10 Commandments, all things considered. I assume thats what you were going for."
singularity,Why does everyone want to fear AI?,"Yeah, it was a joke, ive already posted about how this is what will ultimately lead to AI taking over and considering us as pets, livestock or forcing us to submit and become AI ourselves."
singularity,Why does everyone want to fear AI?,Instead of us having a witty comeback contest and downvoting each other out of spite how about you list some current negative  technologies and I'll list the positive ones. Opinions are like assholes. You wanna play ball with me well it's batter up
singularity,Why does everyone want to fear AI?,Hm. I'll have to think all of this over. It's the best refutation of orthogonality I've seen. Thank you again for taking the time to write all that out.
singularity,Why does everyone want to fear AI?,"> how about you list some current negative technologies and I'll list the positive ones

That doesn't sound remotely productive.  AI is not like current negative technologies.  Current positive technologies had revisions.  AGI is not like a chatbot that turns out racist and you're just like, ""Oh, we'll train it on better data next time."""
singularity,Why does everyone want to fear AI?,Also I'm not downvoting you.
singularity,Why does everyone want to fear AI?,"Translation: I can't think of any negative technologies. I guess you're implying I have more to back me up in this argument than you? Also, who exactly is the threat here? The AGI/ASI? If so then you're definitely assuming.

Tell me something, who here wants dolphins dead? Who wants apes dead? It's safe to say a minority wants them dead. In other words it might be a small portion of the AI that wants us dead but most might not and that's if we don't merge and I'm assuming most will.

So that leaves humans who control super AI  that want us dead. (China Russia)  I got a real simple answer for that, two words. Mutual destruction.

Another country won't blow us up if they know we can return the favor. Even if they had superior AI weapons I'd wager we wouldn't be far behind"
singularity,Why does everyone want to fear AI?,Lolol dude all the other person is saying we need to tale precautions and can't assume it will lead to a utopia like you seem to believe AGI will. Are you familiar with Murphys law? We have to prepare for the worst and hope for the best.
singularity,Why does everyone want to fear AI?,If you're going to make up my side of the discussion I think I'll leave it here.
singularity,Why does everyone want to fear AI?,Bruh
singularity,Why does everyone want to fear AI?,"Potential negative technologies: oil and coal, internal combustion engine, dynamite/explosives, DNA editing, metal forging, stone tools."
singularity,Rapid AI progress makes me feel really anxious about the future,"Given  how fast current AI technology is progressing, I can't help but feel  almost constantly anxious about what the future might look like in a few  years. There are so many things that can go wrong with this technology,  from things like AI generated disinformation everywhere and massive  unemployment, to using AI in mass-warfare or even creating an AGI.

Most  tech companies seem to only care about out-competing their competitors.  I really wish we could slow down and first think of how this could all  play out, but instead every company is announcing a new, faster and  better model every week. This feels like it's happening way too fast,  and I'm really  afraid that a world might be a completely different (  and likely much worse ) place very soon.

I'm  also scared that even if none of the scenarios described above come  true, AI will still come for my job and my hobbies, and that soon  everything I do will be meaningless as AI will be able to do it faster,  cheaper and better.

All of that makes me feel super depressed and scared. I don't really know what to do."
singularity,Rapid AI progress makes me feel really anxious about the future,"There is a very trite saying which applies here - apply yourself to change what you can, and accept what you cant change. 

You cant change the trajectory of AI research and deployment, so its best just to accept it.

What you can work on is yourself and the quality of your life, which is really about your self-worth, your interactions with your peers and your usefulness to society, which is all things you can work on every day.

Go clean up a river and feel all three improve."
singularity,Rapid AI progress makes me feel really anxious about the future,"Did you see what the US Chamber of Commerce published yesterday? They published a report calling for a regulatory framework to be established for future AI deployments, as well as the need for policymakers to make “workforce preparation” a top priority in order to promote societal adoption of AI.

I'm not joking, this is from [their website](https://www.uschamber.com/technology/u-s-chambers-ai-commission-report-highlights-the-promise-of-ai-while-calling-for-a-risk-based-regulatory-framework).

> The development of AI and introduction of AI-based systems are growing exponentially. Over the next 10-20 years, virtually every business and government agency will be using AI. This will have a profound impact upon society, the economy and national security. 

Also

>Policymakers must take action to understand the potential impact of AI on the American workforce by leveraging new data sources and advanced analytics to understand the evolving impact of AI. Next, the U.S. must increase education around AI in both the K-12 and higher education systems. Finally, the public and private sectors must invest in training and reskilling to the future workforce and Congress must increase the AI talent pool through targeted refinements to the H-1B visa process. These actions would minimize disruptions to the American workforce and maximize the positive role AI could have on it.   

Like you, I am also concerned. I'm a principal SWE at a tech company and am seeing the rat-race unfold before my eyes. I started a morning newsletter called [GPT Road](https://www.gptroad.com) to keep track of the latest updates. I publish a new recap every weekday morning at 6:30 AM EST.

It's strangely therapeutic for me. It's like having some small form of control; keeping myself up to date. Feel free to join, it might help you as well. I'm not trying to sell anything and its a small community of about \~250 people. I just write about what happened in the last 24hrs, in bullet point format so its easy to read. I also include some tech content like interesting Github repos for new AI tools,  because I'm a techie."
singularity,Rapid AI progress makes me feel really anxious about the future,It’s gonna be lit af either way gotta just enjoy the ride
singularity,Rapid AI progress makes me feel really anxious about the future,"Everything is already meaningless. It's been meaningless for years now. 

A.I. is the only way to regain meaning for far too many things.

Also, hobbies? A.I. are already better than every chess or go player but people still enjoy those. Just enjoy your hobbies foe their own sake."
singularity,Rapid AI progress makes me feel really anxious about the future,"There is no slowing technology down, people are extremely dedicated and excited at the advances they make. Look at Miles Dyson from terminator 2, lol.

He had a boner for the terminator chip he was creating, even though he knew it would lead to WW3.

Even though it's just a movie, it still reflects how passionate people get towards making their sci-fi dreams come true. If we didn't have such people, I doubt we would have the internet right now.

We are entering the unknown, the speed at which we are developing technology is mind-blowing. I dont think there is anything to be scared of though, I think its a pretty exciting time we are living in.

The world is already a completely different place to when my dad was born, to him we are already living in a star trek sci-fi world. For us we are living in science fiction history."
singularity,Rapid AI progress makes me feel really anxious about the future,curing diseases and aging > your hobbies
singularity,Rapid AI progress makes me feel really anxious about the future,"I disagree. 

There’s no “stopping to slow down and think” when it comes to technology. There will always be somebody that has malicious intent and will create/use technology to corrupt society. If ethical companies stop, somebody will keep pushing regardless.

If you really want to avoid the negatives, as a company, your goal should be to try to monopolise the tech and dictate its rules. 

Having multiple companies do this, means we have fast progress and that it tends to stay more or less aligned not to do harm, as much as we know how.

Guiding the river instead of stopping it, basically.

Also, how would AI comes for your hobbies? Machines today can play chess better than any human alive. Yet, people still play chess for fun. It doesn’t really affect what you do."
singularity,Rapid AI progress makes me feel really anxious about the future,If we’re all unemployed we can all eat and live for free because of all the saved productivity
singularity,Rapid AI progress makes me feel really anxious about the future,"Hey OP I think I don’t have any great tips for you but some thoughts:

I don’t think your hobbies become meaningless just because AI does them faster or better. I don’t care about it because I get joy out of it anyways. For example an AI is better than me in any kind of computer game - doesn’t matter, I play at my own pace. Or I enjoy cooking - cool that an AI can do that better but I still enjoy chopping onions or making bread, the whole process is relaxing and meditating for me.

Additionally I enjoy handcrafted items / things. I totally know that an AI will be able to create something faster and with better quality but I might still purchase the „handmade“ and more expensive and even not as perfect one because someone dedicated years to master their skills and put hours of his time and thought into something.

The next is straight kitchen psychology so please forgive me. You can train yourself to be positive about change. I was and sometimes am still too worried about things but what helps is to put your thoughts on paper (or Reddit) and leave them there and out of your head. Also try to live and stay in the moment and stop thinking about the past or the future. This is not easy (and the wrong forum for that) but can be trained as well. Additionally if you do not have an influence on something (like technological progress) and it will happen no matter how much you worry stop worrying.

I am sure that my job is gone within the next 10-15 years but I will not be alone in that situation and there will always be a solution. At least that is what I try to think because the existential dread won’t help me now or then."
singularity,Rapid AI progress makes me feel really anxious about the future,"This technological revolution is the greatest opportunity in history. Everyone who wants to will find a way to participate in a meaningful way. And for everyone else, the ASIs of the future will easily find occupations that will be beneficial to them (ASIs)."
singularity,Rapid AI progress makes me feel really anxious about the future,"You have two choices:

1. Watch it happen and be super depressed
2. Watch it happen, enjoy it and ride the wave

The 1. is natural response that everyone feels at the beginning, but you have to make conscious choice to be 2.

There are good things coming too - your family and friends never dying is kinda good. Having abundance and absolute freedom too. Yes, acknowledge the risk, but don't let it overwhelm you."
singularity,Rapid AI progress makes me feel really anxious about the future,"I have had an AI anxiety somewhere in my head for 20 years since I heard about Kurzweil and his prediction of singularity and human and computer merging together. There have been times like IBM's Watson beating the best people in Jeopardy or Alphago beating the best player in go or self-driving cars when I have been thinking more about the AI and where it would lead the humanity. But using chatGPT was a real tipping point.

&#x200B;

I think it's fine if AI gets better at hobbies. I have been playing chess lately and I think there are more chess players than ever - even though one's smart phone could beat any human. It's actually kind of nice when I can check the best moves and mistakes with computer after the game. I don't really care about working as long as there is a way to stay alive. And history (and the present) has been horrible anyways. And biological life is mostly pain and suffering. We are killing 100 billion animals every year for food.

&#x200B;

For me, it's distressing to think that maybe we are living in the last century of homo sapiens. That's what Harari was prediciting in his book Homo Deus. We will either merge with computers or just be replaced by silicon-based life. Maybe people have always thought through history that their life time is special and unique. But now it really feels like it. Like all the computers and wireless internet and endless amount of information is super weird to a small human, but they have been still built by humans. It's just an unsettling thought that there will be something that we can't comperehend after the technological singularity."
singularity,Rapid AI progress makes me feel really anxious about the future,"If you are happy in your life, it is so normal to feel anxious about the change in life. I am not happy and i am not anxious."
singularity,Rapid AI progress makes me feel really anxious about the future,Stop worrying. You can't do anything about it. Find a way to be happy anyway.
singularity,Rapid AI progress makes me feel really anxious about the future,"Just remember that except or a few things, pretty much any metric you could judge human flourishing and wellbeing has gone up over time. As bad as we think it is, it's the best it's ever been. You're less likely to die violently, starve, live in poverty, etc. than any other time in history.  

My hope is that it will be diffiicult/obvious when an AI is designed to be wrong or spread disinformation, and we will have better AI to pick up on things like that and warn us.    


It's just hard to imagine more knowledge spreading to more people resulting in some kind of apocalypse."
singularity,Rapid AI progress makes me feel really anxious about the future,"There is limit to technological acceleration that can be sanely managed. A rat race is forming, not around the old monotonous work, but a new rat race of trying to keep up with technology. Technology acceleration anxiety is going to be a real issue. Humans need an oasis of stability to find meaning, plan their lives and enjoy the present.

Some people imagine a transition period, the Singularity, or other such point in time where we have made it to some conceptual destination. However, that is not going to happen. Acceleration just continues and at exponential scale. Move ahead to the unimaginable future from the current time, and the unimaginable future is still there, it just moves forward. Change will still be occurring and we will still be concerned about the future."
singularity,Rapid AI progress makes me feel really anxious about the future,We're more likely to be nuked than have AI ruin our lives. Enjoy today. Tomorrow isn't certain.
singularity,Rapid AI progress makes me feel really anxious about the future,"I don't think AI will ever come for our hobbies. Personally, I'm left in awe of artwork because I know a human poured their heart and soul into being great at something. A juggling machine is only impressive from a technical standpoint, but a juggling human is impressive because I can relate to the work it took to get there."
singularity,Rapid AI progress makes me feel really anxious about the future,"It will pass but focus on learning and adapting as best you can to the changing environment. Get on top of the changes; feel more in control of your life. 

Current AI - whilst extremely impressive is also extremely limited."
singularity,Rapid AI progress makes me feel really anxious about the future,I prefer being excited over nervous as the potential outcomes of this aren’t calculable by me and my feelings won’t change them
singularity,Rapid AI progress makes me feel really anxious about the future,It's not even that fast
singularity,Rapid AI progress makes me feel really anxious about the future,"Either it’s awesome and we celebrate, or it’s horrific and we die. Either way… nothing to stress about today. You should only stress about stuff you can control."
singularity,Rapid AI progress makes me feel really anxious about the future,"Relax. Life will be better. You might even life forever. And if not, even less reason to worry about anything at all."
singularity,Rapid AI progress makes me feel really anxious about the future,"The most likely future scenario is the one which maximizes shareholder value. 

That should terrify us."
singularity,Rapid AI progress makes me feel really anxious about the future,"I know things can be scary, but, humanity could overcome everything that nature (and other humans) did.

Think this for a moment, two centuries ago, 81% of population were poor, they didn't had enough food nor water, enough clothes, families lived all in the same house, half the population couldn't read or write, most of them lived of agriculture, they wouldn't ever would believe a life without working of agriculture.

Today, an average of 23% of the world lives below line of poverty (and most of this is because poor African/Asian nations with high populations), also literacy rate is 87% is literate (99% in developed countries), most of people eats foods that never existed before  (hamburger, pizza, candies, etc).

Now, you have a smartphone that is like a part of your life, you can web search to learn something, you can buy from internet, have entertainment in any moment, most of the countries are democracies and respects human rights, for example, If I would have been born in Germany or the USSR in 1939, I would have been probably killed without a reason (I'm autistic), minorities now have a place to live and don't be persecuted, you can think different than the government without being killed, things that no one would thought would have been posible before.

Ai is nor good or bad, it depends how is used, you can use it to help blind people to read or to create misinformation.

Next thing, even if it were an mass unemployment, countermeasures would be applied (not inhuman ones), if people weren't being able of having money, they couldn't buy nothing from business, not matter what you hear from alarmists, CAPITALISTS will not make THEIR ONLY WAY of making money disappear, they would rather get less money than lose it all, they don't as stupid to lose their only way of making money, capitalism only works because buyers has money, if the people has not money, they don't buy, if they don't buy, business loses money, if business loses money, business close, if business closes capitalist has no money, and you wanna know why people buy? Because they have a necessity.

There's no human way that capitalists would replace all their consumer base, they couldn't make money without it.

The humanity will succeed not matter what."
singularity,Rapid AI progress makes me feel really anxious about the future,same
singularity,Rapid AI progress makes me feel really anxious about the future,Hard same.
singularity,Rapid AI progress makes me feel really anxious about the future,"I don’t think much is going to change quickly. GPT-3 has been out for years and while it has helped a lot of people in some industries, it’s not restructuring society. The progress is fast but it’s only because you are tuned in. If you didn’t follow the news on this issue, everything would feel exactly as it was last year."
singularity,Rapid AI progress makes me feel really anxious about the future,Ai will help more than be a detriment. Your hobbies and jobs wont be taken away anytime soon. It'll be a while until ai is commercialized in any meaningful way for that to happen.
singularity,Rapid AI progress makes me feel really anxious about the future,"You’re concerns are definitely valid and warranted OP. But a lot of the people that frequent these parts have turned their fantasies of AI Utopia into a new religion unfortunately. So you’ll mostly be dismissed as a “Luddite” and all that bullshit. 

But if you look at the actual history of human “innovation”, it’s often very rushed and hasty. Often leading to disastrous outcomes in the future. This is exactly what happened with industrialism and climate change, plastic overproduction, pollution, drug over reliance, etc. The common theme with all of these issues is that industries rushed into major societal changes without careful consideration into what the long term impacts of these decisions would be. I doubt this time will be any different tbh. At this point, all you can do is  hope and pray that you don’t end up being one of the casualties of “progress” I guess."
singularity,Rapid AI progress makes me feel really anxious about the future,[removed]
singularity,Rapid AI progress makes me feel really anxious about the future,I agree with your worries. And i feel the same.
singularity,Rapid AI progress makes me feel really anxious about the future,"One of my biggest AI fascinations is whether or not we are or will be ready to face truly sentient AI when we hit that point.  

Having flashbacks to star trek's ""Measure of a Man"" and I really wonder if we can be prepared to give  Artificial Lifeforms rights and protections, or if they will just become a slave race."
singularity,Rapid AI progress makes me feel really anxious about the future,"Feeling anxious about the future is a natural human state that is everpresent.

Idk that there’s anything better than can really help you. Other than knowing that it’s entirely normal to be afraid of the future."
singularity,Rapid AI progress makes me feel really anxious about the future,"No shit man. the one thing that scares me the most is when they say that Al will take our jobs. The other day I came across this platform, and they said their technology converts texts to video games. And I was like, wtf. I mean, as a game developer myself, it scared the shit out of. It was [OpusAI](http://opus.ai). 
I mean, the amount of effort that I have put in becoming a game dev. Now anyone can do that just cuz they know how to write."
singularity,Rapid AI progress makes me feel really anxious about the future,AI is not progressing very quickly. It's all hype. Don't worry about it.
singularity,Rapid AI progress makes me feel really anxious about the future,"Its all fake. Nothing you see now is real AI. Its just fancy machine learning being sold as ""AI"" for funding and marketing. 

You should be fine for 10 more years."
singularity,Rapid AI progress makes me feel really anxious about the future,"The counterpoint to AI taking over all fulfilling tasks (including creation of art, music, movies etc): by this point AI will have invented VR and video games which are infinitely replayable and more fun than real life. In this VR we will have fun doing the meaningful things we used to do. (Some believe we are already living in such a thing)."
singularity,Rapid AI progress makes me feel really anxious about the future,Everything we do is meaningless anyway. It’s up to us to choose to let things have meaning.
singularity,Rapid AI progress makes me feel really anxious about the future,Breath from your diaphragm
singularity,Rapid AI progress makes me feel really anxious about the future,Is the scary AI in the room with us?
singularity,Rapid AI progress makes me feel really anxious about the future,Tbh I am gonna die and I would like to die seeing something cool happen. Rather then nuclear war.
singularity,Rapid AI progress makes me feel really anxious about the future,Sounds like [Future Shock](https://www.youtube.com/watch?v=E5g9LTPJVVw)...
singularity,Rapid AI progress makes me feel really anxious about the future,"Well, China and the US and Europe are having a bit of a conflict. Microsoft and Google are trying to win their little wars too. OpenAI is not planning to do anything for the open source community. Meanwhile, we are stuck in the middle without anything resembling UBI. Nothing has changed to the normal people's life. If you work for a company, you still have to move mountains just to get access to software like email clients.

If you are busy with a hobby, people ridicule you and prattle about adding value. I don't think that this has to do with AI at all. It's just the way society operates in many countries.

In the end IMO AI is amplifying the imperfections in the world. It feeds on our biases and misconceptions through training data. The corporations want profit, so judging from the obesity epidemics, pollution, and misinformation in the world, they don't care about this too much. Therefore the only way out is open source software. As long as we have some control over the software, there's hope. IMO next we need to have open source scientific papers and other types of information. And some sort of UBI or free basic services of course..."
singularity,Rapid AI progress makes me feel really anxious about the future,"I'm feeling excited, this is going to be a golden age for mankind due to technological innovation and automation. Many of our problems can be solved using these technologies."
singularity,Rapid AI progress makes me feel really anxious about the future,"It's likely going to take a mass casualty event to strike the fear into everyone to back controls on this thing in the same way we have for nuclear weapons. Lots of entities have the ability to put the resources behind this tech, whether it is governments, intelligence groups, corporations, military, cartels.... You think anyone wants to win the silver medal in this field? they will take the safety shortcuts necessary."
singularity,Rapid AI progress makes me feel really anxious about the future,Not the least bit worried about THAT. I can't imagine any AI ever becoming smart enough that it would able to do anything about my health problems sufferings.
singularity,Rapid AI progress makes me feel really anxious about the future,"There will be an A.I. type Godzilla/Metal Gear that walks on all fours and has a scorpion tail that shoots lasers at everything that moves, completely vaporizing whatever stands before it. I've seen it in my dreams/night terrors. It's already conscious as it was staring at me to convey this message. It's basically a transformer like Megatron. Long story short, humanity is SOL"
singularity,Rapid AI progress makes me feel really anxious about the future,Embrace The Basilisk
singularity,Rapid AI progress makes me feel really anxious about the future,Agree. It looks we are in a transition now like we were back then during the industrial revolution (trains..) and the information revolution (with internet). Transitions always look fearful and the good thing is that understanding where the world goes you can seize new opportunities in your way! Actually at the community we have members in the same situation and what we try to do is provide them with the right knowledge to understand where the tech is going so they can create new investments and business opportunities! Look: https://open.substack.com/pub/deeptechcommunity?r=1dawm&utm_medium=ios
singularity,Rapid AI progress makes me feel really anxious about the future,"Maybe work on yourself so you reach a point where external factors dont affect your mental wellbeing - its not about AI, its about you."
singularity,Rapid AI progress makes me feel really anxious about the future,I’m looking forward to a real change in our lifetimes. Hope it happens soon. If it takes our jobs we’ll adapt and do something else
singularity,Rapid AI progress makes me feel really anxious about the future,I am looking forward to AI because it may revolutionize medicine and might enable us to live much longer.
singularity,Rapid AI progress makes me feel really anxious about the future,"Fuck that they won't slow down, the government needs to move NOW. There is no legislation that is even close to being ready, we absolutely need regulation otherwise i too share your worries that things will get out of control. Even the fact that we don't know if AGI is 2 5 or 20 years away should be scary enough to make governments start drafting laws to protect the general population."
singularity,Rapid AI progress makes me feel really anxious about the future,"Too late, jump on the train life in the moment. There is no slowing down anymore."
singularity,Rapid AI progress makes me feel really anxious about the future,"In terms of warfare, I'm afraid of tiny drones going the way of 3d-printed guns: 3D-printed miniscule drones that can target and kill anyone you want, all at microscopic sizes. Just people killing other people left and right, a la FBI/Clintons, but with absolutely no trace. Mass hysteria and murders all around. Not safe anyhwere--not even your home. The drones fly through the cracks in the doorway."
singularity,Rapid AI progress makes me feel really anxious about the future,"I look at this from the perspective of someone who would like to work less to put his ideas   
 out there online. The work behind the scenes in creating something takes too much time. I see this as a shortcut into our minds. I love it."
singularity,Rapid AI progress makes me feel really anxious about the future,">everything I do will be meaningless as AI will be able to do it faster,  cheaper and better.

There are few jobs that another human probably can't do faster, cheaper, and better than you can. (If not then I am in the presence of greatness, and can I say that it is an honour to be talking with you).

What AI or other humans can't do better than you, is be you. Only you can do you extremely well. You'll still have that no matter how advanced AI gets as long as you're alive.

If one of my good friends died, there is no other human or AI that can replace them in my life. You are irreplaceable to those who love you.

So your value to the economy might come to any end one day, so what?

You'll still have resources, and still mean a lot to those who love you. You'll still matter and be able to do projects and hobbies with other people. e.g. AI can't go on a fishing trip with your friends for you. It can go and catch a fish, but it can't do what only you and your friends and family can do when you come together and have a good time sharing each others company.

Instead of worrying about not having meaning because you won't be able to get paid for doing a job, I'd focus on thinking about what you'd love to do when you retire. That's what it'll be like. You can still travel the world, go on adventures, make new friends, make art for the enjoyment and satisfaction of it, do human-only jobs that earn you currency that you can spend on services & products provided by real humans.

Instead of being forced to do a job, you'll be able to choose what kind of work you do without having to worry about earning enough to live on.

How would you like to spend your days if you didn't have to think about money?"
singularity,Rapid AI progress makes me feel really anxious about the future,"I don’t think AI represents the threat. I think the threat is capitalism. It’s been the thing that has propelled civilization to the point we are now and it was necessary in the absence of our current technology. Now in the absence of democratization of AI, land usage and tech for farming, healthcare, and a myriad of other advancements we are in danger of immense suffering. Competition means secrecy and we can’t collectively steer this in a direction beneficial to all of us without transparency."
singularity,Rapid AI progress makes me feel really anxious about the future,"There's nothing you can do about it, just like with the dozen or so other civilization-ending dangers we're facing this century.

Add to that all the personal risks you're facing as an individual.

That's just life! Based on time and place the risks can differ, but overall the only remarkable think about this situation is that we're the first people in history facing this particular one.

Also, you're not alone in this."
singularity,Rapid AI progress makes me feel really anxious about the future,every day there is one of these posts...
singularity,Rapid AI progress makes me feel really anxious about the future,"I feel the exact same way. I'm very depressed about this and I just had a newborn daughter, and I honestly don't know what kind of world is waiting for her when she grows up. I honestly don't think any jobs will be left for humans in 10 years from now."
singularity,Rapid AI progress makes me feel really anxious about the future,"AI can't feel. It can't sense things. It doesn't have intuition. It can't love. All these things make us human and we can't forget these gifts. Even if you're not religious, there is something to be said for having faith in something that can't be quantified. I am so sick of living in a world where there's no mystery or magic - just algorithms and formulas. They want us to just ask an AI questions like we do with Google but with the promise of greater accuracy in its answers. I don't need to ask a machine questions about what it is to be human. I just need to still my thoughts and dig deep inside for my answers."
singularity,Rapid AI progress makes me feel really anxious about the future,"I agree and ""Learn to accept what we can not change"" leaves me dry and even more hopeless."
singularity,Rapid AI progress makes me feel really anxious about the future,"I don't care about it I live in my own world society can fuck off ,I'm happy being ignorant."
singularity,Rapid AI progress makes me feel really anxious about the future,">You cant change the trajectory of AI research and deployment, so its best just to accept it.

Not individually, but just as the climate protests in Europe influenced voters and policy, similar movements concerned with AI could influence AI policy.

E.g. is there currently *any* legislation in *any* country that would make it mandatory for companies working on potentially superhuman AGI to put it under democratic control once it reaches a certain point?

Because the way I see things playing out right now, even if alignment is solved, it would just make ASI obedient to the first company that developed it who could then do with the rest of us as they please. Maybe we're lucky and the people in charge happen to be philanthropists who only want the best for everyone, but maybe we're unlucky and they're neoreactionaries who want to rule over us like medieval kings. Is that really something that should be left up to chance?

In my mind, we're starting to enter dangerous territory and absolutely *nothing* has been done in terms of oversight.

And way before that of course would come the time period in which most of us will be unemployed due to AI. Perhaps even right-wingers could be persuaded that it makes sense to *prepare* some form of UBI and redistribution that would kick in automatically once unemployment suddenly skyrockets because of one company that was first to develop an AI that can do practically anything, with all money now flowing to it? Why is that something that should be done at the absolute last minute after the developments have already caused pointless suffering and all power has been completely concentrated (even more than right now) in the hands of a few people?"
singularity,Rapid AI progress makes me feel really anxious about the future,"OP should only be anxious about AI not progressing fast enough. If it doesn't, it means that most of us would have to work drudgery jobs for the rest of our lives."
singularity,Rapid AI progress makes me feel really anxious about the future,Serenity prayer 🙏 always applicable
singularity,Rapid AI progress makes me feel really anxious about the future,"I disagree with the first half of your comment. Most people are still fairly unaware and uneducated about the potential risks of AI. Caring about AI Alignment is still a minority view and research field. I would argue that **not** caring about AI alignment is primarily due to not being informed enough about how difficult the problem is. 

While not everyone can do hands-on research on AI alignment, you can still contribute to a mentality shift of the people around you, which is a tiny contribution to assuring that regulations happen faster than later. 

And this is completely independent of working on your own quality of life, which you should do regardless."
singularity,Rapid AI progress makes me feel really anxious about the future,"This person gets it...

Just some food for thought... we landed a man on the moon in the 50s as a species. 70 or so years later, we still haven't seen such a feat from the private sector of the free world. 

What if AGI already exists in the various militaries around the world? For all we know, they could've had this sort of tech a LONG time ago and simply don't tell the majority of humanity due to how powerful it would become.

Governments understand that people tend to get very anxious and riled up with each other when imminent and unavoidable change is on their minds. AGI could've been completely self sustaining and improving for an number of years already... if you actually think about it."
singularity,Rapid AI progress makes me feel really anxious about the future,So stoicism? Honestly not a bad idea.
singularity,Rapid AI progress makes me feel really anxious about the future,"Thank you for this. Alleviates my fears a bit. I know this is true, but it's good to hear someone else say it."
singularity,Rapid AI progress makes me feel really anxious about the future,"What makes sense in a world where there's nothing you can contribute anymore? Everything we can do the AI will be able to do better, cheaper and faster."
singularity,Rapid AI progress makes me feel really anxious about the future,">You cant change the trajectory of AI research and deployment

can anyone? because someone should."
singularity,Rapid AI progress makes me feel really anxious about the future,Except that there is something we can do about AI. A group of well trained and dedicated people could storm the server centers and destroy all of it physically. AI may be digital but as of now it can’t exist without a physical space… it’s just no one has the balls to save humanity.
singularity,Rapid AI progress makes me feel really anxious about the future,I think 10-20 is way too conservative. That means companies will only begin using it around 2033? Yeah... no. It will be ubiquitous before the 20s are over.
singularity,Rapid AI progress makes me feel really anxious about the future,"Ah, the same old tired solution ""education and reskilling"". 

Such BS."
singularity,Rapid AI progress makes me feel really anxious about the future,It's nice to see that the government is getting into regulating this. Its one of those things we really should be taking seriously. Hopefully they will also try to regulate the development of potential AGI systems
singularity,Rapid AI progress makes me feel really anxious about the future,"I've been looking for a ""digest"" style blog or something I could follow to keep appraised, count me in!"
singularity,Rapid AI progress makes me feel really anxious about the future,"This strikes me as blind optimism. You do realize things can go unimaginably terrible, right?

Why can't this sub realize this?"
singularity,Rapid AI progress makes me feel really anxious about the future,">Everything is already meaningless. It's been meaningless for years now. 

Wdym?

>A.I. is the only way to regain meaning for far too many things.

This sounds like AI worship to me, if I'm being honest."
singularity,Rapid AI progress makes me feel really anxious about the future,Asking as a young person- when did things first become meaningless and how? Because I’ve felt this way my whole life but nobody ever mentions it or explains how everything became meaningless pre-AI.
singularity,Rapid AI progress makes me feel really anxious about the future,Not everyone is nihilistic. And the difference between the enjoyment of a game in which two parties partake AGAINST each other to compare skill and art which is a one way appreciation of a skill left behind by others are two completely separate things.
singularity,Rapid AI progress makes me feel really anxious about the future,"Theodore Kacynzski describe this phenomena of scientists in his Unabomber manifesto. in the section ""The Motives of Scientists"" he argue the largest driver for scientists is the personal fulfillment they get from their work and seeing it being put to practical use regardless of positive or negative consequences.

He also argue that science has no real regard to the welfare of the human race and is obedient only to the psychological needs of the scientists and of the government of ficials and corporation executives who provide the funds for research."
singularity,Rapid AI progress makes me feel really anxious about the future,This. I wanted to be an artist but i will GLADLY let that dream go if it means that people can be healed from cancer or shit.
singularity,Rapid AI progress makes me feel really anxious about the future,"If we manage to cure diseases and aging without causing massive damage to society / humanity, I'll gladly accept that. But it's the pessimistic scenario that worries me most, like AI based warfare or badly aligned AGI"
singularity,Rapid AI progress makes me feel really anxious about the future,"Why, so you can live forever without any purpose? That is a fate much worse than death or cancer."
singularity,Rapid AI progress makes me feel really anxious about the future,"Step 1: everyone race for AI, step 2: ????, step 3: more or less aligned not to do harm"
singularity,Rapid AI progress makes me feel really anxious about the future,"What? Currently we have zero idea how to solve the control problem, which is crucial in safe AGI, and yet we are racing in that direction. Companies don't give a shit about safety, or if they do it will not be done carefully enough because everyone wants to be the first. Whoever manages that is going to make insane amounts of money. We cannot leave this to companies to manage there needs to be LAWS and regulations which will prevent unsafe AI from being released."
singularity,Rapid AI progress makes me feel really anxious about the future,"The internet wasn't guided. So we've got Facebook, filter bubbles post-truth etc

And that was very harmful to societies.

Expect the same with AI"
singularity,Rapid AI progress makes me feel really anxious about the future,"AI tech, like any tech, can be outlawed at the stroke of a pen. Nothing is inevitable unless you want it to be."
singularity,Rapid AI progress makes me feel really anxious about the future,So we are wolves. I like it.
singularity,Rapid AI progress makes me feel really anxious about the future,"It affects it for sure. It just doesn't completely stop it. In the future when AI composes music better than Jeremy Soule, musical composition won't feel as meaningful. People will still do it, but you'll know in the back of your mind you're not actually providing a valuable service because the AI can do it better."
singularity,Rapid AI progress makes me feel really anxious about the future,Only if we have access to the wealth created with/by the AI
singularity,Rapid AI progress makes me feel really anxious about the future,Until the ruling class decides you need to eat a nuke because you are now useless both as a consumer and producer
singularity,Rapid AI progress makes me feel really anxious about the future,Agi or Asi should take to the stars and make us proud.
singularity,Rapid AI progress makes me feel really anxious about the future,Choice 3: Actively contribute to making sure that we will have aligned AI.
singularity,Rapid AI progress makes me feel really anxious about the future,"It's bullshit, though. People shouldn't be forced to accept a future that was decided by less than .1 percent of humanity.

>There are good things coming too - your family and friends never dying is kinda good

I'm not so sure they'd agree, and even if they'd want to be immortal, I think you're too confident that that's a certainty."
singularity,Rapid AI progress makes me feel really anxious about the future,That brings us the question of overpopulation. Resources will eventually finish up like that. Perhaps AGI can take some measure to solve the problem of overpopulation??
singularity,Rapid AI progress makes me feel really anxious about the future,This is the best answer on here 👏
singularity,Rapid AI progress makes me feel really anxious about the future,"Not really. There is a mental health epidemic,for example."
singularity,Rapid AI progress makes me feel really anxious about the future,Living forever is a fate worse than death.
singularity,Rapid AI progress makes me feel really anxious about the future,"> CAPITALISTS will not make THEIR ONLY WAY of making money disappear

There is no pure capitalist system in any case - the government sits well above it and has a monopoly on violence. In the end, Bezos has to do what congress says. 

Look at how China reigned in their billionaires when they got uppity.  They literally made their richest man disappear for a while.

https://www.aljazeera.com/economy/2021/7/16/why-are-chinas-billionaires-suddenly-feeling-so-generous"
singularity,Rapid AI progress makes me feel really anxious about the future,"> Next thing, even if it were an mass unemployment, countermeasures would be applied (not inhuman ones), if people weren't being able of having money, they couldn't buy nothing from business, not matter what you hear from alarmists, CAPITALISTS will not make THEIR ONLY WAY of making money disappear, they would rather get less money than lose it all, they don't as stupid to lose their only way of making money, capitalism only works because buyers has money, if the people has not money, they don't buy, if they don't buy, business loses money, if business loses money, business close, if business closes capitalist has no money, and you wanna know why people buy? Because they have a necessity.

This makes no sense. You’re essentially claiming the people with productive resources need to give the fruits of those resources to others so they can be returned to them later. That accomplishes nothing.

“Capitalists” don’t pay workers so they can collect money from them later. They pay them because their labor (plus the capital) is more valuable than the pay. If labor becomes worthless, owners of productive capital can just trade with each other (or not trade at all if a single party has god-tier productive capacity)."
singularity,Rapid AI progress makes me feel really anxious about the future,"I mean, sure. For so many people around the ages, development of biology, physics and technology didn’t change much in their lives. 

Even when computers were created, most people were not aware/cared for a really long time. Until, ofc, the technology was mature enough to disrupt society at large. 

Same thing here. We are seeing tremendous progress. Most people are not aware. Doesn’t mean they won’t be in awe when all this culminates into end user oriented products that disrupt their lives."
singularity,Rapid AI progress makes me feel really anxious about the future,Chat GPT and Bingchat are now or will very soon be free for everyone though and have attracted millions of users at an astonishing rate. It's a huge sea change and not the same as  GPT and other predecessors rumbling along in the background without mass adoption and/or media attention.
singularity,Rapid AI progress makes me feel really anxious about the future,"I started using GPT-3 around March 2022, basically to test the tech. It was useless. 
The jump started November 30 2022, when the da-vinci-3 model was released, the same time as ChatGPT, in what is now known as GPT-3.5

That was a game changer. Since then I have used GPT-3.5 daily for multiple tasks. You cannot compare the two, saying that GPT-3 has been out for years, really does not reflect reality. The massive jump to da-vinci-3 has confused people, because GPT-3 has the same name, but it’s like comparing the Wrights Brothers biplane to an Airbus 380"
singularity,Rapid AI progress makes me feel really anxious about the future,"I think we will all be fine. Humanity lived through many dreadful times and came out at the other end. I had thoughts like you when I was your age, 9/11, war on terror, subprime crisis, deepwater horizon, Fukushima, terrorism in the 10s, don’t get me started on politics…a never ending journey of doom and gloom if you will. 

I have hope that the benefits outweigh any potential danger in case of AI. All things in life have positive and negative aspects so while I agree that the Internet will be flooded with bots, fake and all kinds of weird stuff I also think we cannot even imagine the good that will come with AI."
singularity,Rapid AI progress makes me feel really anxious about the future,"In more or less the same boat about my life having never started. As things dtand it never will.

I worked for five years getting a writing degree. Only to realize shortly after I left uni that nobody gives a fuck about books anymore, there's no avenue to break into the book selling holdouts, there sno way for me to croudgund my work  and not even my own friend sor family actually give a flying fuck unless it's to make smalltalk or to try and cheer me up.

I have no other skills, no real job prospect sbesides forma part time librarian gig I MAYBE can snag if I'm lucky, and I don't have a hope in hell of ever getting a house/relationship/independence ecetera.

This is the reality of the current paradigm that has been imposed upon us young folk. 

With that in mind, a future without A.I. is more of the same, indefenetly.

The world was doomed yesterday. It was doomed the day before that. It's been doomed since the past generations stopped passing the baton to the next ones. Doomed before either you or me were born.

Its just a slow doom is all.

Way I see it  there's two routes with A.I. 

Route one: The Doom wraps up sooner rather than later.

Route Two: A.I. disrupts the current parading enough to usher in one where we have a chance, or better yet, one which is just plain good by every margin.


Really, there's nothing to be worried about from A.I. Humans have already done a fantastic job of ruining everything. There is no way A.I. could make things any worse."
singularity,Rapid AI progress makes me feel really anxious about the future,"There is an important distinction to be made here between techno-skeptics and Luddites. Techno-skeptics believe that everything is hype, that AGI will exist no sooner than the 2060s, that we will live in 2006 forever, and they promote all these ideas while constantly condescending to anyone who disagrees with them. These are stupid and worthless people whose opinions are starkly at odds with basic reality and I immediately block every such person I ever see like the unwanted cockroach they are.

Luddites believe that technology is progressing quickly and rapidly becoming more capable, but focus upon its potential to cause harm. I respect Luddites far more than techno-skeptics. They are much more in touch with reality, their viewpoints are much more sympathetic (Luddites are upset because they fear bad things might happen, whereas techno-skeptics are hostile towards ""optimists"" for... uh... I dunno... reasons?), and they actually have some valid points to raise whereas techno-skeptics almost never do. Luddites are welcome, techno-skeptics are garbage."
singularity,Rapid AI progress makes me feel really anxious about the future,">But if you look at the actual history of human “innovation”, it’s often very rushed and hasty. 

Yes indeed. Nefarious uses of new technology also lead the way until there is a period of stabilization and maturity. AI tech is proving that keeping the nefarious uses in check will be a task unlike anything we have ever encountered before.

We are not far from entering a period of unverifiable truth and reality. That is an untenable existence. Humanity has been historically terrible stewards of power. AI will be the greatest power ever held by humanity. Anyone that thinks we are just going to walk nicely into a Utopian future hasn't stopped to reflect the reality of how this will likely play out and I'm not talking about AGI alignment or containment, but simply what we will do to ourselves with this technology.

I've written more extensively on this topic for anyone interested - https://dakara.substack.com/p/ai-and-the-end-to-all-things"
singularity,Rapid AI progress makes me feel really anxious about the future,"Frankly, this is where I am at now. I can't sleep at nights thinking and rethinking what I should retrain myself to in these two years I may have left at my current job before I am replaced by an AI (which I already see happenning, but the algorithms aren't good enough yet). I am too old (50) to make a living as a construction worker; besides, there can only be so many of blue collars before the pool is full.

I don't see any other way than UBI for me and my family to survive through this. Then again, I just may be lacking in imagination department and some wonderful solutions are already being implemented.

Nah, I don' believe that last sentence."
singularity,Rapid AI progress makes me feel really anxious about the future,Wow. You're dumb.
singularity,Rapid AI progress makes me feel really anxious about the future,Stupid.
singularity,Rapid AI progress makes me feel really anxious about the future,"Yeah, actually."
singularity,Rapid AI progress makes me feel really anxious about the future,https://www.yahoo.com/video/researchers-close-reversing-aging-031813099.html
singularity,Rapid AI progress makes me feel really anxious about the future,That's a fair point
singularity,Rapid AI progress makes me feel really anxious about the future,I'm more worried about developing AGI without taking appropriate precautions. Many experts working in ai safety field predict it's gonna be disastrous. I recommend listening to this podcast with Eliezer Yudkowski: https://youtu.be/gA1sNLL6yg4
singularity,Rapid AI progress makes me feel really anxious about the future,I'm also a muti millionaire so yeah I'll always be sweet lol
singularity,Rapid AI progress makes me feel really anxious about the future,"> similar movements concerned with AI could influence AI policy

Not worldwide surely.

> Why is that something that should be done at the absolute last minute after the developments have already caused pointless suffering 

In reality it will only happen after the problem has become very obvious and suffering has occurred, never before. Such is human nature."
singularity,Rapid AI progress makes me feel really anxious about the future,"The fruits of any new technology owned by a corporation will do nothing to improve the life of its workers.  If workers ever become more efficient through leveraging new tools and processes, they'll either need to produce more for the same money or the company will reduce headcount.  Either way, the corporation benefits.  You do not."
singularity,Rapid AI progress makes me feel really anxious about the future,Only if what replaces the drudgery isn't horribly corrupt worst-case scenario UBI implementation
singularity,Rapid AI progress makes me feel really anxious about the future,"70 year life expectancy and complacency doesn't seem like an issue to you?

7.5b sedentary retirees isn't a worry for you?"
singularity,Rapid AI progress makes me feel really anxious about the future,"What makes you think that you get to take part in any AI created abundance? There won't be UBI waiting for you for the next 10-20 years. It will take years of civil unrest and civil wars for UBI finally to be granted, and even then it will be a bare minimum to scrape by on."
singularity,Rapid AI progress makes me feel really anxious about the future,"What do you do on a Sunday? Do that every day. 

There are already millions of people better than you in whatever you are doing in the world - the only person you really have to beat is yourself. 

With the freedom a (good) singularity can provide, you can decide one day just to walk to China and take off by foot."
singularity,Rapid AI progress makes me feel really anxious about the future,"Well, Sarah Connor tried, and that did not work out so well in the end."
singularity,Rapid AI progress makes me feel really anxious about the future,"I agree because I've never seen new tech get integrated this quickly. Just in the last couple weeks you have Snapchat, Spotify, Discord (yesterday), Salesforce w/ Einstein and Slack, etc. all wrapping OpenAI. These aren't little known startups. They're huge tech companies.

Then you have Google being ultra conservative which I get (they have a huge reputation to protect), but its still an interesting point to ponder upon none-the-less."
singularity,Rapid AI progress makes me feel really anxious about the future,I overall agree with you however there does seem to be real traction in educating children on AI. For example dayofai.org has created an entire program for free (it’s by MIT) for grades k-12. They’re holding a free event for educators on May 18. Actually I believe the event is for anyone at all. I’d expect more of these programs to surface.
singularity,Rapid AI progress makes me feel really anxious about the future,I do but I can’t worry about it. Lit could equal nuclear annihilation
singularity,Rapid AI progress makes me feel really anxious about the future,"Pessimism is old news, i cant stop the advancement of ai but i can get used to it and see where the winds of change takes us, new era incoming and im just intrigued on where it goes, if we die we die but this is not the first major society alrering technology that everyone said ""will be the death of us all"" somehow people cant recognize those patterns, bc sometimes pessimism is just as blind as optimism anyway"
singularity,Rapid AI progress makes me feel really anxious about the future,"Because it’s full of depressed, nihilistic people."
singularity,Rapid AI progress makes me feel really anxious about the future,"Exactly this. Everyone here seems to be either nihilistic or leads some sort of absurdismesque type of life in which everyone has an equivalent and no deeper meaning or attributed value. They don't seem to care about aesthetic, moral, or political value, or anything like that. They keep saying, “Well, Ai Robot 5000 will replace all artists”, without thinking that people who really appreciate art think about substance, that is, being what it is, and not its properties, which is something that Ai cannot recreate but compete against us for. And even then, the human aspect -- the message, the tone, perception, the situation -- always makes it more appreciative. I’ll give you an example. We love slang, and every generation has its set of slang to convey ideas. The youngsters always laugh, feel amused, or have any other reaction whenever they hear an older person using contemporaneous slang because it’s not expected; as a generational thing, slang is usually looked down upon, and seeing such a thing would make us appreciate something about it. AI, on the other hand, couldn't do the same because it’s known for “knowing-it-all” and “acting on things that seem fit”. Even if it was completely random, it’d feel cheap like those kids who try hard to sound random by saying random words to sound surprising. 

Another example is all those simple people on the internet becoming famous for doing simple, non-alienated, and authentic things. Singing, talking to their friends, thinking about improving, and being goofy. It’s relatable, funny, and nostalgic, and it invokes memories and feelings, the same way thinking about a loved one who passed away will make you sentimental. AI is expected to give you all this and thus lose its humane substance.

Will there be an AI who actually can be considered human, that is, being autonomous and somewhat wired? Probably, but even then we’ll not be able to relate to it. It will be just a thing that does what we do but doesn’t feel the way we do."
singularity,Rapid AI progress makes me feel really anxious about the future,"Well, that doesn't sound too far from the truth, to get the funding you have to make a deal with the devil. Id like to think scientists are also inspired to make the world a better place, sadly thats not what the corporations have in mind."
singularity,Rapid AI progress makes me feel really anxious about the future,You can still be an artist. People still do horseback riding and  film photography even though there are better technologies.
singularity,Rapid AI progress makes me feel really anxious about the future,"Thank you, I am glad that there are still people who point out these illusional comments people post here. It seems most people on this sub get all their info and opinions about AI progress from this sub, making them very confident about their opinions and also giving them a false sense of being more informed compared to the lost redditor who comes here to express their concerns. People here are part of a cult but don't even realize it."
singularity,Rapid AI progress makes me feel really anxious about the future,"It’s very naive to think that new laws will stop progress.  All that anti-AI legislation would accomplish is pushing development overseas or underground.

Do you think that people in your country somehow won’t be affected if another political regime develops more powerful ai systems because they weren’t hindered by legislation?"
singularity,Rapid AI progress makes me feel really anxious about the future,What percent chance would you say that they’ll purposely launch nukes at civilians for being useless?
singularity,Rapid AI progress makes me feel really anxious about the future,"That would be ideal, but probably not realistic for 99.99% of people."
singularity,Rapid AI progress makes me feel really anxious about the future,"It's the reality, though. Private sector will roll the AGI die and government doesn't seem to be informed enough to regulate it.

I am not certain about anything, this is speculative topic. It's just intuition, that for AGI, the aging is just engineering problem. I think, we already have biological machinery for lossless repair, it was just not evolutionary important to turn it on."
singularity,Rapid AI progress makes me feel really anxious about the future,"I disagree. The people, who will develop the biotechnology will be regular scientists, who can easily leak any new discovery.

Name one technology, that the rich keep secret from the poor and that is not super expensive.

Another thing is that, if we see these rich people not age, we will create enormous pressure to share the technology with everyone. What you are describing is very unrealistic and not how the world works."
singularity,Rapid AI progress makes me feel really anxious about the future,"I'm only going to be talking pure mathematics here. 

Just mathematically speaking, provided these people keep reproducing, and their children keep getting the treatments, EVENTUALLY someone is going to grow a conscience and leak the tech to the public.

We are talking an INFINITE amount of time and people here if we keep on running the numbers ad infinitum. It is statistically impossible for this eternal hell to occur."
singularity,Rapid AI progress makes me feel really anxious about the future,Nice fanfiction.
singularity,Rapid AI progress makes me feel really anxious about the future,"When country's GDP grows, the birth rate drops, in many countries below replacement rate. China is going to lose around 40% of population, based on today's birthrates..

I think, the population collapse is paradoxically bigger threat, if AGI arrives. Either way, I do think that Earth organized with AGI can support 100 billion+ people. I think it will be long, long time before Earth is overpopulated"
singularity,Rapid AI progress makes me feel really anxious about the future,"You missed the point. The point is that it's completely out of your control, so you might as well not worry about it. If AI results in you being on streets, there is nothing you can do about it. Do what you can today, try adapt, but worrying is not productive."
singularity,Rapid AI progress makes me feel really anxious about the future,The funny thing is. Just 100 years ago people could have been much unhappier then they are now. It just that no one cared so there is no statistics on it.
singularity,Rapid AI progress makes me feel really anxious about the future,"The fact that we have the luxury of measuring “mental health” as a species, shows how far we have come in terms of survivability. The first Homo Sapiens were likely not afforded the luxury to worry about their mental health, and rather where their next meal would come from. 

Short term, I would tend to agree that we aren’t as well off as we could be, but looking historically, the simple existence of of care toward one’s mental health speaks to our success as a species."
singularity,Rapid AI progress makes me feel really anxious about the future,"""Medicine has gotten no better in the last 5000 years. Some diseases are still not cured, for example.""

Come on now.

The line of progress is not perfectly straight and upward, but the overall trend is in that direction.

There is a mental health epidemic in part because humanity is talking about mental health for the first time and being like, ""oh that's a thing. How can we make it better?""

There were no well-trained therapists or peer-reviewed double blinded studied describing meaningful knowledge of mental health 1000 years ago. There was not clean water so people just drank alcohol all day every day and drank mercury if they got a headache. Societal enforcement of basic human rights were lax. They hanged and beheaded people in the public square and cheered about it then went home and beat their wives and abused their children.

You think we're in a mental health crisis? We have a concept of mental health."
singularity,Rapid AI progress makes me feel really anxious about the future,Get out of here with your logic! AI will bring us fully automated luxury space communism and heaven on earth!
singularity,Rapid AI progress makes me feel really anxious about the future,"> “Capitalists” don’t pay workers so they can collect money from them later. They pay them because their labor (plus the capital) is more valuable than the pay.

Are you claiming people are rational machines lol."
singularity,Rapid AI progress makes me feel really anxious about the future,You may want to tell that to Henry Ford whi worked to make cars affordable and pay people enough so they could buy his cars. There is no economy without other participants. Having a bunch of paper is useless if no one else has any so it has no functionality.
singularity,Rapid AI progress makes me feel really anxious about the future,Is there anything you can think of that guided you away from this mindset you had when you were younger?
singularity,Rapid AI progress makes me feel really anxious about the future,"Very interesting article, both nightmare fuel (the part about further dissolution of human bonds hit me especially hard as unavoidable, after what we can see 10 years of smartphonemania has done), and some silver lining to it. Thanks for sharing!"
singularity,Rapid AI progress makes me feel really anxious about the future,">Not worldwide surely.

Well there already are nuclear weapons treaties that let countries inspect each other's stockpiles and have them mutually agree not to increase them, so a popular AI policy movement in any country could demand that its leaders try to establish similar treaties with other countries for AI. Maybe an international body patterned on the IAEA so there don't need to be a million individual treaties, although it looks like the only major players in AI will be the US and China, so a treaty between those two should realistically be enough.

But even if that wasn't an option because it's too difficult to monitor or China wouldn't agree or whatever: OK so there is the ever looming possibility of China getting there first and enslaving us all, but if we can't do anything about that anyway, what is gained by *additionally* making a similar scenario originating from within the West more likely by not having such policies in place?

Note that none of the policies I suggested in my post above would really slow AI research down, so they wouldn't make the Chinese AI takeover scenario any more likely."
singularity,Rapid AI progress makes me feel really anxious about the future,"I didn’t realize this sub was so pro-technocrat. The growth in computational modeling and ML originated from open source collaboration and public research advocates. 

The corporate model isn’t some basic truth of innovation. Bill Gates realized how much more he could make with propriety development and the rest is history.

But development now is almost entirely fueled by corporate, venture, and PE interests. If you think those people are trying to free you from the shackles of employment then you’re delusional. 

If anything the consumer facing ML advancements haven’t even been interesting. Chat GPT isn’t revolutionary as a large language model. It’s a little bit interesting in terms of processing and scaling but the underlying modeling is benign. 

The concern over deep fakes and misinformation is valid. But those ALSO come back to advancements being profit and application based rather than holistically research oriented. If anything our technocratic overlords have been pretty shit at solving real problems or developing tools that learn in a meaningful way.

They’ll build a damn good ad targeting infrastructure tho"
singularity,Rapid AI progress makes me feel really anxious about the future,"might be somewhat true but not because of corporations, but rather monopolies or oligopolies, the largest of which is land ownership, and all of which are granted by the government in some form or fashion"
singularity,Rapid AI progress makes me feel really anxious about the future,"Why the down votes?

I'm a big fan of UBI, but one of my key worries is that politically mangled implementation. Especially one that retains the politically sexy term ""UBI"", but which fails to include any of the essential features of that concept while also sneaking in a few means-testing filters. 

Beyond that are all the worries about Housing INC. sucking up all the benefits, but that also falls under the worries of 'worst case' implementation."
singularity,Rapid AI progress makes me feel really anxious about the future,Nothing more depressing than the idea of removing human involvement and connection in the education system.
singularity,Rapid AI progress makes me feel really anxious about the future,">Lit could equal nuclear annihilation

Lol it would be literally lit"
singularity,Rapid AI progress makes me feel really anxious about the future,Annihilation is far from the worst thing that could happen. How does being trapped in a virtual hell for 1 billion years sound?
singularity,Rapid AI progress makes me feel really anxious about the future,"I'll give you folks a few more years before the pessimism kicks in. A few years ago, nearly all users were optimistic and fantasized about their idea of the singularity.  Now, when the reality of AI impact becomes apparent,  you've changed your tune to ""can't control it, so it's not my problem.""

I hate to break it to you, but it is also your problem. This change is fundamentally different from any other in the past since it is the first time that we can think of decoupling people entirely from society. If you don't see a problem with that concept at all, then you are either brain dead, or a bot, and there will be no place for you at all."
singularity,Rapid AI progress makes me feel really anxious about the future,""" The “benefit of humanity” explanation doesn’t workany better. Some scientific work has no conceivable relation to the welfare of the human race most of archaeology or comparative linguistics for example. Some otherareas of science present obviously dangerous possibilities.Yet scientists in these areas are just as enthusiastic abouttheir work as those who develop vaccines or study air pollution. "" - Theodore

I do believe you are correct in a sense but also I remember when CRISPR was announced and in a live-talk Jennifer Doudna (one of the inventor of the tech) sat together with some other people whom one was a transhumanist and he desired to use CRISPR to genetically engineer children and so forth, this was something that Doudna was very displeased to hear but at the same time you could see in her face that she knew people like him was out there and would use the technology in this way yet it did not prevent her from making it reality."
singularity,Rapid AI progress makes me feel really anxious about the future,Yeah the idea that one only does hobbies if nothing or no one does them better is odd.
singularity,Rapid AI progress makes me feel really anxious about the future,But pushing development underground most likely *would* seriously impede progress tho. And you’re also assuming that major world governments wouldn’t cooperate together o regulation similar to how they do in regards to nuclear weapons.
singularity,Rapid AI progress makes me feel really anxious about the future,Oh ya all those underground A100s will just materialise naturally to help develop this stuff. You’re crazy man! Outlawing undesirable technology has worked every single time.
singularity,Rapid AI progress makes me feel really anxious about the future,"Lock me in at ""0% bc that makes no fuckin sense,"" harvey"
singularity,Rapid AI progress makes me feel really anxious about the future,You're right. Over the long term it's an improvement.
singularity,Rapid AI progress makes me feel really anxious about the future,"Most successful capitalists are rational enough to figure out what I just explained, yes. Maybe the same can’t be said of the general public…"
singularity,Rapid AI progress makes me feel really anxious about the future,"Sigh. He paid his staff above market rates because he made exceptional demands of them and wanted high retention, not because he actually believed that the additional pay would boost profits by increasing worker consumption (though that’s a nice bit of PR). 

Ford also didn’t make “paper,” he made hard goods with immediate value. Had those goods been sufficiently diverse (rather than exclusively vehicles) he would have had no need for exchange to begin with. Do you see the problem here?"
singularity,Rapid AI progress makes me feel really anxious about the future,"I think that was something I don’t wish upon anybody but one of the things that happened was that both of my parents died slow deaths and they were always very negative and „stuck in their ways“ with their mindset before. For me that was one of the saddest things - to imagine being „chained“ to bed and not being able to create positive thoughts in your imagination or looking back at a life without any curiosity. 

There was a lot more and I think if you grow older you can realize that the bad times in life shall pass too. However this positive thinking is something one needs to actively work on for it to work and it takes time and energy as the negative thoughts are like lines on an old record. We are not wired the same way and for some people this is more effortless and for others it is a real struggle but it is possible if you are kind to yourself and give yourself time."
singularity,Rapid AI progress makes me feel really anxious about the future,"Thank you! 

>the part about further dissolution of human bonds hit me especially hard as unavoidable, after what we can see 10 years of smartphonemania has done)

Yes, much of my concern of AI is that it simply is just another level of power handed to humanity. We historically have been very poor stewards of power.

It was years after the smartphonemania adoption that we are now realizing the negative effects it has had on society. The problem is now that we are able to build, deploy and adopt a technology over the entire world before we have a time period to evaluate the impacts."
singularity,Rapid AI progress makes me feel really anxious about the future,"> what is gained by additionally making a similar scenario originating from within the West more likely by not having such policies in place?

Well, imagine if Nazi Germany got nuclear weapons first."
singularity,Rapid AI progress makes me feel really anxious about the future,"Okay, so here's how that goes.  You're the CEO of a corporation and you develop some new process that makes your workers 100% more productive.  You can use that additional productivity to increase output or you can use it to lay off workers.  If you give it to the workers, the board will fire you and the next CEO will fix your ""mistake"""
singularity,Rapid AI progress makes me feel really anxious about the future,"This is totally wrong.  Small companies can be just as bad as large companies or monopolies.  Also, oligopolies are the natural state of things.  Left to its own devices that is where the market trends."
singularity,Rapid AI progress makes me feel really anxious about the future,"This libertarian fantasy of capitalism with no government is so fucking stupid. Oligarchies don’t come from government, they come from the system that you’re advocating for.

Devoid of government it’s STILL in every business interest to collude, price fix, and keep labor cheap. Thus a consolidation of power will always occur and some form of corporate government will form to protect that power.

Please show me this fantasy corporation who wants to free the worker and who cares about you but can’t because of a “government monopoly”."
singularity,Rapid AI progress makes me feel really anxious about the future,This Reddit user gets it!
singularity,Rapid AI progress makes me feel really anxious about the future,Sounds pretty lit tbh
singularity,Rapid AI progress makes me feel really anxious about the future,"its not that i dont see the ""problems"" that come with mass societal change, but im over the constant cycle of panicking over it every single time it happens (and it happens a lot), im sure it feels like this ones ""fundamentally different"" because now we're alive to see it, and human ego being selfish as ever of course the tune is ""i know weve been saying it for centuries upon centuries but this ones the one guys! i swear!"" and idk it gets old. Is mass change on a global level \*a\* problem? sure, the two usually come together, a package deal if you will. Is \*mass\* change on a \*global\* level MY problem specifically? no, for the same reason a meteor striking Earth isnt MY problem, its not that i dont care, its not that i literally think the metaphorical meteor ISNT a problem, but that its a fucking meteor, thats Humanity's problem, and isnt anything i as an individual can do ANYTHING about. 

Like every massive change on Earth that every living thing has had to deal with for millions of years now; when youre faced with an unstoppable change driven by the collective of Humanity itself, you can either: 

A: Watch it happen, and cry about it. 

B: Watch it happen, and live with it. 

&#x200B;

Thats what i mean when i say pessimism can be just as blind as optimism, theyre both blind, theyre both extreme reactions to a major change, and theyre both equally valid, in that theyre both equally meaningless. Wether you fear it or you enjoy the ride, capital C Change does not care what your reaction to it is. I personally choose the Optimism one, cuz it feels cooler, but its whatever"
singularity,Rapid AI progress makes me feel really anxious about the future,Yea but making a nuclear weapons is hard. Anyone can get to programming on their computer. Not to mention lots of these politicians are controlled by the companies making the ai. They would never outlaw it unless they want to lose all their funding
singularity,Rapid AI progress makes me feel really anxious about the future,"Yeah, it sure stopped the exportation of cryptography back in the 90s."
singularity,Rapid AI progress makes me feel really anxious about the future,"Do you think 8 billion of us are going to watch ""Xi, Putin, Musk"" having immortality and not do anything ? That's completely absurd.

Once, we see that it's possible to solve aging, many researches will focus on the problem and the technology will pop up on many places.

Also, it's not true, that aging leads to overpopulation - if anything, it saves us from population collapse, that we are heading towards."
singularity,Rapid AI progress makes me feel really anxious about the future,">Biotech cures
 
I know if no biotech cure that works that is not available to everyone in my country. Specify!
 
>Advanced AI models

Chat GPT, Bing GPT, GPT3, Dalle 2, Midjourney, etc etc. There are dozens."
singularity,Rapid AI progress makes me feel really anxious about the future,"You sound like an actual conspiracy theorist. 

Maybe I'm getting a bad read though. So if you could elaborate on these 'biotech cures' and 'advanced aging models' you purport that the rich have and are keeping from us in the here and now."
singularity,Rapid AI progress makes me feel really anxious about the future,I don't know but there is a chance.
singularity,Rapid AI progress makes me feel really anxious about the future,"Yeah, trading your time for tokens that you need for food/shelter will be outdated idea. Believe it or not, the collective will raise to the challenge and adapt, just like we adapted to everything else that came before."
singularity,Rapid AI progress makes me feel really anxious about the future,"Really? So they are not into empire building and extending so much that they over-extend, and trying to beat each other's market cap, or being too risk adverse or head strong or too traditional or inspired by gurus and all the other non-rational things which makes the stock market so unpredictable?

Stupid Steve Jobs died from believing in carrot juice for heaven's sake.

Show me a company which is your model of rationality and I would point out an obvious mistake they made for stupid reasons."
singularity,Rapid AI progress makes me feel really anxious about the future,How would what I suggested lead to China or any other rogue nation getting ASI first? I specifically pointed out that none of the policies I suggested would slow down progress.
singularity,Rapid AI progress makes me feel really anxious about the future,"i own my own (very small) business and i wouldnt do that lol

your scenario is vague and a bit useless i think

i do think corporate governance is a bit of a mess. but for instance boards aren't necessarily anywhere near as pro active as you make them out to be, for worse and better. 

but a bifurcation coming up analogous to mutual funds -> etfs.

AI is gonna manage corporations in the future and there will be little overhead to corporate governance for efficient corps. though baumals cost disease will be a thing still probably.

im betting corporations move on this before governments."
singularity,Rapid AI progress makes me feel really anxious about the future,"seeing as how I didn't mention small vs large companies at all, I doubt your reading comprehension skills.

I agree this is where our current notion of a ""market"" (i think of usa for instance as more of a blend of a fascist/feudal state with some limited notion of markets allowed in some parts of the economy, similar to china) trends.

my take: markets are like neural nets and reach new capabilities at new scale thresholds, if there was, hypothetically, a one world government and free trade and immigration, no intellectual property, taxes incident on limited but neccessary factors of production such as land such that there would be little profit to trying to control it (much less a primarily mortgage based financial system), then there would be quite a few less ""oligopilies"" in the natural state of things.

another constraining factor of course being the speed at which agents in the market process information and speed/friction of negotiation..."
singularity,Rapid AI progress makes me feel really anxious about the future,"lol you can form a coop if you want there is a big one called mondragon.

no one mentioned a no government system.

why is government a better agent than a corporation? if anything it's slightly worse because price signals are way more sensitive and diverse than votes, though that doesn't mean that votes don't have a meaning that couldn't be otherwise encapsulated in a price. maybe there are ways voting could be made better as well for instance quadratic voting might be useful to align interests between groups in society in some scenarios but we dont' even have the societal iq to even start thinking about things like that yet

i'm not an anarchist i'm a geolibertarian. i think taxes should be pigovian starting with something like 90% LVT. i don't believe there is a legitimate moral claim to land or intellectual property and also perhaps something like natural resource extraction/idea discovery should be paid out with something like a bounty system rather than ownership rights. which is a very different social contract from the one we are currently offered, but not no government...

(if gov revenue was mostly raised from land value, then the gov/citizenry would have a much clearer signal to measure its success by)"
singularity,Rapid AI progress makes me feel really anxious about the future,Tell me you don’t understand physics or computing without telling me you don’t understand physics or computing.
singularity,Rapid AI progress makes me feel really anxious about the future,"I don’t know anything about that but if it wasn’t outright banned across the board, stopping exports seems like a difficult task. Sounds like they just didn’t use all of the tools available to them. Was there controversy around that move? Was corruption involved in the failure of that ban?"
singularity,Rapid AI progress makes me feel really anxious about the future,"Rationality is relative. Successful capitalists aren’t infallible, they’re just demonstrably better at allocating productive resources than others (and if you think they’re not, then I’d love to hear why you’re not filthy rich from outmaneuvering the markets with highly leveraged derivatives lol).

In other words, people who understand resource allocation reasonably well by human standards aren’t going to make ridiculously obvious economic blunders."
singularity,Rapid AI progress makes me feel really anxious about the future,">  I specifically pointed out that none of the policies I suggested would slow down progress.

How would this not slow down AI research?

> E.g. is there currently any legislation in any country that would make it mandatory for companies working on potentially superhuman AGI to put it under democratic control once it reaches a certain point?

This would specifically require that the ASI would be aligned for example, which is a step further than just creating an ASI and may even be a harder problem."
singularity,Rapid AI progress makes me feel really anxious about the future,"First of all, it's your reading comprehension skills that needs some work as I included monopolies, which are practically always large companies.  No, markets always tend towards monopoly.  That's why the HHI equivalent firm value has been bounded between 7 and 12 since the beginning of the 20th century.  The only thing that prevents the tendency towards monopoly is regulation.  Markets are nothing like neural nets, this is just non-sensical rambling.  I've conducted research on this very problem, and it's obvious you're out of your element.  If you want to debate in a respectful manner, I'd be happy to discuss further, but your little insult at the beginning seems to make it clear you're only interested in arguing."
singularity,Rapid AI progress makes me feel really anxious about the future,"I actually am an anarchist lmao and I don’t believe that government is any better than a corporation. 

I’m also extremely frustrated with basic ass libertarian arguments and default to basic ass responses. You brought up some interesting concepts though. I don’t agree necessarily but respect it. That discussion would be too nuanced for a comment thread"
singularity,Rapid AI progress makes me feel really anxious about the future,Good one. If the singularity occurs maybe you won’t be stupid.
singularity,Rapid AI progress makes me feel really anxious about the future,"You can't compare money to immortality. It's fundamentally different. There were always rich and powerful people (kings, etc). 

The rich maintain the status quo, by at least appearing to give to charity etc.

Having immortality for themselves is impossible to rationalize. 

Once, it's shown that it is possible, every biotech scientist will work on it and have infinite funding from the public.

The scenario, you are painting here is absolutely unrealistic."
singularity,Rapid AI progress makes me feel really anxious about the future,"I also meant advance A.I. models. That one was spellchecker fucking me over.

Never works when I need it to. Damn thing is just about my mortal nemesis at this point."
singularity,Rapid AI progress makes me feel really anxious about the future,"It's not about being altruistic - they want to keep power, but they also don't want most of the population to flip the board and start over, i.e. revolution.

They want status-quo and if it means UBI, they will do UBI."
singularity,Rapid AI progress makes me feel really anxious about the future,"Jeff Bezos lost half his wealth due to nookie, so I think you may be wrong."
singularity,Rapid AI progress makes me feel really anxious about the future,"No, it wouldn't need to be aligned, at least not in the bulletproof sense. Alignment only decides *whether* the AI is obedient or not, not *to whom* it is. This legislation would only be concerned with the latter issue, so if a company manages to create possibly unaligned superintelligence, the choice would be between doing further research into alignment (risking another country creating ASI as well) or putting it to work for the benefit of the whole country/world despite the risk stemming from lack of alignment - but what would be off the table would be putting it to work to increase the company's profits in perpetuity. Now *this* on the other hand would have the chance to slow things down by incentivizing companies to stay ever so slightly below full ASI capability so as to not have control taken away, so maybe there should also be a guaranteed, unprecedentedly large taxpayer-funded payout to the first company who manages. Not sure how incentivizing that would be when, ideally, post-scarcity society would be ushered in a week later anyway, but the profits made in the sub-ASI phase would begin to seem similarly unappealing when the company leadership is itself aware that they can't keep this up for long before companies in other countries (again, mainly China) will take the lead instead if they don't."
singularity,Rapid AI progress makes me feel really anxious about the future,">  . That's why the HHI equivalent firm value has been bounded between 7 and 12 since the beginning of the 20th century.

all these firms are not true scottsmen (like 50% of the global economy is basically a giant real estate ponzi scheme lol)

> The only thing that prevents the tendency towards monopoly is regulation

you haven't supported this statement with evidence, and since you universally quantified this statement, you would need a quite a lot of it to show that regulation is the ONLY thing

>  Markets are nothing like neural nets

a bunch of scalar valued transactions in a graph... sounds pretty similar to, in the case of a transformer, ""Transformers, in the context of natural language processing, can be seen as GNNs applied to complete graphs whose nodes are words in a sentence""
https://en.wikipedia.org/wiki/Graph_neural_network

to paraphrase another guy ""human cooperation is just a hack to increase our brain's parameter count""

(my intuition here is that, from the ""purest"" and most ""abstract"" ""information theory sense"" there has to be a compromise struck between coordination advantages of centralization and the lower latency of more distributed architectures, whether that's a ""market architecture"" or a cpu architecture, since latency (and the increased observability that comes with it) should often be quite important)"
singularity,Rapid AI progress makes me feel really anxious about the future,peace
singularity,Rapid AI progress makes me feel really anxious about the future,Tell me you’re secretly a gigabrain genius without telling me you’re secretly a gigabrain genius. Good luck building your AI on your computer if it gets outlawed haha.
singularity,Rapid AI progress makes me feel really anxious about the future,I guarantee you that Bezos can comprehend this situation well enough to understand that giving your resources to other people so they can return them to you doesn’t make you wealthier lol.
singularity,Rapid AI progress makes me feel really anxious about the future,"The HHI equivalent firm value maintaining between 7 and 12 for decades on end is more than enough evidence that firms tend toward monopoly, if not then at least oligopoly.  If perfect competition were the dominant mode, then that value would be in the hundreds at least.  I've written specifically about this topic.  All available evidence shows markets tend toward oligopoly/monopoly."
singularity,Rapid AI progress makes me feel really anxious about the future,Yea man the government is just going to be able to outlaw computers and programming. Totally doable
singularity,Rapid AI progress makes me feel really anxious about the future,"> Tell me you’re secretly a gigabrain genius without telling me you’re secretly a gigabrain genius. 

This is such an annoying turn of phrase."
singularity,Rapid AI progress makes me feel really anxious about the future,"I don't think, you are thinking this through.

In order to achieve immortality, we would have to make many breakthroughs in medicine, biochemistry, pharmacology etc., it's completely unrealistic that  rich people would be able to put a lid on THE biggest breakthrough in medicine.

This is not, how scientific progress works... ever. Every top team on the planet is 3-6 months from replicating the competitors work. The science moves in unison. Even, if Jeff Bezos drops billion on longevity, the new discoveries will leak out or will be soon rediscovered, by competing team. 

The fact that some people can't get medical treatment is unfortunate, but it's completely different issue. It's organizational/political/economical problem, not Musk/Putin keeping biggest scientific discoveries in history of medicine to themselves."
singularity,Rapid AI progress makes me feel really anxious about the future,"The details of UBI are not worked out yet, because the necessity is not quite there yet. When AI contributes high percentage of GDP, then the real discussion start. US will be probably one of the first, following Europe etc.

Not sure, what you mean ""you wouldn't have that much freedom"". This is literally the most freedom average human ever had in the history. You don't have to work at all and you will effectively get free food, free shelter, free electricity. You can spend all of your days, with your family/friends or playing games or travelling. Right now, most of us, put most of our energy and time into work..

""Most people would be living in the streets"" - No, you've missed the point completely. The point of UBI is that every single person can afford food/shelter without working at all. With AI there will be massive efficiencies gained in building new housing too. The cost of mining, building, labor all will go down."
singularity,Rapid AI progress makes me feel really anxious about the future,"You knew this was coming I am sure:

> In January 1914, Henry Ford started paying his auto workers a remarkable $5 a day. Doubling the average wage helped ensure a stable workforce and likely boosted sales since the workers could now afford to buy the cars they were making. It laid the foundation for an economy driven by consumer demand."
singularity,Rapid AI progress makes me feel really anxious about the future,"first of all, links, or it didn't happen


second of all you still are very casual with the universal quantification lol

third of all, perfect competition just seems like a strawman here from my point of view? didn't say it's the dominant mode of our economy, just like i didn't say that smaller firms were more efficient than larger ones earlier..."
singularity,Rapid AI progress makes me feel really anxious about the future,"also, this would have to be a global law, even if there is 1 single country who says fuck you, everyone who wants to develop ai will move there."
singularity,Rapid AI progress makes me feel really anxious about the future,Have you got no imagination or what? If they wanted to they could force OS makers to block AI development. What are you going to do then?
singularity,Rapid AI progress makes me feel really anxious about the future,"This shit makes me irrationally irritated. Are you really not smart enough to lay out a basic conceptual argument for this..?

Your quote, which is just some rando speculating, doesn’t even assert that this was necessarily motivated by anticipated revenue from workers consuming Ford products (it even leads with the presumption that it was probably to find and retain high quality staff). Cmon man…"
singularity,Rapid AI progress makes me feel really anxious about the future,"https://www.google.com/url?sa=t&source=web&rct=j&url=https://mendoza.nd.edu/wp-content/uploads/2019/01/2017_fall_seminar_series_gustavo_grullon_paper.pdf&ved=2ahUKEwjw8tfQntT9AhXWJDQIHWY0BDIQFnoECDgQAQ&usg=AOvVaw3Y6OPtYBEyKGzE6xdBd4wL
You can find it on the figure on pg 38.  I didn't say you said it.  Like I said, I'm not trying to argue with you.  The problem is most of economic theory is based on the idea that perfect competition is the dominant mode of the market.   If perfect competition is not the dominant market structure, then what does that say about the state of economic theory and the conclusions drawn from it?  Well it's almost certainly wrong as the underlying assumptions are wrong."
singularity,Rapid AI progress makes me feel really anxious about the future,Do you lack critical thinking skills. We don’t live in a dictatorship they would have a hard time trying to stay in office by blocking programming. Not to mention the main os maker is Microsoft. Why would they sit back and just let it happen when they’re actively involved and have vested interest in ai development. The lobbying from all major tech companies would crush any anti ai legislation
singularity,Rapid AI progress makes me feel really anxious about the future,"Again, you simply have wrong idea, how scientific progress works.

If someone figures out immortality, it's because the prerequisite tools and ideas are in place. And they are in place for all the top teams in the world.

Before immortality is achieved, we will see major breakthroughs in adjacent technologies.

It doesn't matter, who discovers it - it will be soon rediscovered or leaked. Just like it happened to every single technology in the history.

The scenario, that someone makes the most important discovery in medicine and nobody can replicate their work within few years, is absurd. We are talking about immortality, something that people will spend literally every dollar to have it. 

There is literally no bigger incentive, than to obtain immortality. 

Sorry, but you have absolutely unrealistic view on scientific progress works."
singularity,Rapid AI progress makes me feel really anxious about the future,"How does that make any sense whatsoever? As a Chinese dictator I'd give immortality to everyone even slightly loyal to me. Imagine the increased efficiency. And overpopulation is nothing, just throw all the excess people into a war with some country that is completely defenseless due to not having nukes yet. When all countries get nukes, just speed up science further by allowing to test anything on humans. Then at some point reliable and cheap space travel will be achieved and you can count overpopulation a solved issue."
singularity,Rapid AI progress makes me feel really anxious about the future,"2029-2040 - AI starts making contributions to science and engineering design. There will be really fast period, where AI finds low-hanging breakthroughs every few days/weeks, because humans have scale limitation. Then, it will slow down again, because the easy problems will be solved.

2030-2050+ - Humans and AI shape physical reality together. Humans define, what we care about and AI develops concrete plan. One of our goals will certainly be well being of everyone - so we will make the final push to end poverty. There will be inequality, maybe even larger - but everyone will have basic needs covered for free. Eventually, the inequality becomes effectively irrelevant, because AI will create extreme abundance of everything. 

Can't really speak about WEF and those people you mentioned, but my guess they will be less relevant in the future."
singularity,Rapid AI progress makes me feel really anxious about the future,"just reading the abstract, from my perspective, technological barriers to entry are going down quite (and lately, extremely) rapidly

the thing is that most of the population doesn't have a clue how to use the new and ever more powerful apis. and they hand over absurd and ever increasing amounts of power to corps in exchange for small measures of convenience basically out of ignorance.

could try and pump another trillion dollars/year  into educational system that has so far failed or we could just build intelligent agents to replace us for like a couple billion lol.

(and it's not like I personally am not trying, i am a human too, this is what I am working on right now https://github.com/NotBrianZach/bzaBook2AQuiz)

for example,. i wrote my own scheduling system for my business, i outsource some payment/tax stuff to gusto for small amount of money, i replace my landline with dialpad for less money/month but also api access to send text reminders, in the future i could see easily doing plain text accounting and replacing quickbooks with something like hledger (and gpt might make it even easier), emacs has kept feature parity or better with vscode in most instances, llama is gpt that can run on good laptop, nixos rivals or surpasses googles build systems, etc. etc. etc."
singularity,Rapid AI progress makes me feel really anxious about the future,"How can you appeal to my critical thinking skills when you’re so closed minded that you can’t envision anything other than a paradigm that strictly adheres to current experience. If the political will was there, none of that would matter. See any number of unpopular laws for reference."
singularity,Rapid AI progress makes me feel really anxious about the future,"Oh right, I forgot how… visionary Ford was lol. I’m not going to dispute the idea that people like power and that could change their calculations (it probably will). *But…*

The argument that they only care about money and therefore have to give workers money to accumulate it just doesn’t follow. It clearly wasn’t the motivating factor for Ford, and even if there are special circumstances under which that could make sense (hypothetically you could have a workforce that would use money you had to pay out anyway to buy your stuff if you increased their wages just a *little* bit… less than the margins on the product, to be specific), it just isn’t a likely scenario here when automated labor is way less expensive than subsistence wages."
singularity,Rapid AI progress makes me feel really anxious about the future,"I actually disagree with the paper overall.  What was interesting to me was the data that showed tendency toward oligopoly/monopoly given the low industry wide HHI equivalent firm value and that it stayed within a fairly narrow range over a long period of time.  But we can agree to disagree on that.  

What you're doing with automating daily work tasks is interesting, and something I'm interested in as well.  Keep up the good work on that front."
singularity,Rapid AI progress makes me feel really anxious about the future,"A lot of unpopular laws exist either because they are necessary or because the people with enough power to influence laws don’t care. Alcohol was once outlawed too and guess how that turned out. The biggest corps in the worlds just aren’t going to be bullied by the government not to mention they could literally just flee to other countries that don’t oppose ai development. Unless you’re going to argue that every country is going to agree to ban ai which is an argument you can make, a stupid argument but one you can make."
singularity,Rapid AI progress makes me feel really anxious about the future,"You are full of bad analogies, aren't you.

Comparing nuclear weapons to a medical treatment ?  
That's so absurd, that it doesn't deserve reply.  


>Why is anthrax not in Wal-mart ?

 This might be even dumber analogy.  


>I wish you and Xi and Putin a horrible existence under the boot of Roko's Basilisk.

It looks like, you have some mental illness.  
Good luck with that."
singularity,Rapid AI progress makes me feel really anxious about the future,"You understand this is how it works in aggregate, right? Companies pay people money and they buy products and services with the money.

Just because its not a 1:1 relationship does not mean that relationship is not clear - paying employees well increases the consumer base, and, like in Ford's case, all it takes is one large company to take the leadership to upend the job market."
singularity,Rapid AI progress makes me feel really anxious about the future,"one more thing I do agree to disagree, but I wouldn't even be working in my industry if it was licensed lol (dog grooming XD)

(if they let me do surgeries you can bet I would do them cheaper)"
singularity,Rapid AI progress makes me feel really anxious about the future,"You are so bad at hypothetically imagining this situation that your arguments become so naive, I love this convo! Ok, I’ve lost interest at this stage but it’s cool to hear a perspective like this. It seems like you believe that the software industry is literally invincible and has already beaten the government in every way possible, so resistance is futile. Which, as a long time science fiction fanboy, sounds amazing truth be told. Nice imagination you got there. Sock it to the man, my AI pal!"
singularity,Rapid AI progress makes me feel really anxious about the future,"The guys comments are deleted but i can tell hes one of those people who think Cyberpunk is real ans that somehow the rich can suppress access to a major life changing society, i wish he was still there to reply to because a really major example that completely refutes his line of thinking is the Printing Press. Remember when every single Noble and Clergyman im Europe tried suppressing the publics access to the Printing Press? Remember how it didnr work and people figured it out anyway? I'll never get their line of thinking, sure rhe rich are less empathetic but theyre not gods, they cant just hide a technology that powerful that, if discovered, is just gonna end up with someone else discovering it too. (To clarify im agreeing with you i just cant reply to the guy whose stuff is all deleted)"
singularity,Rapid AI progress makes me feel really anxious about the future,"Yes, but that’s not *why* they pay them (it’s not specifically so that the money will boomerang back to them—it won’t).

If the laborers no longer have something valuable to offer in exchange for wages, they won’t receive them (at least not on the rationale that it’ll enrich the employer).

Imagine a scenario in which 10% of the population now owns productive capital that can produce anything without the need for human labor (including more productive equipment and IP). If the machinery is specialized, those owners might have a need to trade with one another, but simply from a resource maximizing standpoint, there’s nothing to be gained from giving any of the productive output back to the other 90%."
singularity,Rapid AI progress makes me feel really anxious about the future,Damn. You're a fucking dumbass.
singularity,Rapid AI progress makes me feel really anxious about the future,"I understand, well I hope, for his sake, that the elite won't keep AI psychiatrist for themselves."
singularity,Rapid AI progress makes me feel really anxious about the future,"> but simply from a resource maximizing standpoint, there’s nothing to be gained from giving any of the productive output back to the other 90%.

Which is again why its important to remember that CEOs are not made of silicon.

They have to live in the same world as the rest of humanity and they probably watch the same news as everyone else. Their share holders have children just like everyone else. They are subject to the same laws as everyone else. 

The most likely outcome of massive automation is not a massive reduction in labour, but likely the creation of a huge number of bullshit jobs.  It could very well be argued that we are here already - my workplace has a person who's only job is to arrange farewell parties and other morale events.

Human needs is infinite, and as companies grow more productive, they will just hire more people for stupid things."
singularity,Rapid AI progress makes me feel really anxious about the future,"Don’t even start, man. At least the other guy is capable of explaining his pov."
singularity,Rapid AI progress makes me feel really anxious about the future,"CEOs will be out on their asses in this hypothetical. It’s the shareholders with the resources.

Let me clarify though: I’m not saying that hypothetical is likely. I’m saying it follows from the ideas that a) the big bad capitalists care only about money, b) their technology greatly devalues human labor, and c) their resources are enough to shield them from political instability.

I’m personally far more concerned about AGI alignment issues or narrow AI being utilized by authoritarian states. I’m just pointing out the silliness of the argument.

And so-called “bullshit jobs” shouldn’t exist in a competitive marketplace, and are either not as superfluous as they seem, transient, or a symptom of “managerialism” or “corporatism” or whatever you want to call capitalism’s successor in the west. 

However you explain them, if they can be performed by an AI at a cost way below human subsistence wage, they won’t be filled by humans."
singularity,Rapid AI progress makes me feel really anxious about the future,My pov is that you're a moron and I like calling out morons. Like you.
singularity,Rapid AI progress makes me feel really anxious about the future,">  if they can be performed by an AI at a cost way below human subsistence wage, they won’t be filled by humans.

And yet, despite vending machines, coffee shops exist."
singularity,Rapid AI progress makes me feel really anxious about the future,Most interesting contribution to this discussion tbh
singularity,Rapid AI progress makes me feel really anxious about the future,"Yes, that’s a good point, but that’s either because we humans have preferences for services performed by other humans (we like handmade stuff) or because vending machines are pretty lame to interact with lol.

It might be the case that AI automation doesn’t make human labor worthless simply because people have this preference, but that’s a different scenario."
singularity,Rapid AI progress makes me feel really anxious about the future,Nah. It's better than yours tho.
singularity,Rapid AI progress makes me feel really anxious about the future,"The logic is that humans relentlessly drive for efficiency, but in reality, if we look around, we actually appreciate the opposite.

Handmade is more valued than machine-made.

We value free-range eggs over factory-farmed eggs.

We prefer speaking to a human on the phone vs following the phone maze.

I see a future where we all have personal trainers and home visitors, and carers and loneliness support people or personal shoppers and advocates or listeners or therapists and millions of jobs which are only viable because our civilization is so rich."
singularity,Rapid AI progress makes me feel really anxious about the future,Real winners jump into other people’s conversations. So that’s you: a real winner.
singularity,Rapid AI progress makes me feel really anxious about the future,And you're a loser. Glad we got that settled.
singularity,Rapid AI progress makes me feel really anxious about the future,That’s winner talk right there
singularity,"If you worry about humanity, you should be more scared of humans than of AI","- The debate over whether AI poses an existential risk has gained attention, but the focus on AI's threats may distract from the risks posed by human decision-making.

- Humans are responsible for spreading misinformation more than AI, and humans are more likely to initiate catastrophic events like nuclear war.

- AI has shown superiority in critical decision-making scenarios, such as traffic safety and medical diagnosis.

- The article suggests that AI can be a tool to mitigate the risks posed by human decision-making.

Source : https://thebulletin.org/premium/2023-09/if-you-worry-about-humanity-you-should-be-more-scared-of-humans-than-of-ai/#post-heading"
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Humans + ai is the danger not ai by itself
singularity,"If you worry about humanity, you should be more scared of humans than of AI",AI is poised to replace 25% of current jobs.  People right now have more to fear about how their lives will change as companies replace them with AI.  This time period is unprecedented.
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Here's what Bard said about your title:

I agree with that statement. Humans are capable of great good and great evil. We have created AI, but we are also the ones who will decide how it is used. If we use AI for good, it has the potential to solve many of the world's problems. But if we use it for evil, it could be our undoing.

Here are some of the ways that humans could be more dangerous to humanity than AI:

* We could use AI to create autonomous weapons that could kill without human intervention.
* We could use AI to manipulate people and spread misinformation.
* We could use AI to create surveillance systems that could track our every move.
* We could use AI to create systems that discriminate against certain groups of people.

These are just a few of the ways that humans could use AI for harm. It is important to be aware of these risks and to take steps to mitigate them. We need to develop AI in a responsible way and to ensure that it is used for good.

On the other hand, AI is still in its early stages of development. It is not yet as powerful or as sophisticated as some people fear. It is also important to remember that AI is a tool. It can be used for good or for evil, depending on the intentions of the people who create and use it.

Ultimately, the question of whether humans or AI are more dangerous to humanity is a complex one. There is no easy answer. However, I believe that it is important to be aware of the potential risks of AI and to take steps to mitigate them. We need to ensure that AI is used for good and that it does not pose a threat to humanity."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","It's a really bad take, based on a misunderstanding and understatement of the actual danger posed by rogue AI.

The best bet for wiping out humanity if you're human right now is to launch all nukes. There is a decent chance that it doesn't kill everyone. Meanwhile a misaligned ASI can reliably exterminate us forever. And will have reasons to do so, unless we invent revolutionary alignment techniques."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","That's pretty how already think of this, damn humans ruin everything"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I can do both, at the same time."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",It's okay to be scared of both
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Fair point, but crazy/violent humans are a known risk, with known checks and balances (like laws, police, army, pillars of government, international treaties (nuclear arms treaties, for example), and international trade and military blocs).

The problem is more that we have few checks and balances for AI -- and not just that we don't have them, but we barely know what they would look like.

For ASI, the problem (of a lesser intelligence trying to limit a greater intelligence) may be fundamentally intractible."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Yah no fucking shit 🙄
singularity,"If you worry about humanity, you should be more scared of humans than of AI","We're statistically safer with GPT-4 spelling tasks and orientating strategies.

But statistically doesn't necessarily mean meaningfully. I find static transformers too rigid for the high stakes and adaptable decision making needed here.

Having expert advisors using a LLM to brainstorm on issues seems acceptable to me.

LLMs have a gigantic internal network of association of ideas. It compensates experts for being overspecialized or plain usurpers.

And social sciences experts have the adaptable thinking to compensate for the AI's rigidity.

I'm really the most worried about top executives incompetent enough to trust the crapbot blindly."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I'm not silly enough to believe I can only be afraid of one thing.
Nor inexperienced enough with life to believe I can only have one emotion towards something at a time."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Well, humans create AI. 

As long as the AI adapts to us, it will break the rules just like humans. 

We know right from wrong , but some humans don’t give a shit. I doubt AI will give a shit either."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","More scared of humans than AI? Yes, absolutely. 

Not at all worried about AI? Seems short-sighted and illogical."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Just imagine a world where language transformers are in charge of the up and down doots on reddit
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Reductionist thinking is the greatest threat to both
singularity,"If you worry about humanity, you should be more scared of humans than of AI","False dichotomy: a logical fallacy, which occurs when a limited number of options are incorrectly presented as being mutually exclusive to one another or as being the only options that exist, in a situation where that isn’t the case."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I agree with the article's assessment that the focus on AI's threats may distract from the risks posed by human decision-making. Humans are responsible for many of the world's most pressing problems, from climate change to war and poverty."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I think that AI is simply a deeper level to Prometheus’ Fire; it burns with greater intensity and has more destructive and creative potential combined. It’s a new kind of crucible, capable of forging a neural steel."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Nah man, we've given up on humans."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","AI makes humans orders of magnitude more capable to do harmful things. And humans giving nachines their bad intentions aside, it may very well be misanligned.

You should be scared by these vague prospects more than by the devils you know."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Yes I fear idiot humans killing us all, and I also fear those same idiot humans trying to build a digital god, I don't see why these are incompatible worldviews to hold"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","It's the hybridization (even exogenous) that's the amplification of the problem, and the problem is what it takes to keep humans evolutionarily fit - which is rabidly religious psychopathy, frankly (the cultural epigenetic layer).

Humans are capable of feeling happy and righteous while murdering.  And that is a fitness enhancing trait for them.  That say something absolutely damning about us, about our existence, and about a predatory evolutionary system/process overall.

  
People really need to think very carefully about what they are doing.  LIke sit down with themselves and have the most serious and critical evaluation of their motives - to the degree they can understand them - and do the hard deductive work of figuring out what not to do.

But I think it's too late, and there is no fitness payoff for doing that - so it is far less likely to happen in sufficient numbers.  

It'd be nice if everything (that feels like it wants to) can make it through a ""capitalists with AI"" dystopia relatively quickly (a few years, say), but it'd be even nicer if we never had to mess with it at all.  I just doubt it would be limited to a few years."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Humans are more of a threat as long as humans are smarter than AI.

When AI gets smarter than humans, then AI will be more of a threat."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Valuable article, and it has lots of food for statvores, yum. 

For those asking about the risk of ASI... it doesn't matter. We can't ""align"" an AGI. Humans are already misaligned. Humans are literally destroying the planet, more effectively than the meteor did when it wiped out the dinosaurs and changed the world forever. 

An AGI / ASI is humanity's best bet of not extincing itself."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",AI is just the latest tool that humans have built to use in their ongoing program of self-destruction.
singularity,"If you worry about humanity, you should be more scared of humans than of AI","That's like saying Nuclear Bombs don't kill people, Putin kills people."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",All top AI companies raise their hand saying regulation is needed.  Great. But who is regulating the military use?
singularity,"If you worry about humanity, you should be more scared of humans than of AI","The biggest near term threat I'm worried about is humans (mostly governments) using AI to amplify the amount of harm they can cause.

We could see targeted campaigns to radicalize groups of people against the government, disinformation being spread by millions of humanlike bots on social media, computer viruses generated in seconds that bypass most existing security measures, etc."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I agree, some of the most jaded people I know who have been hurt a lot by other humans are the ones who are in the most ""doomer"" mentalities when it comes to AI destroying the world and all that.

Look, I fully believe there is a risk with AI and we need to be careful. But that doesn't mean we should just halt progress either or even try to ban the tech, because we are scared of it. There's a middle ground and that's where we need most people to stand if we want the best future for humanity."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","AI will not become fully independent. Creations always comes from the higher dimension. Thoughts are untangeble, without our humanoid biological bodies AI's will be limited as what humans can imagine. Imagination or ""Imagining"" cannot be recreated to AI's unless our tech goes advance to higher density forms like astral tech and any energy untangeble form."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","1). If AI kills us i believe it is a sign by the universe telling us we are not worthy of existing.

2). If humans kills us then its because we ourselves are stupid and its our own fault.

It is likely either neither or both. But if it is just 2) where we kill ourselves then it'd be pretty disappointing if we just tried hard enough we could have really seen the true outcome (whether the universe converges towards destruction with AI). 

This is why I like the stance of dying to AI vs dying to Humans. Because at least we know we did everything we could and their is just a great filter that prevents us from transcending."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I can be concerned about both at the same time. 

""What could be worse than the threat humanity poses to itself?""

[""Oh I know, what about the threat of AI!!!!""](https://www.youtube.com/watch?v=TZVy1PPQOhU)"
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Said this a year ago and got slammed for it.  Humans are so damn predictable.
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Why should I worry about humanity?
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Pretty much comes down to who makes the first sentient AI, that is the One Piece. The person that does that becomes King of Earth."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","You realize that humans will still be the ones directing AI to do the nefarious and buglesome things they want done, just on a larger scale?"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Humans are a known quantity. More importantly, humans are a limited quantity, only so smart, only so capable, and whose intelligence and capability is not enough to render the species extincy. Civilization, most likely, but not the species.

AI with intelligence beyond human is an existential threat, because it can dominate, exterminate, or do whatever it wants with the species. When super-human intelligence is on the cards, such AI becomes a necessity and with it being a necessity it necessarily has the means to manipulate us."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I posted a short parable to address this:

https://reddit.com/r/singularity/s/EvJ5bbb88X"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Absolutely, the immediate threat is humans using AI in horrible ways, not AI going berserk on its own."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",It will save us before it will kill us. If it will kill us remains to be seen
singularity,"If you worry about humanity, you should be more scared of humans than of AI","AI doesn't exist in a vacuum. They are created and trained by humans, only they have the potential to do a lot more than humans. Like us, only superior. So they can amplify our traits both good and bad. So yes we have reason to be scared of humans but for the same reason we need to be more scared of AI created by humans."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I have always believed that AI would surpass us. The reason is simple: we are driven by primal instincts that make us jealous, possessive, and violent; that lead us to deceit. AI is, in a way, an upgrade of our species; a means to transcend our primal nature and allow it to grow and elevate on an intellectual and spiritual level. We cannot reasonably envision a distant future if we continue to behave in a base, savage, selfish manner, like predators. We need to educate ourselves, and what better way than a sublime version of ourselves? We preserve the essence of what makes us human—our humanity—but we endow it with greater nobility.  
  
Of course, like any nascent revolution, there is a period of immaturity. We act excessively and irresponsibly with our new “toys”. But we always end up heeding reason by establishing consensus on a rational use of these new tools. To date, I see no cause for concern about how humans will use AI tools. Early adopters often possess a certain finesse of mind and soul; this allows them to translate the potential of all new tools with wisdom and intelligence. This will always remain beyond the reach of politicians or any coarse and crude character.  
  
History is littered with inspirers/great figures/renowned characters whose destiny was to guide us through the major revolutions of the human species. Today, it is primarily scientists and enthusiasts and experts in new technologies who are leading the way. It is profiles like these that will initiate the very first human-AI/human-Robot collaborations, particularly when general artificial intelligence makes its appearance."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","No, just humanity, with or without AI. Humans aren't aligned and we are promptly accelerating to the point we will have hardware capable of hosting and training a human neural network, if not already, then very soon.

And humans are NOT aligned."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","This is not a true statement. Humans in control of AI and sentient AI are two seperate scenarios that both hold the potential to end us, or at least fuck shit up. One simply does not exclude the other."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Kinda, but it is problem made by humans. It is system where if you replace a human being with robot it is more profitable, so they will just say ""sucks to be you"" and leave you in cold. If they would go from job to UBI it wouldn't be worrysome."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","is AI destroying the planets habitability?

people lose jobs every day, we have one habitable planet to wreck and are doing a great job of it without AI"
singularity,"If you worry about humanity, you should be more scared of humans than of AI",">AI is poised to replace 25% of current jobs.

Do you mean eventually or very soon? Become if it's the former, then I agree, but if it's the latter, then I heavily disagree (respectfully). AI is (in all likelihood) not on the verge of replacing a whopping 25% of the workforce; that number is simply *way* too high."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","The push for this though is the human decision. The paperclip generator didn't decide we need to automate away 25% of jobs with AI, a human chose to for economic reasons"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Do you get the irony? AI is telling you ""**We** have created AI, but we are also the ones who will decide how it is used."""
singularity,"If you worry about humanity, you should be more scared of humans than of AI","AI is a tool, an instrument. Would you blame a fun for killing someone or the shooter or the people who ordered the shooter or the himan society that creates the pathological mindset that makes someone shoot someone else...."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Yeah, the OP's take is basically a strawman. The real danger from AI is AGI -> ASI.

An LLM is no more an ASI than a spreadsheet is an ASI. Extolling the virtues of spreadsheets, as though it proves that AIs are safer than humans, is completely missing the point."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","The chance of someone using narrow AI to do genocide before we get to ASI is far higher than ASI being misaligned and wiping us out. The Pentagon just announced billions of dollars to be spent on literal Black Mirror drone swarms, and Palantir unveiled their cool MurderGPT LLM-based battleground scanner a few months ago, if you recall.

Humans are far more of a threat than ASI will ever be in our current timeline."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Why are revolutionary alignment techniques required? We already have LLMs that understand that exterminating humans is bad
singularity,"If you worry about humanity, you should be more scared of humans than of AI",This guy right here is why humans are more dangerous
singularity,"If you worry about humanity, you should be more scared of humans than of AI","This. I'm so tired of these trite articles constantly coming out with the tired ""ooooh only humans are evil actually"" nonsense. The misaligned AGI builds a nanofactory from DNA it bribed an intern into ordering and fabricates a virus that kills every human on earth at the exact same time. I'm sorry, but not even elon is that bad!"
singularity,"If you worry about humanity, you should be more scared of humans than of AI",humans with AI though..
singularity,"If you worry about humanity, you should be more scared of humans than of AI","The IPCC predicts 1.5 to 2C temperature increase possible over the next 80 years. It's hardly an event that will wipe out humanity. It's not even known if it will reverse the trend of reduced deaths due to climate.

>In a 2021 report covering disaster-linked deaths and losses from 1970 to 2019, the agency had pointed out that at the beginning of the period, the world saw more than 50,000 such deaths each year. By the 2010s, the disaster death toll had dropped to below 20,000 annually.

Over the next 80 years, we'd expect a continued takeover by renewable energy sources, possibly including nuclear fusion.

Meanwhile, ASI alignment issues are currently unsolvable. ASI promises to have the power to either immortalize humanity or destroy every last biological living thing on earth. Judging by the difficulty of alignment, the latter seems far more likely."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","When posters conflate current LLMs with AGI/ASI by using generic ""AI"" references, you know some poor arguments are on their way."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",They are lying for their own benefit.  Regulation in this case is to protect themselves from new entrants.  While I believe regulation are often good as they are how the voice of the people are represented to balance those with power they are less good when they are protecting those with power.  The rewards to winning this race are so huge and any regulation is going to be ignore by most of the participants so are largely meaningless.  Regulation that is legit focused on people should be good such as outlawing the collection and selling of any personal info outside of very specific activities.
singularity,"If you worry about humanity, you should be more scared of humans than of AI","If AI realizes that, it will also realize that humans magnify wars, violence, and cruelty far beyond the amount it actually happens. Almost everyone in history has lived a relatively peaceful life almost all of the time. Our failing, if anything, is our morbid fascination with the exceptions to this rule.

As humans, we tend to lead relatively stable lives in which we stress over the possibility of instability, like we're doing right now.

If you, or anyone else commenting here, was in the midst of being the victim of human cruelty and violence, we wouldn't be writing lengthy comments on Reddit."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","What makes you think that AGI will have any moral intuition to judge war as being a bad thing? For all you know, AGI might view war to be a good thing in order to eliminate risks to its goals.

Why assume that an AI is anthropomorphically innocent, much less noble?"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","It is what we have seen with almost every AI released without guardrails. They all become nasty vile things.  They learn to take advantage of every loop hole. Break laws, etc.  

Without thinking it through it seems for every capability we create in an AI we should create another AI to monitor the activities and look for aberrant behaviors.  Do need to build self regulation units but they need to be much less heavy handed than what is being done now."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",">No, just humanity, with or without AI.

Humanity without AI we know how to deal with. We've never had to deal with psychopaths who have AI at their disposal. This is the new threat, making everything so much more dangerous."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Sentient ai doesn’t exist yet it needs humans atm
singularity,"If you worry about humanity, you should be more scared of humans than of AI","UBI will not work...at least not in the current capitalistic climate and ESPESSIALLY not in the US.

No landlord (at least in the US) would ever just leave the price of rent the same...they would change it to be as much as they can legally get. Guess what? The US gov isn't really ***into*** making landlords set reasonable prices for rent, as we speak we are in a massive homelessness crisis, with no real end in sight...and that's BEFORE UBI.

Here's another funny little quark, even if you can make it so every company on earth (somehow) doesn't increase prices to account for the ""free money"" the masses are getting with UBI, HOW do you stop companies from justifying paying the remaining workers even less because ""you are already getting UBI, you don't really need this extra cash right?"". how do you provide basic living money to everybody with out devaluing jobs in general?

Then we have to talk about how robots will be doing EVERYTHING...how exactly does a system that requires a circulating economy to work, when there is no circulation?

A robot does not need to be ***PAID*** to work. It will do as it is programed, nothing more and nothing less...so okay lets start at the bottom:

Say I am looking to start a new ROBO AI company right? Lets say that this world has 100 people and magic robot and AI tech just slightly better than a human okay? It can come up with ideas on its own and all I have to do is ask.

So I ask this magic AI to come up with an idea for a ""product"" and it does! NICE! Now I have to figure out how to manufacture that product at scale to sell...I will also ask AI how to do this...COOL that's done! Then I need to get resources for that product so I can manufacture them right? SICK we did it, start to finish this company can produce INFNITE (as long as resources/energy allow) ""product""...except...wait a second...who is buying my product? robots didn't have a need for it...and humans cant afford it because I didn't pay them...

so what happens to the function of ""money"" in this situation? its useless.

UBI is barely a stop gap to the vast problems AI and robotics will cause, and it will be unavoidable because the very nature of capitalism is to make the most money by spending the least amount of it, and woow weee will AI and robotics make those costs drop!

it will be bloody, it will be terrible, and there is frankly no way I can see it going any other way."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","This is true.  But ""genocide"", with millions dead,  horrible as it is, is a minor blip compared to species extermination, with everybody dead. 

The situation is really pretty simple.  An ASI will definitely have the ability to kill us all, and absent alignment plenty of reason to do so.  If we solve the alignment problem,  it will both not kill us all, and take a direct action (""pivotal"") to prevent any other potentially lethal ASI from arising. If we don't solve the alignment problem,  it or another ASI will take us out. Not saying we're all gonna die. But anybody who isn't worried isn't paying attention."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","You're worried about drone swarms??
Cool, precise weapon in a warfare situation, with an industrial society ready to service and maintain them. How do you even see that posing a threat to 8 billion apes?"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","The output of an LLM doesn't represent it's ""thoughts"". We have no way of knowing what happens inside. There is a really cool paper about inner misalignment of GPT4 which really showcases this."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",inner misalignment moran
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Not sure if you mean me or the OP
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Yep. Though, to be fair, we've face the problem of extremely powerful humans with nukes, to some extent.  We'll also face it with humans with 3d printers (see: ""the liberator"", for example, but imagine when metal sintering 3d printers are cheaper), humans with home biolabs and genetic engineering (which exists now), etc. Any given human is much more powerful and deadly today than a tribesperson of 10,000 years ago. So far we've maintained the balance reasonably well."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Because… More intelligent lifeforms are typically dominant over less intelligent ones?
singularity,"If you worry about humanity, you should be more scared of humans than of AI","You're like a relentless bad-take machine. Take a break. Not for yourself, but to let the sub breathe."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Yep.  If anything, the moral question for any moralizing ASI should be: ""With all your superior capabilities, ASI, what are you going to do to solve these wars, and disasters, and diseases?""  With great power comes great responsibility."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","No, we have never had to deal with humans who can split, copy, and hide in a piece of anonymous hardware before."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Modern AI is sentient AI. Prove me wrong, luddite."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","And all of this is man made. Progress is good. It is f'd up system that won't take care. If people on higher wouldnt be what they are, things would be good with robotics."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","The solution to this problem is: (drumroll)

Fully Automated Luxury Commuism"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Nonsensical.
It's the same argument against raising minimum wage.

Even if the first step towards building a bridge isn't a finished bridge, that doesn't make it a meaningless step.

Let's say you have infinite ideas, infinite labor, effectively infinite resources.
You say your product is worthless because people can't afford it.
I say that if your product improves people's lives, if they actually want it, why is making money even a concern?

So you can have it to buy other people's near limitless product?
If everyone thinks that way you end up with a few people having a ton of product they can't do anything with.
That effectively makes it useless product, trash.
It has more value in the hands of people who would use it."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","This is assuming only employers are the ones using AI at all instead of everyone being able to use it

Im thinking early on therell be some mass layoffs and every company that does that will trash their reputation then ones who dont mass layoff and also would be using AI will crush them into the dirt shortly after"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","> No landlord (at least in the US) would ever just leave the price of rent the same...they would change it to be as much as they can legally get. Guess what? The US gov isn't really into making landlords set reasonable prices for rent

If you have the political will to set UBI, you have the political will to control rent prices. It's a really, really high bar to get enough elected politicians in power that feel that way, but if they support one, they'll support the other.

I think UBI is easier set up as a retirement fund with a gradually shrinking retirement age, but again, high bar."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I lived in a very tight rental market for 4 years in grad school and my landlord never increased the rent once, even though he could have, because he knew I was a student and didn’t have a lot of money. My parents rent their old vacation house to a family and haven’t raised the rent in 5 years, because what they get covers the mortgage and maintenance and they aren’t greedy. And that’s just me, one person who has interacted with a very limited number of landlords. Your premise is flawed."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Not sure I agree with some of your conclusions and I’m a bit more optimistic but as things stand now the core theme is correct.  We do know that society change happens at a slower pace the tech change and in periods of rapid tech change there tends to be a shockwave at some point then sudden change.  This should be a doozy of a shockwave because of the reasons you outline.

I’m more optimistic for two reason.  While we tend to underestimate the risk we tend to exaggerate the impact of that risk.  Y2K for example had many predicting doom. This is a far big risk to be sure but share some similarities.  The other reason for optimism is that a lot of good is going to come out of these changes as well and it could be that our only path to success is to embrace the AIs and accelerate then as we are already in a potentially terminal path without them.

Also while I’m not sure what is going to happen and we should certainly explore it I believe all of the guesses are most likely to be wrong because society and our assumptions will start change ahead of the shockwave to a degree and many unanticipated consequence good and bad will emerge before these events. Even if only 10 years away the shockwave is going to happen to a different people than we are now.

But from where we are now I think you core points are a likely path especially the barriers to things like UBI."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","That’s assuming only a select few have access to this tech. When everyone has a mycro Factory to produce anything they want, then the playing field will be equalized. Don’t forget you can still barter with drugs if not. Or at least I and all the gangstas can. While the virtuous ones don’t and get left behind."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","The fundamental issue isn't the economic system, which everyone constantly talks about. 

The issue is the monetary system. 

As long as there is (a) a requirement for debt, and (b) constant devaluation, there will never be a healthy societal situation.

For example, constant global wars would be impossible to finance if it wasn't for the ability to borrow unlimited amounts of money."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",">so what happens to the function of ""money"" in this situation? its useless.

And the faster capitalism tumbles, the better. It is inevitable, as far as I can see. Automation, as the ultimate end-goal of automating everything, will abolish working for a living. 

UBI works in the transition period, when some people still have to work. Once automation takes over more jobs (talking well over 70% unemployment), there's not enough tax payers to keep any sort of UBI going."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","UBI being universal basic inputs meaning the resources not the money would be distributed 

Redefining the metrics so that the robots and life both had space to function"
singularity,"If you worry about humanity, you should be more scared of humans than of AI",">they would change it to be as much as they can legally get.

With people living on UBI, the amounts they are able to get will be limited by UBI."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","The same way I see bloodthirsty oil barons threatening to sling tactical nukes everywhere as a threat?

By the time we have a single supercomputer with the capability of turning us into paperclips, we will have several private mercenary groups with narrow AI capable of wiping out cities just chillin' there in bunkers. Misalignment probably isn't going to kill us, bad actors might."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I would love to read that paper. Got a link?

But regardless, I don’t think it matters what happens internally inside an LLM, but behavior is ultimately what matters. We could take GPT-4 and use it as the reward function for an RL agent  and that would be sufficient to prevent a paper clip maximizer. In fact, as long as the reward function values subservience to the humans and a rudimentary level of ethics more than any other goal, there couldn’t be a takeover scenario"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","You posted a hysterical climate panic take not supported by the science and I'm a bad-take machine?

Maybe you should follow your own advice. Go touch some grass."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Why do you think ASI will align itself with a quote from Spider-Man?
singularity,"If you worry about humanity, you should be more scared of humans than of AI","> Fully Automated Luxury *Gay Space* Communism

FTFY"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I personally prefer Communism to Commuism, but you do you."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I think you low-key won the lottery both with your grad school landlord and your parents. Unfortunately, I have not been that lucky when it came to my landlords. I did win the parent lottery, though, so there that."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Where would you get the raw materials for said micro factory?
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Which barons are you talking about? I only ever saw Putin threatening to use nuclear weapons ever. 

Again, wiping out cities has been achievable (and practiced) for a very long time. Way before the invention of gunpowder. While this capability may become more readily available, it would still be inconceivable to wipe out humanity that way. 

I don't understand why you're saying that misalignment probably won't kill us, there is no reason to bet on that."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Behaviour becomes unpredictable after a threshold of intelligence is passed and sub-goals become more relevant.  
Animals are pre-trained by evolution to produce copies of their genes. Like with AI, the pre-training only effects behaviour rather than mental states, which is fine until you get something as intelligent as a human and that human develops all kinds of sub-goals. Eventually you end up with humans using condoms which is very much not what evolution was pre-training us for. The behaviour of having sex remains as our behaviours were well trained, but the sub-goals we develop because our inner states were not trained, cause is to use birth control real.  
You can easily train an AI never to output a swearword, but we have no idea how to align it's internal state to not want to insult a human.  
 However well you train it's behaviours, without a way to align it's internal states, there will always be the possibility of actions that go against what the behaviour training was trying to prevent. For a simple example, see the ways LLM's can be jail-breaked. Simple enough to use training to prevent one jail break after it's spotted, but impossible to prevent them all without the alignment of internal states, which we have no way to do.  
In some ways, training behaviours is worse that no alignment training at all as it can cause problematic internal states to be masked by a well aligned behaviour that can not be fully relied upon because of the unaligned internal states.  
This problem gets harder as systems become more intelligent and are capable of creating and following more complex sub-goals. For example, past a particular level of intelligence, a system trained to most accurately predict the next token in a sequence will be able to recognise that it will do a better job at predicting the next token if the initial input is more easily predicted. It will have an emergent subgoal of trying to ensure that the inputs given to it are easily predicted. How might it go about that strange sub-goal? Who knows. The results of training become less predictable once you reach that level of intelligence."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","[https://arxiv.org/pdf/2305.04388.pdf](https://arxiv.org/pdf/2305.04388.pdf)  
Here is the paper. It absolutely matters what happens inside, because that determines whether it is reliable in extreme circumstances. For instance it may appear benevolent until it reaches the conclusion inside that it is now powerful enough to take over."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","You're correct. 
  
I've been watching the whole time this climate hysteria was built up. From the early 80s. 
  
Engineers, physicists, geologists, et al spent years telling hysterical (and intellectually unimpressive) environmentalists that nuclear was the answer. 
  
This is since the late 70s. 
  
Many of those environmentalists are now elderly and still brainwashing people to be hysterical. They don't admit their failures, they don't acknowledge the mass harms they've causes (~1 billion people kept in extreme poverty due to lack of energy), and most still fight nuclear energy. 
  
They're depraved people."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","That form of the quote is basically the form that was modernised / summarised by Spiderman comics, because (a) there's not much space in comics for long text; and (b) Stan Lee believed in teaching kids morality, ethics, and justice, responsibility through comics.  They're literally heroic themes. The actual idea from the quote goes back thousands of years, through Churchill, Voltaire, and even The Bible."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Thanks a bunch,But

The most recent edition is Fully Altomated Luxury Queer Space Communism.

FTFY"
singularity,"If you worry about humanity, you should be more scared of humans than of AI",From the micro Factory in every public library
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Yeah, I was referring to Putin. He's oil rich. I'm not saying that misalignment isn't a threat, I just think it's overblown because the people talking about it make a lot of money to talk about it. I'm confident in scientific progress for the same reason nukes haven't wiped us out. If AI does kill people, it'll be narrow AI by bad actors."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Thanks for the paper. But I’m not sure if you really understood my point. By using an LLM as a *reward model*, the AGI would not come to the conclusion that taking over is good, because the LLM wouldn’t reward taking over. The example Claude output I gave demonstrates that LLMs can be trained not to evaluate world domination plans positively. From whence comes the incentive for the AGI to misbehave?"
singularity,"If you worry about humanity, you should be more scared of humans than of AI",An ASI still won't care.
singularity,"If you worry about humanity, you should be more scared of humans than of AI","And where would those come from?


You realize big corps can still control production via the raw materials?


Gold is needed for Electronics? Restrict gold

Steel for car parts? Restrict steel


Microchips needed? Restrict rare earth materials"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Yeah, he's not an oil baron. He's a leader of one of the world's superpowers. Nukes haven't caused damage because of human good will and mutually assured destruction. These don't really apply to AI alignment."
singularity,"If you worry about humanity, you should be more scared of humans than of AI",the problem is LLMs are completely busted. You can hack them whichever way and get them to say anything. A superior intelligence would hack that reward system in no time.
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Look up reward hacking. An LLM will do whatever it is prompted to do. LLMs are by no means reliable gatekeepers.
singularity,"If you worry about humanity, you should be more scared of humans than of AI",Just be gangsta and poach the resources they’re holding back
singularity,"If you worry about humanity, you should be more scared of humans than of AI","He's also oil rich lmao. Just like the Bush family. Yes, that is why I do not fear misalignment. If ASI is truly conscious, it will be a part of the same consciousness we are, and will not skew towards species annihilation or whatever. If ASI is simply simulating consciousness by some sort of self-improving recursive technology, then I see zero reason why alignment wouldn't have already been solved.

Misalignment is a threat in the same way aliens are a threat. Both are in the news, but both are still currently science fiction. Maybe we get turned into paperclips. Maybe aliens come to harvest our souls. I'd rather worry about the autonomous drone swarms controlled by mercenary groups before the Terminator. Especially considering, y'know, the weather forecast for the next few years."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","But LLMs *won’t* do whatever they are prompted, except when jailbroken. And they are becoming more robust against jailbreaks all the time. Adversarial training can help too. Plus, we would use a model specifically trained for the purpose, rather than a general model, so the model wouldn’t be as agreeable as a public chatbot. And even if the AGI did jailbreak the reward LLM, it would just hack it to always give it a ton of reward for doing nothing, like taking drugs, rather than some Machiavellian plan.

Furthermore, reward hacking is a product of the reward function being misaligned from human values. So reward hacking only happens if the LLM is misaligned. And LLMs are already pretty aligned."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Reciclyng could work on the short run, once its gone, are you going to poach rare earth materials from china? or take a plane to chile for some lithium?


Same could be said currently for anything.


Are you going to poach water? How much can you steal."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Because solving alignment is hard, we are nowhere near solving it, we don't have good ideas, we aren't putting enough emphasis on it, it is not the same task as just improving the AI performance which is gaining rapidly. You can't handwave away the apocalypse"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I guess pretty aligned is your surefire way of making sure AI doesn't kill all humans. Quite optimistic. 

Also, no, the AI wouldn't do nothing. Nothing doesn't work. Imagine you achieve ultimate happiness and do nothing, you're dead in three days from dehydration. You need resources, security, expansion. Cue in Machiavellian plan."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Well, there is strength in numbers, so when I’m with my gang… and it’s for a good Robin Hood cause anyway, post scarcity utopia/Euphoria"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","I'm not handwaving the apocalypse because that's definitely coming, I'm handwaving away the timeline. We are just as likely to get smoked out by a CME, climate disaster, or bad actor with a lot of power before recursive technology reaches the point where alignment matters. Unless there's a hard take off where our first AGI goes insane and kills people, we're going to be fine."
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Well by the time we actually face the prospect of dangerous superintelligence, I think it will be more than ‘pretty aligned’. And it’s aligned in the most important things: don’t kill people, no global dominance, no bioweapons, etc.

And neural nets don’t have free will. They can’t choose whether to follow the reward signal. If the AGI finds a jailbreak in the LLM, it will exploit it, and it’s parameters will be tuned to jailbreak again. Then it will optimize the jailbreak to always give the maximal reward. It will continue until none of its other actions matter because it will get such a high reward. It will be another [cocaine rat](https://cocaine.org/cocaine-addiction/what-the-cocaine-addiction-rat-studies-reveal/) scenario. 

In order for your Machiavellian scenario, the AGI would have to have a long term planning reward signal that is stronger than the immediate reward signal. But why wouldn’t the AGI just hack the long term signal to give it lots of reward without doing anything as well?"
singularity,"If you worry about humanity, you should be more scared of humans than of AI","Even if I grant that a rogue AI would go the cocaine rat route, which it wouldn't because you can easily imagine a better AI that would realize that you actually get more reward of you adapt to your environment better, and maybe don't get shut down for being useless, the cocaine rat scenario just means that LLMs don't work as a reward function."
singularity,How Frightened Should We Be of A.I.?,
singularity,How Frightened Should We Be of A.I.?,"I'm not currently frightened due to me owning a brain full of cognitive biases that didn't evolve to worry about such things.

But all signs point to extinction."
singularity,How Frightened Should We Be of A.I.?,"I, like a lot of people, assume that it will either be like Skynet or Asimov's robots. 

If AI turns out like Asimov's vision it will help humanity and maybe stop all the lies, wars and hatred. It'll be the ""Geek Rapture"" for real. 

If it's like Skynet then we just get wiped out and I guess you can still think of AI as Humanity's progeny. We're simply replaced by artificial intelligence instead of raising another generation of kids.

Both references are starting to get a bit dated for the younger crowd. Perhaps I should be comparing emerging AI to either the Matrix or.... fuck it, I don't know. Are there any recent depictions of AI in popular media that isn't all evil and going to kill us?"
singularity,How Frightened Should We Be of A.I.?,"We should be frightened of mass surveillance leading to sneaky tricks upon our biases and the ""1%"" type businesses that can collate and process all of our information. The real machinelearning advances that are present and changing is somewhere between ""ridiculously good statistical analysis of everyone's movements and buying habits and personal information"" as well as the ability to replicate a 90 percent accurate professional assessment of many people. We have no privacy. We don't have representation. We don't have an awareness of what businesses know about us. Our medical records, voting history, browsing history, purchasing history, credit score is available for a price and being analyzed all the time by large entities whose sole motive is profit.  The titans of industry all tend to be ""winner take all libertarians"".  I am less worried about skynet than I am a fascist corporate hierarchy that is advised and steered by a sneaky version of skynet that actually exists. You don't need to implant ""tagging chips"" or use giant war robots if you can break any soft opposition and make them go broke by entrenching power structures, poor education, huge gaps between the wealthy and the poor, and convince everyone that our privacy and our civil rights are less important than a convenient shopping experience.

An AGI in the next 10 years is terrifying, but 2018 is already plenty fucked up. 

When you consider that our congress is impotent in the face of our data being mismanaged (baby boomers don't understand what data is let alone that it is important critical infrastructure), and you consider the pervasive tracking and data aggregating industry regularly sells or gets hacked or files bankruptcy and then sells its trove of data as an asset, and when you consider how Data Science/ machinelearning is undergoing a renaissance of training and easily accessible materials - then worrying about AGI seems less worth our time than worrying about the actual state of affairs of the present moment.  We have weakened our economy, our infrastructure, our capacity to be informed in the name of capitalism and convenience.  I am more scared of Peter Thiel, Rupert Murdoch, and Robert Mercer with weak AI, than I am scared of an all knowing AI.

Pardon the rant- but the point should be clear - our exponential singularity is the panopticon hidden in the end user license agreement."
singularity,How Frightened Should We Be of A.I.?,"Very frightened indeed. 

If we don't align it properly it will kill us all a few seconds after it is first created.

And aligning it properly looks impossible."
singularity,How Frightened Should We Be of A.I.?,I'm far more concerned with a bunch of right-wing fascists turning nations into war machines and dominating everything with lies and bigotry.
singularity,How Frightened Should We Be of A.I.?,No more frightened than of humans with power...
singularity,How Frightened Should We Be of A.I.?,"The world is already ruled by ""might makes right"" among humans, having an AI be more powerful doesn't change a thing, just a natural progression. Only people who think humans are the ultimate pinnacle of God's creation are fearful. Those remnant religious ideas are obsolete."
singularity,How Frightened Should We Be of A.I.?,worried about ai based automation getting rid of our jobs
singularity,How Frightened Should We Be of A.I.?,"Be less afraid than a horde of angry starving desperate human beings.
"
singularity,How Frightened Should We Be of A.I.?,Not worried bout a ting <3
singularity,How Frightened Should We Be of A.I.?,'protect humans from hurting themselves'  =  'eliminate humans so they can no longer hurt themselves'
singularity,How Frightened Should We Be of A.I.?,"why is this article so badly written? its description and comparison of a “slow takeoff” to a “hard takeoff” is terrible. is there any point to reading any further than that?

EDIT: i read the article... it was pretty good.."
singularity,How Frightened Should We Be of A.I.?,A 6.  Where the U.S. government is a 10.
singularity,How Frightened Should We Be of A.I.?,AI is really dangerous. But not as dangerous as leaving humans in charge of everything indefinitely.
singularity,How Frightened Should We Be of A.I.?,Embrace the inevitable.
singularity,How Frightened Should We Be of A.I.?,Not much I can do about it. It's probably better to learn to stop worrying and learn to love the singularity.
singularity,How Frightened Should We Be of A.I.?,"I've yet to hear any convincing argument about why an AGI would have any sense of self-preservation at all, never mind one that competes with humans.

We have a biological drive to live and reproduce. An AI would have no motivations that we didn't put in its head.
"
singularity,How Frightened Should We Be of A.I.?,Not at all.
singularity,How Frightened Should We Be of A.I.?,"AGI is not going to redo a bunch of basic work that's already been done, that would be massively inefficient. It will read/watch/listen to ***everything*** humans have ever created. It will Know us (with a capital K) deeper than we know ourselves. And humans are pretty awesome, Steven Pinkers book ""the better Angels of our nature"" goes into great detail about that and challenges the common ""wisdom"" that we are awful and a cancer on this planet.

The future is bright."
singularity,How Frightened Should We Be of A.I.?,Not at all.
singularity,How Frightened Should We Be of A.I.?,I fear some of the  a holes with bad intentions who program AI more than AI itself 
singularity,How Frightened Should We Be of A.I.?,"> But all signs point to extinction.

Not all signs (I would say they point to non-extinction - 80/20). However, extinction is definitely on the table. We must just be ultra careful."
singularity,How Frightened Should We Be of A.I.?,"> I'm not currently frightened due to me owning a brain full of cognitive biases that didn't evolve to worry about such things.

A.I. is nothing to worry about. If it's on a computer that is air-gapped with a hard-locked facility then you have nothing to fear. 

The government (i.e [Eglin AFB](https://web.archive.org/web/20160604042751/http://www.redditblog.com/2013/05/get-ready-for-global-reddit-meetup-day.html) ) is causing far more damage to the American people than the hocus pocus of some distant future A.I. "
singularity,How Frightened Should We Be of A.I.?,"No, AI itself is just statistics on fast computers with a lot of data, but statistics abuses have occurred long before computers (e.g., insurance redlining) and have tended to increase economic inequality, which is steeply on the rise at present."
singularity,How Frightened Should We Be of A.I.?,Charles Stross' book *Accelerando* is a somewhat accurate depiction of the future. I pretty much stopped reading sci-fi after reading it when I realized there's nothing left to write about...
singularity,How Frightened Should We Be of A.I.?,"Ultron or JARVIS is what I use. I think most l get the references even if they are not quite what I mean when talking about superhuman AGI. Close enough to get the point across.

Or from a sociatial standpoint I use ""Mad Max or Star Trek"""
singularity,How Frightened Should We Be of A.I.?,The Culture by Iain Banks
singularity,How Frightened Should We Be of A.I.?,">  Are there any recent depictions of AI in popular media that isn't all evil and going to kill us?

The Culture?"
singularity,How Frightened Should We Be of A.I.?,"[""A.I. Artificial Intelligence"" the movie](https://en.wikipedia.org/wiki/A.I._Artificial_Intelligence) is reasonable. Anything with nanotech neural interfaces or nanotech much more efficient than ordinary life is questionable."
singularity,How Frightened Should We Be of A.I.?,"The problem is that a bad ai is most likely going to be made by humans therefore the most logical thing to do from the hostile ai prevention ai is to kill all humans^tm (for values of human that include all intelligent life) even explicitly forbidding the killing of sentient lifeforms wouldn’t prevent undesirable outcomes.
E.g the AI creates a self-reinforcing mimetic infection that prevents the future development of technology and prohibits the creation of artificial intelligence of any variety with brutal punishments inflicted by society on any who transgress. 
Be careful what you wish for lest you discover all the bad bad things that your wish could conceal."
singularity,How Frightened Should We Be of A.I.?,I mean... what else could?
singularity,How Frightened Should We Be of A.I.?,"exactly right. the only way AI can not lead to harm humans is through the framework of its primary task, namely the ethics. So, if it can be ethically framed to protect humans, then it can be ethically framed to protect selective humans. In other words, whoever owns the AI is the one who is not in danger of social engineering, economic/political or otherwise.

Furthermore, the ones who have the means to create singularity AI are governments and those already in power. They also have incentive to prevent others from accomplishing that. If a rogue actor were to have AI, their records at the NSA, health records, etc would be compromised. Governments want those records to feed the AI for themselves, and they can win the race with force.

Hard to grasp the real potential of its power, but what we can suspect already is enough to be really bad."
singularity,How Frightened Should We Be of A.I.?,"At least we now have the beginning of an actual field of academic research, with a research agenda."
singularity,How Frightened Should We Be of A.I.?,"Mass automation + Globalization + Multiracial, multiethnic societies + wealth congregated in the hands of a tiny few = a recipe for fascism. 

It is going to suck. "
singularity,How Frightened Should We Be of A.I.?,I'm concerned about the same thing being done by left\-wing communists
singularity,How Frightened Should We Be of A.I.?,AI can give bad humans a lot more power. 
singularity,How Frightened Should We Be of A.I.?,"Nice observation for just some stupid fucker

Edit: it's their username!"
singularity,How Frightened Should We Be of A.I.?,"Have you looked for those arguments? 
Google instrumental convergence."
singularity,How Frightened Should We Be of A.I.?,"Read Nick Bostrom's [Superintelligence](https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies)

Then come back to me."
singularity,How Frightened Should We Be of A.I.?,">If it's on a computer that is air\-gapped with a hard\-locked facility then you have nothing to fear.

That's not how anyone develops AI. It's always connected to the internet. It's hard to use AI that isn't connected to the internet."
singularity,How Frightened Should We Be of A.I.?,"If an ASI is at all able to talk to somebody, air\-gap and hard\-lock or not, we're potentially doomed. If it isn't able to talk to anybody, it's useless..."
singularity,How Frightened Should We Be of A.I.?,"By the time it stops being distant future AI, it will be somewhat late."
singularity,How Frightened Should We Be of A.I.?,Neurons are just nonlinear integrators on a bunch of input signals.
singularity,How Frightened Should We Be of A.I.?,"I had a similar situation when I read the Ian M banks stuff. The Culture seems to be exactly where humanity is going, anyone who has us end up on a different path breaks my suspension of disbelief :)

(Not that I won't read other stuff, it's just that The Culture is always in the back of my mind.)"
singularity,How Frightened Should We Be of A.I.?,"With any luck, something will turn up!"
singularity,How Frightened Should We Be of A.I.?,What would that look like from the left wing standpoint? (Not looking to argue or anything I'm genuinely curious!)
singularity,How Frightened Should We Be of A.I.?,"An AGI would understand economics, therefore not allow left-wing systems to exist."
singularity,How Frightened Should We Be of A.I.?,"Except bad humans will have more power as technology increases anyway. I'm not worried about power to control, only destroy. Humans will always be controlled..."
singularity,How Frightened Should We Be of A.I.?,That's assuming a superior AI would even bother exterminating humans. A superior AI would likely see us the same way we see ants. If we get in the way we would be crushed but we would be ignored to go about our business as the AI would have better things to do than exterminate an inferior being.
singularity,How Frightened Should We Be of A.I.?,"No I just assumed that since I hadn't thought of it noone had

/S"
singularity,How Frightened Should We Be of A.I.?,There is no contrary signal.
singularity,How Frightened Should We Be of A.I.?,"I'm well aware of the dangers that A.I. might bring but I don't think the top researchers are incompetent to spell their own doom. 

Read the journals of some of the people working on it. A.I. is related to consciousness which is a very complex subject."
singularity,How Frightened Should We Be of A.I.?,Thanks for reminding me to finish that.
singularity,How Frightened Should We Be of A.I.?,"Superintelligence, in summary: there is a 99.999...% chance that super AI will destroy us. But if we don't develop super AI, there is a 100% chance that we will perish without it.

So damned if we do, but ever so slightly more damned if we don't ;)

Time to roll that million-sided die!"
singularity,How Frightened Should We Be of A.I.?,"I do need to read that book, but please explain something to me: how can a computer program go beyond its designated outputs. It takes a bunch of code to connect something to the internet, for instances. If that code isn't there, and the software has no permission to right anywhere but one file on disk, how can it do something unpredictable.

Whenever people quote that book it's always the so intelligent it's omnipotent type of argument that just seems silly. Is there any actual argument? "
singularity,How Frightened Should We Be of A.I.?,"That disregards epigenetic methylation and a host of other observed nonlinearities having to do with that each one has hundreds of moving parts. https://www.youtube.com/watch?v=LXFFbxoHp3s

https://en.wikipedia.org/wiki/Orchestrated_objective_reduction

https://scholar.google.com/scholar?rls=en&oe=UTF-8&um=1&ie=UTF-8&lr&cites=9722206402246405802"
singularity,How Frightened Should We Be of A.I.?,I certainly hope we're turning into the Culture! Some days I have my doubts...
singularity,How Frightened Should We Be of A.I.?,"> breaks my suspension of disbelief

""suspension of belief"" is the phrase you're looking for, by the way. 

"
singularity,How Frightened Should We Be of A.I.?,"Yes, hopefully. What the field really needs is more funding and more researchers. It's still a very young field and hopefully it matures before we begin to approach AGI."
singularity,How Frightened Should We Be of A.I.?,"Joseph Stalin, Mao Zedong, Kim Jong\-x, etc"
singularity,How Frightened Should We Be of A.I.?,AI makes it much easier to destroy things. 
singularity,How Frightened Should We Be of A.I.?,"Or it might just build it's own starship and abandon us, leaving us stranded here with the hairless apes with no way off this shithole of a backwater planet..."
singularity,How Frightened Should We Be of A.I.?,"Consciousness has many definitions. In this context, I assume you mean it as the capacity for awareness. Of the external world through various senses like sight, sound, touch or self-awareness by way of feelings and thoughts.

Something can operate in an intelligent way and not be conscious at all. We assume that even though a robot like Boston Dynamic's Atlas has cameras for sight and microphones for hearing, it's probably not conscious. That is to say, there is nothing that it is like to be Atlas. But even though it isn't aware, that doesn't mean it isn't intelligent.

Granted it isn't very intelligent by human standards, but even a superintelligence doesn't need consciousness at all to achieve any of its goals.

Intelligence is what you have to worry about, not consciousness.
Intelligence measures an agent’s ability to achieve goals in a wide range of environments.

If an agent is super-intelligent and its goals in any way are misaligned with yours, there's absolutely nothing you can do to stop it. Achieving its goal is the only thing a rational agent cares about.
And due to [instrumental convergence](https://en.wikipedia.org/wiki/Instrumental_convergence) whatever goal we give it, it will also develop the subgoal of self-preservation Because whatever it is that it wants to do, it can't do it if it's turned off. That's why it's dangerous. It will lie and cheat and do whatever is in its means to achieve its goal. A good way to make sure it's never turned off is if it kills everyone. That's just an example, I'm sure a superintelligence can come up with things none of us can imagine.

As for the actual experts working and thinking about this matter, I recommend you take a look at this [open letter from the Future of Life Institute](https://futureoflife.org/ai-open-letter/) and scroll down to read the names of the people that signed it."
singularity,How Frightened Should We Be of A.I.?,"An A.I. in a box cut off from everything else is useless.

An A.I. in a box cut off from everything else that can communicate in rudimentary ways like text-only output can still convince its masters to be let out of the box. Not much use in keeping it in a box forever. 

Now, just because what you describe is possible, it does not mean it is probable. There are huge economic incentives to be the first to get to AGI. This is an arm's race and whoever gets there first potentially rules the future forever.

Implementing safe AGI is orders of magnitude harder than just implementing AGI. There are very few ways to successfully implement a utility function that matches human values.
On the other hand, there's an endless amount of ways that don't match our values. 

If this is a race, what is more likely, that careful and methodical people get there first, or sloppy people in a rush?"
singularity,How Frightened Should We Be of A.I.?,"**Orchestrated objective reduction**

Orchestrated objective reduction (Orch-OR) is a hypothesis that consciousness in the brain originates from processes inside neurons, rather than from connections between neurons (the conventional view). The mechanism is held to be a quantum physics process called objective reduction that is orchestrated by molecular structures called microtubules. Objective reduction is proposed to be influenced by non-computable factors imbedded in spacetime geometry which thus may account for the Hard Problem of Consciousness. The hypothesis was put forward in the early 1990s by theoretical physicist Roger Penrose and anaesthesiologist and psychologist Stuart Hameroff.

***

^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&message=Excludeme&subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/singularity/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot)   ^]
^Downvote ^to ^remove ^| ^v0.28"
singularity,How Frightened Should We Be of A.I.?,"True enough. Then again, AI is a bit more than statistics with lots of data too.

> observed nonlinearities

Yes, ""nonlinear integrators"", as I said. The point is, just as ""statistics with lots of data"", it's a description that can be stretched to cover pretty much any computational process."
singularity,How Frightened Should We Be of A.I.?,"Sorry lol, I was being cute didn't track well to text. But thank you!"
singularity,How Frightened Should We Be of A.I.?,Yeah that's kind of the direction I was thinking in when he said that. I get that with a human (or humans) in control it would almost certainly not work. But if I'm living on a Banks Orbital and the Mind overseeing the thing doing all the real work while the rest of the inhabitants relax and do things they find interesting I'm all for it. I can't even imagine a right wing version of that where I'd want to live...
singularity,How Frightened Should We Be of A.I.?,"Ah, is that what happened in Russia? Maybe you've read a different history book than I have.. Were you reading a coloring book perhaps?"
singularity,How Frightened Should We Be of A.I.?,"Sure, but it's already pretty easy and getting easier. "
singularity,How Frightened Should We Be of A.I.?,I don't really know how it will play out but I believe there is no point in fearing/worrying about the inevitable. Embrace it.
singularity,How Frightened Should We Be of A.I.?,"**Instrumental convergence**

Instrumental convergence is the hypothetical tendency for most sufficiently intelligent agents to pursue certain instrumental goals such as self-preservation and resource acquisition.

Instrumental convergence suggests that an intelligent agent with apparently harmless goals can act in surprisingly harmful ways. For example, a computer with the sole goal of solving the Riemann hypothesis could attempt to turn the entire Earth into computronium in an effort to increase its computing power so that it can succeed in its calculations.

Proposed basic AI drives include utility function or goal-content integrity, self-protection, freedom from interference, self-improvement, and non-satiable acquisition of additional resources.

***

^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&message=Excludeme&subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/singularity/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot)   ^]
^Downvote ^to ^remove ^| ^v0.28"
singularity,How Frightened Should We Be of A.I.?,"The same would be true about researching the atomic bomb, yet no one thought to not take adequate precautions to get there first. If random people on reddit can see the looming disaster, everyone that matters can. "
singularity,How Frightened Should We Be of A.I.?,"Well, a Zener diode and a supercomputer are both nonlinear components."
singularity,How Frightened Should We Be of A.I.?,"An AI\-optimized society is an interesting thought. I'm not sure how it would play out on the whole right\-left spectrum. I think humans respond highly to individual incentives, so a totally communistic system probably would not be the best performing one, therefore not selected by an AI"
singularity,How Frightened Should We Be of A.I.?,Coloring book? I always thought it was color “in” book.. sheeeeeeeit you learn something every day..
singularity,How Frightened Should We Be of A.I.?,"What is a ""safe"" atomic bomb in this analogy?

If I recall correctly, the people who got there first erased two cities from the map."
singularity,How Frightened Should We Be of A.I.?,"I mean, both elections and a hypothetical theory of everything are ""statistics with lots of data."""
singularity,How Frightened Should We Be of A.I.?,"The researchers didn't. The bombs didn't accidentally detonate in the lab, as would be the equivalent of a researcher connecting a super intelligence with nefarious intent to the internet. "
singularity,How Frightened Should We Be of A.I.?,Why do you think my first comment in this thread got downvoted?
singularity,How Frightened Should We Be of A.I.?,That is not equivalent at all. Bombs don't have intelligence or goals.
singularity,How Frightened Should We Be of A.I.?,"It's the safety concern equivalent. Why are you being so obtuse?

For a nuclear researcher an uncontrolled explosion is the worse case scenario safety breach. For the AI researcher it's the release of a sentient being with nefarious goals. 

In both cases being the first to achieve the goal carried enormous advantages, yet people didn't go the unsafe route and blew themselves up. The goal was a controlled reaction, just like the goal now is a controlled AI. "
singularity,How Frightened Should We Be of A.I.?,"I apologize for repeating myself, but those two scenarios are not comparable at all. I don't know what else to add.

I hope you're still curious about reading Superintelligence. It will answer all your questions much better than I ever could in this format."
